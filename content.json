{"pages":[{"title":"","text":"2t70lZryvq","link":"/baidu_verify_2t70lZryvq.html"},{"title":"book","text":"这个栏目写我的一些读后感，记录了在书中学到的知识，以及个人感悟。 《小狗钱钱》","link":"/book/index.html"},{"title":"了解本站","text":"个人简介 昵称：不愿意透露姓名的黑心市民 性别：帅气男子 年龄：20出头 方向：java，后端开发。 爱好：漂移板，沙雕视频，吹NB… 技术栈：熟悉各种 hello world！！！的写法，精通各种编程软件的卸载。 关于本站 故事的开始，要一个月黑风高的夜晚讲起…… 从前是在CSDN写技术博客，表面上是为了记录生活记录美，实则就是因为脑瓜不灵光，记不住东西，所以才萌生了写博客来记笔记的念头，经过长达两个月的产出，CSDN的文章数也突破了100大关，浏览量也有1万+了（虽然别人写个十多篇就有十几万的浏览量，我默默留下了没有技术的眼泪），粉丝也惊人的突破了11个，其中两个还是我的好朋友，（看到这里，你是不是应该考虑一下去给我涨个粉呢？）点我跳转，记得登录！ 言归正传，后来在百度的时候，惊奇的发现除了CSDN和简书之外，还有另一种博客的存在，一番了解之后，我秉持着探索新事物的理念，开始动手搭建。经过一个多月的折腾后，终于有了你眼前的这个博客网站。可以说实属不易了，理论和实践的千差万别，足以让我再次流下没有技术的眼泪，摸着头顶日渐稀疏的头发，再次陷入了沉思~ 博客历程 基于 github 的 page 服务，使用hexo博客框架，主题是next，本地环境是Nodejs，平时推送使用Git。 买了域名，并且备案通过后，将网站部署到了阿里云服务器上。 为网站添加了SSL证书，可以通过Https://访问，安全有保障，请放心浏览。 后来看惯了next主题过于简洁的画面，迁移到了Icarus，虽然过程艰辛，但不得不说真香！ 投机取巧使用CSDN的图床，终究还是错付了CSDN。 做了个勉强过得去的logo，也只能说还行~ 也许你可能看不到头像上的字母，love and share！，热爱，和分享！！！ 白嫖了阿里云的CDN加速，以及OOS对象存储，以提高网站的加载速度。 给网站添加一些小功能，添加一些小图标，排一下版，不痛不痒。 打赏功能就是图个乐呵，还有其他的一些功能实现的并不是特别的理想，后期慢慢完善。 将网站的配置信息上传到了Github上，有兴趣的朋友可以下载，会玩的朋友记得给颗星哦！链接奉上：https://github.com/DAQ121/DAQ121.github.io/tree/hexo 现在最主要的任务就是将CSDN上的文章迁移过来，唉~又要熬夜了。 SEO相关优化正在奋力学习中。 网站美化并不充分，追求加载速度，男人嘛，得快！！！ 本站存储一些学习笔记，就当做是个人空间。和大家一起分享学到的东西，看过的书，还有一起奔赴美好的明天，冲冲冲。 送给读者 如果你觉得这个网站符合你的口味，不妨点击一下关注，订阅哦。留言也可以整两句儿。","link":"/about/index.html"},{"title":"archives","text":"","link":"/archives/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"friends","text":"友情链接（friends）欢迎小伙伴交换友链~","link":"/friends/index.html"},{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"","text":"相册","link":"/photo/index.html"},{"title":"","text":"#link-box{ display: flex; width: 100%; height: auto; flex-wrap: wrap; align-items: center; display: flex; justify-content: flex-start; } .box{ width: calc(100% /2 - 11px); border-radius: 6px; box-shadow: 0 2px 3px rgba(10, 10, 10, 0.1), 0 0 0 1px rgba(10, 10, 10, 0.1); color: #4a4a4a; display: block; margin: 5px 5px 5px 5px !important; } .medias{ height: 80px; display: flex; } .avatar{ /* position: relative; */ width: 80px; height: 80px; } .avatar img{ width: 80px; height: 80px; border-radius: 50%; } .info{ flex: 1; } .info .title{ /* position: relative; */ font-weight: 600; /* width: 100%; */ /* height: 0px; */ margin-left: 15px; margin-top: 5px; margin-bottom: 6px; } .info .title i{ font-size: 15px; color: #0a0a0a; } .info .title a{ position: relative; font-size: 20px !important; color: #0a0a0a; font-weight: 400; } .info .descript{ position: relative; font-size: 14px; color: #0a0a0a; font-weight: 500; /* width: 100%; */ height: 20px; margin-left: 15px; /* margin-top: 10px; */ height: 40px; } @media screen and (max-width: 1450px) { .box { width: 100%; } }","link":"/friends/friends.css"}],"posts":[{"title":"HTPP中的GET和POST","text":"当我们在浏览器点击某个按钮，会向服务器发送一个请求（request），服务器收到请求之后，会返回给我们一个响应（response），那这个请求是如何发送的呢。 一、基础概念 HTTP是什么？HTTP基于TCP/IP，它是关于数据如何在万维网中通讯 的协议。 GET和POST是什么？HTTP协议中的两种发送请求 的方法。 二、简单理解 把万维网传输线路比作一条高速公路，公路上的汽车就相当于一个个TCP ，用他们来实现可靠数据传输，但是车也有不同车型，如果全都一样，送急件的汽车可能被前面满载货物的汽车拦堵在路上，整个交通就会瘫痪。为了避免这种情况发生，需要制定好交通规则，也就是HTTP协议。 HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等。①当执行GET请求的时候，要给汽车贴上GET的标签（设置method为GET），而且要求把传送的数据放在车顶上（url中）以方便记录。②如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物；也可以在POST的时候在车顶上也放一些数据。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。 不同的浏览器（发起http请求）和服务器（接受http请求），虽然理论上，你可以在车顶上无限的堆货物（url中无限加参数）。但是数据量太大对浏览器和服务器都是很大负担。 于是大多数浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。超过的部分不处理。如果使用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到。 所以可以这么理解：GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 三、标准答案 GET参数通过URL传递，POST放在Request body中。 GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST没有 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 四、关键区别 GET产生一个TCP数据包；POST产生两个TCP数据包。 通俗来讲就是：①对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）。②对于POST方式的请求，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。但是！！！！①GET与POST都有自己的语义，不能随便混用。②在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。③并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。","link":"/1483407090/"},{"title":"DBUtils学习笔记","text":"DbUtils是Apache组织提供的一个对JDBC进行简单封装的开源工具类库，使用它能够简化JDBC应用程序的开发，同时也不会影响程序的性能。并且简化了增删改查的操作。 使用开源的DBUtils概述 Commons DbUtils是Apache组织提供的一个对JDBC进行简单封装的开源工具类库，使用它能够简化JDBC应用程序的开发，同时也不会影响程序的性能。 简化了增删改查的操作。 用法 增删改 1234567891011121314151.导入jar包 commons-dbutils-1.4.jarpublic class TestDBUtils { @Test public void testInsert() throws SQLException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); // dbutils 只是帮我们简化了CRUD 的代码， 但是连接的创建以及获取工作。 不在他的考虑范围 QueryRunner queryRunner = new QueryRunner(dataSource); // 增加 queryRunner.update(\"insert into category values (null , ? , ? )\", \"a\", 1000); // 删除 queryRunner.update(\"delete from account where id = ?\", 5); // 更新 queryRunner.update(\"update account set money = ? where id = ?\", 10000000, 6); }} 查 123456789101112131415161718192021222324252627282930311.直接new接口的匿名实现类QueryRunner queryRunner = new QueryRunner(new ComboPooledDataSource()); Account account = queryRunner.query(\"select * from account where id = ?\", new ResultSetHandler&lt;Account&gt;(){ @Override public Account handle(ResultSet rs) throws SQLException { Account account = new Account(); while(rs.next()){ String name = rs.getString(\"name\"); int money = rs.getInt(\"money\"); account.setName(name); account.setMoney(money); } return account; } }, 6); System.out.println(account.toString());2. 直接使用框架已经写好的实现类。（最常用） QueryRunner queryRunner = new QueryRunner(new ComboPooledDataSource()); //查询单个对象Account account = queryRunner.query(\"select * from account where id = ?\", new BeanHandler&lt;Account&gt;(Account.class), 8); System.out.println(category.toString()); * 查询多个对象List&lt;Category&gt; list = queryRunner.query(\"select * from category\", new BeanListHandler&lt;Category&gt;(Category.class)); for (Category category : list) { System.out.println(category.toString()); } ResultSetHandler 常用的实现类 以下两个是使用频率最高的 BeanHandler 查询到的单个数据封装成一个对象 BeanListHandler 查询到的多个数据封装 成一个List&lt;对象&gt; ArrayHandler, 查询到的单个数据封装成一个数组。 ArrayListHandler, 查询到的多个数据封装成一个集合 ，集合里面的元素是数组。 MapHandler, 查询到的单个数据封装成一个map MapListHandler,查询到的多个数据封装成一个集合 ，集合里面的元素是map。 ColumnListHandler KeyedHandler ScalarHandler","link":"/2524199830/"},{"title":"HashMap源码分析","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前有一篇关于HashMap底层原理的分析，由于没有结合源码，所以只停留在浅显的层面，这篇结合JDK1.7和1.8的源码，分析一下HashMap的底层实现。 JDK1.7大致了解 JDK1.7：数组+链表 key和value组合成一个entry对象，将这个对象的引用地址存放在数组中。 table数组 123456781.根据key先算出来一个hash值int hash = key.hashcode();2.用这个hash值去跟数组长度(table.length)做与操作int i = hash &amp; (length-1); //得到的这个i就是数组下标3.就把这个key对应的value放入数组下标i对应的位置table[i]=value; 那为什么要用链表呢？ 再传进来一个value值,万一这个值对应的key算出来的hash值跟之前的重复了怎么办？这就要用到链表了。 将这个key对应的value值放在数组的同一个位置，只不过是以链表的形式。 那怎么放呢？是把这个元素放在链表的头部还是尾部呢？当然是采用头插法，因为尾插法效率低（他要遍历整个链表，要知道尾结点是谁，才能放入。）而放在头部只需要将next指向链表的头结点。 那么用put（）存进去了，用get()怎么取呢？，因为get()也是通过计算hash值，得到数组下标，但是这个下标上，有一个链表呀，怎么知道取的是哪个值呢？所以说： 一个新的结点插入到头部之后，要往下移动一个位置，（虽然说是移动一个位置，实际上是将这个新元素的值赋值给table[i],这样，头结点在哪里，链表就在那里）那么取链表上的元素就好取了。 源码分析 先分析一下put()方法 12345678910111213141516171819202122public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } 通过查看源码第一行的if语句可以看出，只有当要往里面存放元素的时候，才去初始化这个桶，懒加载（延迟初始化），在初始化数组的时候，调用了inflateTable(threshold)方法 12345678private void inflateTable(int toSize) { // Find a power of 2 &gt;= toSize int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); } 在其中又调用了roundUpToPowerOf2(toSize)方法。 123456private static int roundUpToPowerOf2(int number) { // assert number &gt;= 0 : \"number must be non-negative\"; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;} highestOneBit（）方法,通过移位和或运算计算出小于i的2的幂次方数capacity（这就是庶族的初始化容量），比如说，传入10，计算得出8，传入19，计算得出16。这个方法里面的运算是先把传入的数转化为二进制，然后在进行移位位运算和或运算，就像这个方法名字一样：得到最高位的那一位，自然而然的得出来的数就是2次幂的数了。得出来的这个数就是table数组的长度，jdk的作者对于位运算的使用已经达到出神入化的境界。 这样做的目的是，如果你修改了这个number值，他也会在加载的时候将这个值转化小于number的2的幂次方数。 123456789public static int highestOneBit(int i) { // HD, Figure 3-1 i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1); } 再看indexFor()方法，是通过将算出来的hash值与数组长度进行一个与运算，得到这个数组下标i。这个table[i]就是要存的位置。 12345678static int indexFor(int h, int length) {// assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); }思考为什么要length-1？因为length是2的幂次方数经过与运算之后，只得到低四位有效，有效的低四位取值范围就是0-15就得出了下标在0-15这个范围之内。 这就可以解决以上的一个问题了，为什么hashmap在初始化一个数组的容量的时候，要是一个2的幂次方数，因为要配合indexFor()计算出数组下标，对应存储。但是这样算出来的hash值会覆盖掉很多种情况，这就导致了很多元素算出来的下标值一样，存储在同一链表上，链表就会很长，进而影响到get()的效率，因为get()要循环链表嘛，所以回到上一步，可以看到hash()方法。 再看hash()方法（并不是hashcode()方法哦），它里面有异或和移位运算（这样高位就参与到运算了），可以理解为再次哈希，这样就增加了散列性。解决了的单条链表很长的问题。如果我们要改写hashcode（），但是我们水平不行，改了之后导致返回的hashcode值非常不均匀，那么这个hash()方法就会帮我们容错。 1234567891011121314final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } 再看for循环，它要做的事就是遍历链表，看看有没有key值相同的，比如说put(1,2);和put(1,3)，可以看到，两个key值是相等的，for循环判断之后，就会用新的值覆盖老的值，再返回老的值oldValue。 modCount++跟多线程并发有关。 addEntry(hash,key,value,i)这才是真正的将key和value放到数组上面去。if里面的语句就是涉及到扩容了，threshold是通过阈值capacity乘加载因子DEFAULT_LOAD_FACTOR得到的，如160.75=12，可以看到扩容要满足两个条件。这里的size是指当前数组占用了多少，而不是指链表的长度。后面那个条件是指数组中没有位置为空了，*大于阈值，并且发生过一次碰撞之后就扩容！！！** 123456789void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } 扩容的目的就是为了提高效率，因为链表上元素太多了，就会影响get()的效率。点开resize()方法可以看到，先new出来一个新的数组，长度是原先的两倍，然后在调用transfer()方法将老元素移动到新数组中。在转移的时候，将一个长链表拆成两个个短链表，减轻了压力。 12345678910111213void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 扩容是怎么来实现的呢？看这个transfer()方法中显示，有需要进行rehash的情况，也有不需要rehash的情况。看到for()循环是遍历这个数组上有没有空，而嵌套的while()循环是遍历这个链表上的元素。 先看不需要rehash的情况（适用于单线程）此时rehash=false，可以看到下面又使用了indexFor方法，传入的是被遍历的这个元素的hash值，和新数组的长度，计算得出一个值i，这就是新数组的下标，把老元素放到newTable[i]上。事实上，根据运算得到的i值和原先是一样的，因为原本的hash值没有变，只是拿过来用，而变化的是数组长度，但是并不会影响算出来的i值，所以说，传到新数组后，下标还是没有变。但是这样引发了扩容之后的一个问题：链表上的元素全部倒过来了，意思就是新链表的顺序和之前的完全颠倒了。 多线程情况下，如果有两个线程同时调用haspmap的这个对象，都会使用到put()方法，如果最终同时走到了resize()方法中，各种混乱的走法之后，最终会产生一个循环链表，最终耗尽CPU的资源。–这就是haspmap扩容带来的第二个问题 再看需要rehash的情况，其实很少会走到rehash()中，在rehash（）中打了一个断点，测试的时候无限put(),却发现，始终不会执行rehash（）。 123456789101112131415void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } 归纳总结 HashMap底层是怎么实现的呢？答：在jdk1.7的时候，底层是由数组+链表实现的，由key和value组成一个entry对象，用put方法将key和value传入，当调用这个put方法的时候，就会初始化一个数组（也就是所说的延迟初始化），这个数组的初始容量给的是16，负载因子是0.75，根据这个key值使用hash方法算出hash值，再用这个hash值跟数组的长度做模运算，得到一个数组下标，就将这个元素的值放入到对应下标的位置，那如果再传入的另一个元素算出来的hash值也是一样的（这就叫hash冲突），那么进而算出来的下标也是一样的，这就要用到链表了，使用头插法，并保证最新插入的这个元素是整个链表的头结点，就实现了存储的过程。 扩容的机制？在put的时候，有一个方法是addEntry，先判断当前的size是不是大于阈值，这里的阈值就是（数组初始长度加载因子），默认的就是12，大于这个阈值，并且发生了hash碰撞的时候，就要进行扩容了，就是执行resize()方法，扩容的方法就是，new一个新数组，长度是原数组长度的两倍，然后在用transfer方法将老数组中的元素转移过去，还重新算一下扩容之后的阈值，这样做出现的问题就是：在单线程情况下还好，只不过转移过去的链表会反转，*但是在多线程的情况下**，就会出现一个闭环，会把cpu的资源耗尽。这里面还有一个rehash()方法，但是这个方法我并没有具体研究，涉及到一个哈希种子，其实这个rehash方法并不会用到。在源码rehash中打个断点，测试代码中无限put操作，发现程序并不会停止。 HashMap为什么是线程不安全的？HashMap在put的时候，超过的阈值就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。 JDK1.8大致了解 在1.7中叫entry对象，在1.8中叫node结点。 在1.8中加入了红黑树，为什么加红黑树？虽然在1.7中实行了很多措施，如扩容，去增加元素的散列性，使链表的长度更短一些，但是还是会出现一些极端情况，某些地方链表还是会很长，所以加入了红黑树，当链表达到一定长度大于8的时候，就要先看数组，决定是否要扩容，然后在不行就要换用红黑树了。当红黑树结点小于6的时候，又变为链表了。 为什么链表上限设置为8，为红黑树下限设置为6呢？为什么不设置为8？这样是为了防止平凡的插入和删除，打个比方，当我插入第9个元素的时候，这就要变为红黑树了，可是我马上又删除了一个元素，红黑树又要变成链表，这样不停的来回转换，会拉低效率，所以将红黑树结点下限设置为6。 源码分析 分析put（）方法。 在1.8中采用尾插法加入元素，这是因为，每次加入元素的时候，本来就要遍历一下链表，看有没有超过八个结点，超过了就变成红黑树，总之是要遍历的，直接用尾插法，一举两得。 在遍历的过程中，还要看有没有与老元素key值相同的，相同则覆盖掉，除此之外还要判断是否为红黑树。 关于树化: 点开treeifyBin方法发现：在链表上的结点大于八个的时候，不会第一时间去树化，而是先判断是否需要扩容，然后再去决定要不要树化，其实扩容大概率能减少链表的长度了。一举两得，扩容比树化优点好多了。基于对内存的一个节省，不能扩容的太大，就用红黑树。 1.8里的扩容只要满足一个条件，而1.7中需要满足两个。 扩容详解，条件只有一个，但是代码却长了很多，核心思想就是：使用2次幂的扩展（长度变两倍）所以，要么元素的位置是在原位置，要么是在原位置基础上移动2次幂的位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 看到里面的算hash值的方法。跟1.7的差不多。 总结归纳 JDK1.8中，HashMap是怎么实现的？在JDK1.8中，底层是由数组+链表/红黑树实现的，将key和value封装成一个node结点，计算hash值和1.7是差不多的，在put的时候，有两点要注意，一个是判断新元素key值是否与老元素相等，相等则覆盖掉，不相等就直接插入，另一点就是判断是链表还是红黑树，选择遍历的方式，采用尾插法来插入元素，也不用担心需要遍历整个链表，因为判断链表上结点个数的时候总是要遍历的，这里值得注意的是，在判断是否需要变为红黑树的时候，（也就是链表结点大于等于8的时候）首先要考虑的是扩容，因为扩容大概率能够解决链表长度的问题，而且还增大了空间，但是不能一味的扩容，这样会导致内存浪费，所以就转换成红黑树了。 对比JDK1.7和1.8 1.7 1.8 底层实现 数组+链表 数组+链表/红黑树 形式 Entry&lt;key，value&gt;对象 Node&lt;key,value&gt;结点 下标值 hash &amp;（length-1） （n-1）&amp; hash 元素插入 头插法 尾插法 扩容机制 resize（链表反转，循环链表） 解决了链表反转的问题 查询效率 链表：n 红黑树：log（n） 扩容 transfor（）方法，新数组两倍长度 resize（）方法 常见问题 HashMap线程不安全，为什么还要用它？它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。但综合各种因素，首要推荐使用ConcurrentHashMap。 ConcurrentHashMap实现ConcurrentHashMap基于lock实现锁分段技术。首先将Map存放的数据分成一段一段的存储方式，然后给每一段数据分配一把锁，当一个线程占用锁访问其中一个段的数据时，其他段的数据也能被其他线程访问。ConcurrentHashMap不仅保证了多线程运行环境下的数据访问安全性，而且性能上有长足的提升。 ConcurrentHashMap有哪些优点？ 线程安全的，在多线程下效率更高。 ConcurrentHashMap对整个桶数组进行了分段，而HashMap则没有。 ConcurrentHashMap在每一个分段上都用锁进行保护，从而让锁的粒度更精细一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。 ConcourrentHashMap和Hashtable都是线程安全的，为什么不用Hashtable？ hashtable:使用一把锁处理并发问题，当有多个线程访问时，需要多个线程竞争一把锁，导致阻塞。 concurrentHashMap则使用分段，相当于把一个hashmap分成多个，然后每个部分分配一把锁，这样就可以支持多线程访问。","link":"/HashMap/"},{"title":"Http协议&C/S通讯抓包","text":"http协议：针对网络上的客户端 与 服务器端在执行http请求的时候，遵守的一种规范。 规定了客户端在访问服务器端的时候,服务器端返回数据的时候，要带上什么东西。 一、Http协议 什么是协议？双方在交互、通讯的时候， 遵守的一种规范、规则。 http协议概述针对网络上的客户端 与 服务器端在执行http请求的时候，遵守的一种规范。 其实就是规定了客户端在访问服务器端的时候，要带上哪些东西， 服务器端返回数据的时候，也要带上什么东西。 版本 1.0：请求数据，服务器返回后， 将会断开连接。 1.1：请求数据，服务器返回后， 连接还会保持着。 除非服务器 | 客户端 关掉。 有一定的时间限制，如果都空着这个连接，那么后面会自己断掉。 二、演示客户端 如何 与服务器端通讯。问题： 在地址栏中键入网络地址 回车 或者是平常注册的时候，点击了注册按钮 ， 浏览器都能显示出来一些东西。那么背地里到底浏览器和服务器是怎么通讯。 它们都传输了哪些数据？ 安装抓包工具 HttpWatch (IE插件) 打开tomcat. 输入localhost:8080 打开首页 在首页上找到Example—&gt;选择 Servlet Examples—&gt; Request Parameter 接着点击Request Parameters 的 Execute超链接，会出现请求参数示例 执行tomcat的例子，然后查看浏览器和 tomcat服务器的对接细节 三、Http请求数据解释 请求的数据里面包含三个部分内容 ： 请求行 、 请求头 、请求体 请求行： 12345678POST /examples/servlets/servlet/RequestParamExample HTTP/1.1 POST ： 请求方式 ，以post去提交数据 /examples/servlets/servlet/RequestParamExample 请求的地址路径 ， 就是要访问哪个地方。 HTTP/1.1 协议版本 请求头： 123456789101112131415161718192021Accept: application/x-ms-application, image/jpeg, application/xaml+xml, image/gif, image/pjpeg, application/x-ms-xbap, */* Referer: http://localhost:8080/examples/servlets/servlet/RequestParamExample Accept-Language: zh-CN User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E) Content-Type: application/x-www-form-urlencoded Accept-Encoding: gzip, deflate Host: localhost:8080 Content-Length: 31 Connection: Keep-Alive Cache-Control: no-cache Accept: 客户端向服务器端表示，我能支持什么类型的数据。 Referer ： 真正请求的地址路径，全路径 Accept-Language: 支持语言格式 User-Agent: 用户代理 向服务器表明，当前来访的客户端信息。 Content-Type： 提交的数据类型。经过urlencoding编码的form表单的数据 Accept-Encoding： gzip, deflate ： 压缩算法 。 Host ： 主机地址 Content-Length： 数据长度 Connection : Keep-Alive 保持连接 Cache-Control ： 对缓存的操作 请求体： 12345浏览器真正发送给服务器的数据 发送的数据呈现的是key=value ,如果存在多个数据，那么使用 &amp; firstname=zhang&amp;lastname=sansan 四、Http响应数据解析 请求的数据里面包含三个部分内容 ： 响应行 、 响应头 、响应体 1234567HTTP/1.1 200 OKServer: Apache-Coyote/1.1Content-Type: text/html;charset=ISO-8859-1Content-Length: 673Date: Fri, 17 Feb 2017 02:53:02 GMT...这里还有很多数据... 响应行：第一行 1234567891011HTTP/1.1 200 OK 协议版本 状态码 咱们这次交互到底是什么样结果的一个code. 200 : 成功，正常处理，得到数据。 403 : for bidden 拒绝 404 ： Not Found 500 ： 服务器异常 OK 对应前面的状态码 响应头 1234Server: 服务器是哪一种类型。 Tomcat Content-Type ： 服务器返回给客户端你的内容类型 Content-Length ： 返回的数据长度 Date ： 通讯的日期，响应的时间 五、Get 和 Post请求区别 post 数据是以流的方式写过去，不会在地址栏上面显示。 现在一般提交数据到服务器使用的都是POST。 以流的方式写数据，所以数据没有大小限制。 get 会在地址栏后面拼接数据，所以有安全隐患。 一般从服务器获取数据，并且客户端也不用提交上面数据的时候，可以使用GET。 能够带的数据有限， 1kb大小。","link":"/678909362/"},{"title":"Github使用学习","text":"刚开始上手使用github的时候，真是一头雾水，不仅看不懂英文，而且也不懂如何使用，一番研究之后，基本了解了如何使用github的功能。 一、使用Github1.1 目的 借助Github托管项目代码 1.2 基本概念 仓库（Respository） 收藏（Star） 复制克隆项目（Fork） 发起请求（Pull Request）：等待作者查看，如果他觉得不错，他会合并到自己的仓库。 关注（Watch）：你关注的人或者项目有新动态，你会收到消息。 事物卡片（Issue）：向作者发送问题，并且可以一起讨论这个问题。 1.3 创建仓库 创建账号，验证邮箱 创建一个test仓库 readMe：详细描述 1.4 仓库管理 创建新文件 修改文件 删除文件 删除之后可以进入commits查看被删除的文件。 上传文件 点击 upload选择要上传的文件，或者将文件拖动到该区域，一次可以选择上传多个文件。填写标题和描述之后，点击提交，就上传完成 搜索文件 点击find file，或者按住键盘T。 下载 / 检出项目 点击克隆或者下载。 1.5 提出问题 Issues作用： 发现代码BUG，但是目前没有成型代码，需要讨论时用，或者使用开源项目，出现问题时用。使用： 发现别人的项目有bug，提交issue，填写相应的标题和描述，然后提交过去。当作者登录github的时候，可以查看问题并讨论回复，问题解决后，点击close Issue 关闭问题。两方都有关闭Issue的权限。 1.6 拉取请求（Pull Request）","link":"/1657072496/"},{"title":"一、HashMap的底层实现原理","text":"HeshMap是基于哈希表的Map接口的实现，此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 此实现假定哈希函数将元素适当地分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代 collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。在面试中也经常出现这道考题，记录一下！ HsahMap的实现原理简要概括 HashMap 基于 Hash 算法实现的，底层是由数组+链表/红黑树构成的，我们通过 put(key,value)存储，get(key)来获取。当传入 key 时，HashMap 会根据 key. hashCode() 计算出 hash 值，根据 hash 值将 value 保存在 bucket 里。当计算出的 hash 值相同时，我们称之为 hash 冲突，HashMap 的做法是用链表和红黑树存储相同 hash 值的 value。当 hash 冲突的个数比较少时，使用链表，否则使用红黑树。 HashMap的存取实现 HashMap通过键值对实现存取。 put（）方法：对key做null检查。如果key是null，会被存储到table[0]，因为null的hash值总是0。 key的hashcode()方法会被调用，然后计算hash值。hash值用来找到存储Entry对象的数组的索引。有时候hash函数可能写的很不好，所以JDK的设计者添加了另一个叫做hash()的方法，它接收刚才计算的hash值作为参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods. * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } Get（）：对key进行null检查。如果key是null，table[0]这个位置的元素将被返回。key的hashcode()方法被调用，然后计算hash值。indexFor(hash,table.length)用来计算要获取的Entry对象在table数组中的精确的位置，使用刚才计算的hash值。在获取了table数组的索引之后，会迭代链表，调用equals()方法检查key的相等性，如果equals()方法返回true，get方法返回Entry对象的value，否则，返回null。 12345678910111213141516171819202122232425262728293031public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } /** * Implements Map.get and related methods. * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 补充： HashMap有一个叫做Entry的内部类，它用来存储key-value对。 上面的Entry对象是存储在一个叫做table的Entry数组中。 table的索引在逻辑上叫做“桶”(bucket)，它存储了链表的第一个元素。 key的hashcode()方法用来找到Entry对象所在的桶。 如果两个key有相同的hash值，他们会被放在table数组的同一个桶里面。 key的equals()方法用来确保key的唯一性。 有关知识的具体解析一、Map的几种类型 Map就是一个值key对应一个value。 Hashtable（线程安全）和HashMap（非线程安全）在代码实现上，基本上是一样的。现在Hashtable已经过时了(小写的t，因为sun当时的一个失误，因为是JDK1.0的产物，所以不方便改)。 ConcurrentHashMap也是线程安全的，但性能比HashTable好很多，Hashtable是锁整个Map对象，而ConcurrentHashMap是锁Map的部分结构。 二、什么是哈希表？ 利用数组寻址容易，但插入和删除困难。而链表是：寻址困难，插入和删除容易。而哈希表便综合两者的特性，是一种寻址容易，插入删除也容易的数据结构。 哈希表有多种不同的实现方法，最常用的方法—— 拉链法，可以理解为“链表的数组” 一个长度为16的数组中，每个元素存储的是一个链表的头结点。这些元素是按照什么样的规则存储到数组中呢？一般情况是通过hash(key)%len获得，也就是元素的key的哈希值对数组长度取模得到。 比如上述哈希表中12%16=12 , 28%16=12 , 108%16=12 , 140%16=12。所以12、28、108，140都存储在数组下标为12的位置。 HashMap其实也是一个线性数组（Entry[]）实现的,所以可以理解为其存储数据的容器就是一个线性数组。但是一个线性的数组怎么实现按键值对来存取数据呢？这里HashMap是做了一些处理的。 三、什么是哈希算法？ Hash算法虽然被称为算法，但实际上它更像是一种思想。Hash算法没有一个固定的公式，只要符合散列思想的算法都可以被称为是Hash算法。 哈希（hash）算法又称为散列算法，通过hash算法，可以将任意长度的信息转换成一个固定长度的二进制数据，我们经常会使用十六进制值来表示转换后的信息。 比如，数字123，使用md5的hash算法后，得到十六进制的值：202cb962ac59075b964b07152d234b70 哈希算法的特点：（1）不同的信息，理论上得到的hash值不同，我们称之为“无碰撞”，或者发生“碰撞”的概率非常小。（2）不可逆，hash算法是单向的，从hash值反向推导出原始信息是很困难的。所以，有些系统中，我们可以使用hash算法对密码进行处理后保存。 哈希算法的应用① 四、什么是红黑树？ 二叉树（BST）：①左子树结点的值小于等于根节点的值。②右子树结点的值大于等于根节点的值。③左右子树分开来也是单独的二叉树。 红黑树（RBT）：红黑树是一种自平衡的二叉树，除了符合二叉树的基本特征之外还引入了一些附加的条件。①节点是红色或黑色。②根节点是黑色。③每个叶子节点都是黑色的空节点（NIL节点）。④每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)。⑥从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 五、HashMap 和 Hashtable 有什么区别？ HashMap是非线程安全的，HashMap是Map的一个实现类，是将键映射到值的对象，不允许键值重复。允许空键和空值；由于非线程安全，HashMap的效率要较 Hashtable 的效率高一些。 Hashtable 是线程安全的一个集合，不允许 null 值作为一个 key 值或者value 值。 Hashtable是sychronized，多个线程访问时不需要自己为它的方法实现同步，而HashMap 在被多个线程访问的时候需要自己为它的方法实现同步。 一般现在不建议用Hashtable：①注意是小写的t，这是sun公司的一个失误，但是由于是JDK1.0的产物，所以没有改②是Hashtable是遗留类，内部实现很多没优化和冗余。③即使在多线程环境下，现在也有同步的ConcurrentHashMap替代，没有必要因为是多线程而用HashTable。 如何解决hash冲突产生hash冲突的原因 当我们通过put(key, value)向hashmap中添加元素时，需要通过hash函数确定元素究竟应该放置在数组中的哪个位置，因为不同的元素可能通过hashcode（）计算得到的哈希值相同，那么不同的元素被放置在了数据的同一个位置时，后放入的元素会以链表的形式，插在前一个元素的尾部，这个时候我们称发生了hash冲突。 解决方法 事实上，想让hash冲突完全不发生，是不太可能的，我们能做的只是尽可能的降低hash冲突发生的概率。①开放定址法②链地址法（拉链法）Java 中 HashMap 解决 Hash 冲突就是利用了这个方法，具体实现这里暂时不做详解，可以参考 Jdk HashMap 源码进行理解。③再哈希法④建立公共溢出区","link":"/2744944506/"},{"title":"JDBC学习","text":"如何使用JDBC连接到数据库 一、添加JDBC驱动包) 二、使用JDBC简单步骤 1、注册驱动` 1DriverManager.registerDriver(new com.mysql.jdbc.Driver()); 2、建立连接 1Connection conn=(Connection) DriverManager.getConnection(\"jdbc:mysql://localhost/数据库名\", \"root\", \"daq\"); 3、创建statement—-跟数据库打交道，一定需要这个对象 1st = conn.createStatement(); 4、执行sql 查询，得到结果集ResultSet 12String sql = \"select * from t_stu\";ResultSet rs = st.executeQuery(sql); 5、遍历查询每一条记录 1234567while(rs.next()){ int id=rs.getInt(\"cid\"); String name =rs.getString(\"cname\"); String desc =rs.getString(\"cdesc\"); System.out.println(\"cid\"+id +\"cname\"+name +\"cdesc\"+desc); } 6、关闭，释放资源 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748新建一个包放置适房资源的工具类，在JDBC释放资源时调用即可public class JDBCUtil { /** * @param args * @deprecated 释放资源 */ public static void release(ResultSet rs,Statement st,Connection conn){ closeRs(rs); closeSt(st); closeConn(conn); } private static void closeRs(ResultSet rs){ try { if (rs != null) { rs.close(); } } catch (SQLException e) { e.printStackTrace(); }finally{ rs=null; } } private static void closeSt(Statement st){ try { if (st != null) { st.close(); } } catch (SQLException e) { e.printStackTrace(); }finally{ st=null; } } private static void closeConn(Connection conn){ try { if (conn != null) { conn.close(); } } catch (SQLException e) { e.printStackTrace(); }finally{ conn=null; } } 三、JDBC工具类（修改原有代码） 查看源代码，有一段静态代码块（类加载的时候就会执行），所以等同于说注册了两次驱动，其实驱动只需要注册一次就够了。 1、注册驱动（防止二次注册） 123改成以下代码即可Class.forName(\"com.mysql.jdbc.Driver\");引号里面是Driver的全路径 2、在工具类中加方法getconn（） 123456789101112131415161718192021static String url=\"jdbc:mysql://localhost/daq\";static String name=\"root\";static String password=\"daq\";/** * 获取连接对象 * @return */public static Connection getconn() { Connection conn = null; try { // 1.注册驱动 Class.forName(\"com.mysql.jdbc.Driver\"); // 2.建立连接 conn = (Connection) DriverManager.getConnection( url, name, password); } catch (Exception e) { e.printStackTrace(); } return conn;} 使用properties配置文件 123456789101112131415161718192021222324252627282930311.创建properties 在src下面新建一个**jdbc.properties** 文件 写入： driverClass=com.mysql.jdbc.Driver url=jdbc:mysql://localhost/daq name=root password=daq 2.读取properties 在JDBCUtil工具类中添加静态代码块，保证工具类一加载，就可以读取配置文件。 static String driverClass = null; static String url = null; static String name = null; static String password = null; static { try { // 1.创建一个属性配置对象 Properties properties = new Properties(); InputStream is = JDBCUtil.class.getClassLoader().getResourceAsStream(\"jdbc.properties\"); // 导入输入流 properties.load(is); // 读取属性 driverClass =properties.getProperty(\"driverClass\"); url =properties.getProperty(\"url\"); name =properties.getProperty(\"name\"); password =properties.getProperty(\"password\"); } catch (IOException e) { e.printStackTrace(); } } 四、JDBC的CRUD insert（插入） 1234567891011121314151617INSERT INTO t_stu VALUES (NULL,'wangqiang2',28) // 1. 获取连接对象 conn = JDBCUtil.getconn(); // 2. 根据连接对象，得到statement st = conn.createStatement(); //3. 执行添加 String sql = \"insert into t_stu values(null , 'aobama' , 59)\"; //影响的行数， ，如果大于0 表明操作成功。 否则失败 int result = st.executeUpdate(sql); if(result &gt;0 ){ System.out.println(\"添加成功\"); }else{ System.out.println(\"添加失败\"); } delete（删除） 1234567891011121314151617DELETE FROM t_stu WHERE id = 6 // 1. 获取连接对象 conn = JDBCUtil.getConn(); // 2. 根据连接对象，得到statement st = conn.createStatement(); //3. 执行添加 String sql = \"delete from stu where name='XXX'\"; //影响的行数， ，如果大于0 表明操作成功。 否则失败 int result = st.executeUpdate(sql); if(result &gt;0 ){ System.out.println(\"删除成功\"); }else{ System.out.println(\"删除失败\"); } query（查询） 123456789101112131415161718SELECT * FROM t_stu // 1. 获取连接对象 conn = JDBCUtil.getConn(); // 2. 根据连接对象，得到statement st = conn.createStatement(); // 3. 执行sql语句，返回ResultSet String sql = \"select * from stu\"; rs = st.executeQuery(sql); // 4. 遍历结果集 while (rs.next()) { String name = rs.getString(\"name\"); int age = rs.getInt(\"age\"); System.out.println(name + \" \" + age); } update（更新） 12345678910111213141516UPDATE t_stu SET age = 38 WHERE id = 1; // 1. 获取连接对象 conn = JDBCUtil.getConn(); // 2. 根据连接对象，得到statement st = conn.createStatement(); //3. 执行添加 String sql = \"update t_stu set age = 26 where name ='qyq'\"; //影响的行数， ，如果大于0 表明操作成功。 否则失败 int result = st.executeUpdate(sql); if(result &gt;0 ){ System.out.println(\"更新成功\"); }else{ System.out.println(\"更新失败\"); } 补充：单元测试junit 1234567891011121314- 定义一个类， TestXXX , 里面定义方法 testXXX.- 添加junit的支持。 右键工程 --- add Library --- Junit --- Junit4- 在方法的上面加上注解 ， 其实就是一个标记。 @Test public void testQuery() { ... }- 光标选中方法名字，然后右键执行单元测试。 或者是打开outline视图， 然后选择方法右键执行。 五、DAO模式 Data Access Object 数据访问对象 1、新建一个dao的接口， 里面声明数据库访问规则 12345678910/** * 定义操作数据库的方法 */public interface UserDao { /** * 查询所有 */ void findAll();} 2、新建一个dao的实现类，具体实现早前定义的规则 12345678910111213141516171819202122232425262728public class UserDaoImpl implements UserDao{ @Override public void findAll() { Connection conn = null; Statement st = null; ResultSet rs = null; try { //1. 获取连接对象 conn = JDBCUtil.getConn(); //2. 创建statement对象 st = conn.createStatement(); String sql = \"select * from t_user\"; rs = st.executeQuery(sql); while(rs.next()){ String userName = rs.getString(\"username\"); String password = rs.getString(\"password\"); System.out.println(userName+\"=\"+password); } } catch (Exception e) { e.printStackTrace(); }finally { JDBCUtil.release(conn, st, rs); } } } 直接使用实现 12345@Testpublic void testFindAll(){ UserDao dao = new UserDaoImpl(); dao.findAll();} 六、JDBC Statement安全问题 Statement执行 ，其实是拼接sql语句的。 先拼接sql语句，然后在一起执行。 123456789String sql = \"select * from t_user where username='\"+ username +\"' and password='\"+ password +\"'\"; UserDao dao = new UserDaoImpl(); dao.login(\"admin\", \"100234khsdf88' or '1=1\"); SELECT * FROM t_user WHERE username='admin' AND PASSWORD='100234khsdf88' or '1=1' 前面先拼接sql语句， 如果变量里面带有了 数据库的关键字，那么一并认为是关键字。 不认为是普通的字符串。 rs = st.executeQuery(sql); 七、PreparStatement CRUD 该对象就是替换前面的statement对象。 相比较以前的statement， 预先处理给定的sql语句，对其执行语法检查。 在sql语句里面使用 ? 占位符来替代后续要传递进来的变量。 后面进来的变量值，将会被看成是字符串，不会产生任何的关键字。 123456String sql = \"insert into t_user values(null , ? , ?)\"; ps = conn.prepareStatement(sql); //给占位符赋值 从左到右数过来，1 代表第一个问号， 永远你是1开始。 ps.setString(1, userName); ps.setString(2, password); PreparStatement的添加，删除，更新，","link":"/473128650/"},{"title":"JSP&EL&JSTL","text":"JSP，EL表达式，JSTL介绍 一、JSP什么是jsp？Java Server Page 从用户角度看待 ，就是是一个网页 ， 从程序员角度看待 ， 其实是一个java类， 它继承了servlet，所以可以直接说jsp 就是一个Servlet. 为什么会有jsp?为了有更好的用户体检，更好的交互效果。因为html 多数情况下用来显示静态内容 ， 一成不变的。 但是有时候我们需要在网页上显示一些动态数据， 比如： 查询所有的学生信息， 根据姓名去查询具体某个学生。 这些动作都需要去查询数据库，然后在网页上显示。 html是不支持写java代码 ， jsp里面可以写java代码。 jsp怎么用？一、jsp指令一、page指令 1234567891011121314151617181920212223242526指令写法：&lt;%@ 指令名字 %&gt;page指令：1. language：表明jsp页面中可以写java代码2. contentType：其实就是说这个文件是什么类型，告诉浏览器我是什么内容类型，以及使用什么编码 contentType=\"text/html; charset=UTF-8\" text/html MIMEType 这是一个文本，html网页3. pageEncoding：jsp内容编码4. extends 用于指定jsp翻译成java文件后，继承的父类是谁，一般不用改。5. import 导包使用的，一般不用手写。6. session - 值可选的有true or false - 用于控制在这个jsp页面里面，能够直接使用session对象。 - 具体的区别是，请看翻译后的java文件： 如果该值是true , 那么在代码里面会有getSession（）的调用， 如果是false : 那么就不会有该方法调用，也就是没有session对象了。在页面上自然也就不能使用session了。7. errorPage： 指的是错误的页面， 值需要给错误的页面路径8. isErrorPage：上面的errorPage 用于指定错误的时候跑到哪一个页面去。 那么这个isErroPage , 就是声明某一个页面到底是不是错误的页面。 二、include指令 包含另外一个jsp的内容进来。 1&lt;%@ include file=\"other02.jsp\"%&gt; 背后细节:把另外一个页面的所有内容拿过来一起输出。 所有的标签元素都包含进来。 三、taglib 123&lt;%@ taglib prefix=\"\" uri=\"\"%&gt; uri: 标签库路径 prefix : 标签库的别名 二、jsp动作标签（写在body里面）123&lt;jsp:include page=\"\"&gt;&lt;/jsp:include&gt;&lt;jsp:param value=\"\" name=\"\"/&gt;&lt;jsp:forward page=\"\"&gt;&lt;/jsp:forward&gt; 12345678910111213141516171819- jsp:include&lt;jsp:include page=\"other02.jsp\"&gt;&lt;/jsp:include&gt;包含指定的页面， 这里是动态包含。 也就是不把包含的页面所有元素标签全部拿过来输出，而是把它的运行结果拿过来。 - jsp:forward前往哪一个页面。 &lt;jsp:forward page=\"\"&gt;&lt;/jsp:forward&gt;等同于：请求转发&lt;% request.getRequestDispatcher(\"other02.jsp\").forward(request,response);%&gt; - jsp:param第一步：在包含某个页面的时候，或者在跳转某个页面的时候，加入这个参数。&lt;jsp:forward page=\"other02.jsp\"&gt; &lt;jsp:param value=\"beijing\" name=\"address\"/&gt;&lt;/jsp:forward&gt;第二步：在other02.jsp中获取这个参数&lt;br&gt;收到的参数是：&lt;br&gt;&lt;%= request.getParameter(\"address\")%&gt; jsp内置对象（重点！） 所谓内置对象（有九个），就是我们可以直接在jsp页面中使用这些对象。 不用创建。 作用域对象 作用域对象有四个： pageContext request session application 作用域 ： 表示这些对象可以存值，他们的取值范围有限定。用setAttribute 和 getAttribute来进行存取。 12345678910111213使用作用域来存储数据&lt;br&gt;&lt;% pageContext.setAttribute(\"name\", \"page\"); request.setAttribute(\"name\", \"request\"); session.setAttribute(\"name\", \"session\"); application.setAttribute(\"name\", \"application\");%&gt;取出四个作用域中的值&lt;br&gt;&lt;%=pageContext.getAttribute(\"name\")%&gt;&lt;%=request.getAttribute(\"name\")%&gt;&lt;%=session.getAttribute(\"name\")%&gt;&lt;%=application.getAttribute(\"name\")%&gt; 作用域范围大小：（由小到大） 1pageContext -- request --- session -- application 四个作用域的区别 123456789101111. pageContext 【PageContext】作用域仅限于当前的页面，还可以获取到其他八个内置对象。12. request 【HttpServletRequest】作用域仅限于一次请求， 只要服务器对该请求做出了响应。 这个域中存的值就没有了。13. session 【HttpSession】作用域限于一次会话（多次请求与响应） 当中。 14. application 【ServletContext】 整个工程都可以访问， 服务器关闭后就不能访问了。 其他内置对象 out 【JspWriter】 response 【HttpServletResponse】 exception 【Throwable】 page 【Object】 —就是这个jsp翻译成的java类的实例对象 config 【ServletConfig】 二、EL表达式 是为了简化jsp代码，具体一点就是为了简化在jsp里面写的那些java代码。 12写法格式： ${表达式 } 如果从作用域中取值，会先从小的作用域开始取，如果没有，就往下一个作用域取。 一直把四个作用域取完都没有， 就没有显示。 EL取值方式1234567891011121314151617181920212223242526272829303132333435363738394041424344451. 取出4个作用域中存放的值 &lt;% pageContext.setAttribute(\"name\", \"page\"); request.setAttribute(\"name\", \"request\"); session.setAttribute(\"name\", \"session\"); application.setAttribute(\"name\", \"application\"); %&gt; 按普通手段取值： &lt;%= pageContext.getAttribute(\"name\")%&gt; &lt;%= request.getAttribute(\"name\")%&gt; &lt;%= session.getAttribute(\"name\")%&gt; &lt;%= application.getAttribute(\"name\")%&gt; 使用EL表达式取出作用域中的值： ${ pageScope.name } ${ requestScope.name } ${ sessionScope.name } ${ applicationScope.name }2. 如果域中所存的是数组 &lt;% String [] a = {\"aa\",\"bb\",\"cc\",\"dd\"}; pageContext.setAttribute(\"array\", a); %&gt; 使用EL表达式取出作用域中数组的值： ${array[0] } , ${array[1] },${array[2] },${array[3] }3. 如果域中存的是集合 使用EL表达式取出作用域中集合的值： ${li[0] } , ${li[1] },${li[2] },${li[3] }4. 取出Map集合的值 &lt;br&gt;-------------Map数据----------------&lt;br&gt; &lt;% Map map = new HashMap(); map.put(\"name\", \"zhangsna\"); map.put(\"age\",18); map.put(\"address\",\"北京..\"); map.put(\"address.aa\",\"深圳..\"); pageContext.setAttribute(\"map\", map); %&gt; 使用EL表达式取出作用域中Map的值： ${map.name } , ${map.age } , ${map.address } , ${map[\"address.aa\"] } 取值细节12345678910111213141516171819202122232425262728291. 从域中取值。 得先存值。 &lt;% //pageContext.setAttribute(\"name\", \"zhangsan\"); session.setAttribute(\"name\", \"lisi...\"); %&gt; 直接指定说了，到这个作用域里面去找这个name ${ pageScope.name } //先从page里面找，没有去request找，去session，去application ${ name } 指定从session中取值 ${ sessionScope.name } 2. 取值方式- 如果这份值是有下标的，那么直接使用[] &lt;% String [] array = {\"aa\",\"bb\",\"cc\"} session.setAttribute(\"array\",array); %&gt; ${ array[1] } --&gt; 这里array说的是attribute的name - 如果没有下标， 直接使用 .的方式去取 &lt;% User user = new User(\"zhangsan\",18); session.setAttribute(\"u\", user); %&gt; ${ u.name } , ${ u.age } 3. 一般使用EL表达式，用的比较多的，都是从一个对象中取出它的属性值，比如取出某一个学生的姓名。 EL表达式 的11个内置（隐式）对象12345678910111213141516171819202122232425内置对象：已经存在，不用创建，可以直接获取成员变量或者属性 用法：${ 对象名.成员 }JSP相关对象- pageContext 作用域相关对象（用的比较多）- pageScope- requestScope- sessionScope- applicationScope请求头信息相关对象- header- headerValues请求参数信息相关对象- param- paramValuesCookie- cookie全局初始化参数- initParam 三、 JSTL（标准标签库） 全称 ： JSP Standard Tag Library ： jsp标准标签库 简化jsp的代码编写。 替换 &lt;%%&gt; 写法。 一般与EL表达式配合 JSTL使用 导入jar文件到工程的WebContent/Web-Inf/lib jstl.jar和standard.jar 在jsp页面上，使用taglib 指令，来引入标签库 注意： 如果想支持 EL表达式，那么引入的标签库必须选择1.1的版本，1.0的版本不支持EL表达式。 1&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt; 常用标签123&lt;c:set&gt;&lt;/c:set&gt;&lt;c:if test=\"\"&gt;&lt;/c:if&gt;&lt;c:forEach&gt;&lt;/c:forEach&gt; 1234567891011121314151617181920212223242526272829303132333435363738391. c:set &lt;!-- 声明一个对象name， 对象的值 zhangsan , 存储到了page（默认） ， 指定是session --&gt; &lt;c:set var=\"name\" value=\"zhangsan\" scope=\"session\"&gt;&lt;/c:set&gt; ${sessionScope.name }2. c:if 判断test里面的表达式是否满足，如果满足，就执行c:if标签中的输出 ， c:if 是没有else的。 &lt;c:set var=\"age\" value=\"18\" &gt;&lt;/c:set&gt; &lt;c:if test=\"${ age &gt; 26 }\"&gt; 年龄大于了26岁... &lt;/c:if&gt; &lt;c:if test=\"${ age &lt;= 26 }\"&gt; 年龄小于了26岁... &lt;/c:if&gt; ------------------------------ 定义一个变量名 flag 去接收前面表达式的值，然后存在session域中 &lt;c:if test=\"${ age &gt; 26 }\" var=\"flag\" scope=\"session\"&gt; 年龄大于了26岁... &lt;/c:if&gt;3. c:forEach 从1 开始遍历到10 ，得到的结果 ，赋值给 i ,并且会存储到page域中， step , 增幅为2， &lt;c:forEach begin=\"1\" end=\"10\" var=\"i\" step=\"2\"&gt; ${i } &lt;/c:forEach&gt; ----------------------------------------------- &lt;!-- items : 表示遍历哪一个对象，注意，这里必须写EL表达式。 var: 遍历出来的每一个元素用user 去接收。 --&gt; &lt;c:forEach var=\"user\" items=\"${list }\"&gt; ${user.name } ----${user.age } &lt;/c:forEach&gt;","link":"/1540231261/"},{"title":"JDBC基础知识","text":"JDBC概述，作用，类型，以及使用时如何选择。 一、JDBC是什么？ 百度百科解释：JDBC(java database connectivity)驱动程序是对JDBC规范完整的实现，它的存在在Java程序与数据库系统之间建立了一条通信的渠道。它是 一 种可用于执行 SQL 语句的 Java API(Application Programming Interface， 应用程序设计接口)。 简单理解：java 数据库连接。有了它，就能够在java代码中操作任何数据库。由于数据库种类繁多，并且java程序使用广泛，sun公司就提供了一种规范，让其他的数据库提供商去实现底层的访问。 刚开始每个数据库（Oracle，Mysql，SqlServer）的访问规则都不同，后来SUN公司想一统天下，出台了一套规范，各个数据库要按照这个规范去写底层代码，与此同时，Java程序也直接去找JDBC。 二、作用是什么？ JDBC 为数据库应用开发人员、数据库前台开发人员提供了一种标准的应用程序设计接口， 使开发人员可以用纯 Java 语言编写完整的数据库应用程序。 JDBC 通过调用其接口提供的方法， 提供了 Java 应用程序与各种数据库服务器之间的连接服务，。 它支持 ANSI SQL- 92 标准， 实现了从 Java 程序内调用标准的 SQL 命令对数据库进行查询、插入、删除和更新等操作， 并确保数据事务的正常进行。 三、JDBC驱动程序根据访问数据库的技术不同， JDBC 驱动程序相应地分为四种类型。不同类型的驱动程序有着不一样的特性和使用方法。 1.JDBC-ODBC桥驱动程序(JDBC-ODBC Bridge Driver) 此类驱动程序由JDBC-ODBC桥和一个ODBC驱动程序组成。 工作原理：通过一段本地C代码将JDBC调用转化成ODBC调用。这一类型必须在本地计算机上先安装好ODBC驱动程序，然后通过JDBC-ODBCBridge的转换，将Java程序中使用的JDBC API访问指令转化成ODBC API指令，进而通过ODBC驱动程序调用本地数据库驱动代码完成对数据库的访问。 2.部分Java的本地JDBC API驱动程序 JDBC API驱动程序(Anative API partly Java technology-enabled Driver) 工作原理：此类驱动程序也必须在本地计算机上先安装好特定的驱动程序(类似ODBC)，然后通过PartialJavaJDBCDriver的转换，把Java程序中使用的JDBC API转换成NativeAPI，进而存取数据库。 3.纯Java的数据库中间件驱动程序 纯Java的数据库中间件驱动程序(Pure Java Driver for Database Middleware)使用这类驱动程序时，不需要在本地计算机上安装任何附加软件，但是必须在安装数据库管理系统的服务器端加装中间件(Middleware)，这个中间件负责所有存取数据库时必要的转换。 工作原理：驱动程序将JDBC访问转换成与数据库无关的标准网络协议(通常是HTTP或HTTPS)送出，然后再由中间件服务器将其转换成数据库专用的访问指令，完成对数据库的操作。中间件服务器能支持对多种数据库的访问。 4.纯Java的JDBC驱动程序 纯Java的JDBC驱动程序(Direct-to-DatabasePureJavaDriver)这类驱动程序是直接面向数据库的纯Java驱动程序，即所谓的”瘦”驱动程序。 工作原理：使用这类驱动程序时无需安装任何附加的软件(无论是本地计算机或是数据库服务器端)，所有存取数据库的操作都直接由JDBC驱动程序来完成，此类驱动程序能将JDBC调用转换成DBMS专用的网络协议，能够自动识别网络协议下的特殊数据库并能直接创建数据连接。 四、JDBC驱动程序的选择在企业内部信息系统中，选择合适的JDBC驱动程序，使之符合数据库程序设计的要求，是提高系统性能必须考虑的一个方面。不同的应用有不同的需要，所以要根据应用选择合适的驱动程序。 JDBC-ODBC桥驱动程序(JDBC-ODBC Bridge Driver) 优点：节省投资，利用了已有的ODBC驱动程序。 缺点：中间有多次调用，性能受到影响，执行效率比较低，不适合对大数据量存取的应用。有损Java数据库程序的兼容性，不具备跨平台性，不适合基于Internet/Intranet的应用。 应用：桥接驱动程序用于已经在ODBC技术上投资的情形，例如已经投资了Windows应用服务器。 部分Java的本地JDBC API驱动程序 优点：具有开放性，其利用多层结构，上层用Java实现，支持多数据库，下层为本地代码(包括一些二进制代码和一个轻量的Java库)，加快了执行速度，提高了数据库访问效率。 缺点：没有使用纯Java的API，如果在本地代码中存在缺陷，将可能使Java虚拟机完全垮掉。 应用：受到限制 纯Java的数据库中间件驱动程序 优点：由纯Java语言开发而成的，并且中间件也仅需要在服务器上安装，不再需要客户端的本机代码，这类驱动程序的体积最小，效率较高，具有最大的灵活性。此类驱动采用标准的网络协议，可以被防火墙支持，是开发Applet程序理想的选择(其实这些驱动是为Applet特别编写的)，是Internet应用理想的解决方案。开发者还可以利用单一的驱动程序连接到多种数据库。 缺点：需要在服务器端安装中间件，这适当影响了驱动程序的效率。 应用：基于Web的应用系统的开发。 纯Java的JDBC驱动程序 最佳的JDBC驱动程序类型。 优点：无需安装任何附加软件，不会增加任何额外开销，效率最高，拥有最佳的兼容性。 缺点：可能不被防火墙支持，在Internet中会存在潜在安全隐患，成为这类驱动最大的缺陷。 应用：在企业级应用软件中，是应优先考虑的。因此，一个Servlet程序，要适应不同的操作系统，最好使用此类驱动;这种驱动也非常适合Applet程序，事实证明它能安全通过TCP/IP协议连接到数据库。","link":"/3453823259/"},{"title":"操作系统---CPU调度","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;计算机的三大核心部件：CPU，存储器，I/O设备，其中CPU作为操作系统的运算和控制核心，是信息处理、程序运行的最终执行单元，起到了大脑的作用。CPU又包括两部分：控制器、运算器。众所周知，在某一个时间段，CPU只能被一个进程占用，这篇文章就认识一下CPU的调度策略。 小概念 我们所做的多进程，多线程，多道程序设计，批处理等等一些操作的目的就是为了最大化cpu的利用率。 用一会cpu，等待一会IO，循环往复，交替执行（通过IO获得数据，再通过CPU对数据进行处理，在通过IO将结果输出） 通过考虑CPU和IO的占用，我们还可以将进程划分为两大类：①：CPU绑定进程（对CPU使用的比较多，很少量的时间使用IO）②：IO绑定进程（与之相反） 调度：队列里面有好多个进程，选择哪一个去运行，决定下一个是谁。①抢占式：（被动的）②非抢占式：（自愿让出CPU） CPU的利用率：占了百分之多少，越多越好。 吞吐率：单位时间内完成了多少进程。越多，效率越高。 周转时间：一个进程从创建到结束，一共用了多少时间。 等待时间：一个进程在等待状态多长时间，这个时间越短越好。 响应时间：正在等待的进程，对已经发生的事件，的响应速度，越快越好。 调度策略 但是看得不是单个进程的性能指标，看得是所有进程加在一起，算出来的平均周转时间，平均等待时间，平均响应时间。才能看出调度能力。 最短作业优先（SJF） ：谁运行时间最短谁来使用CPU。 最短剩余时间优先： 不看他以前运行了多久，只看他剩下多少时间。 上面这两种调度策略是在已知需要在CPU上运行多少时间的情况，但是这个运行时间未知呢？调度最有效的依据是进程将来在CPU上消耗的时间，并期望用时最短的进程最优先执行。 预测未来： 基于统计过去这个进程对CPU的使用情况来 预测。根据统计IO的时间多，还是使用CPU的时间多。 先来先服务（FCFS） ：谁优先级高运行谁。会导致优先级低的进程饿死。 时间片轮转算法（Round Robin） ：广泛采用，给定每个进程一个时间片，用完了就去等待。这个时候就要考虑时间片的设置大小。越合理越好。如果时间片太大，那么他就近似成了一个先来先服务算法。 将时间片轮转和优先级结合起来：时间片轮转就在就绪队列里选择优先级高的进程先运行。 多级队列（Multilevel Queue） ：把整个系统所有的进程放在好多个队列中，这个队列里面的进程优先级是一样的，调度的时候，就按着这个队列找。①系统级队列（最高优先级）：系统进程要应对很关键的问题，它负责系统的中断处理的。（中断指令一定要及时响应，否则下一个中断进来了，就会丢失一个中断）② 交互式的进程：属于IO绑定的进程，很少使用CPU，随时给用户一个反馈。响应速度必须得快。③批处理进程：频繁使用CPU的进程。 多级反馈队列（普遍采用）： 根据这个进程以前的行为的统计来预测以后怎么处置他，这个预测就是由反馈实现的。①反馈怎么实现？：新来的进程首先设置他的优先级为最高，来根据他的行为，表现，来确定他的优先级，降级。②只要长时间使用了CPU，就把你优先级降低，只要你做过一次IO操作，就把你优先级提一级，形成一个动态的变换。 多CPU调度 多核，重核。每一个内核在任意时刻只能运行一个进程。未来可能会出现128核，实际上，会有备用的核，因为出厂的时候，也许会有坏核，备用核就顶上。 特别之处：调度问题的复杂度增加了，如何去做负载均衡（比如说一个CPU太忙，一个CPU太闲,那这样多核就没有意义了）。 同构（CPU完全一样的）①非对称式的多处理器管理（现阶段用不到）：（每个内核的作用是不同的）让一个内核只运行操作系统，其他的内核只运行应用程序。好处：对操作系统简单多了，只用管理自己的内核。②对称式的多处理器管理：所有的处理机都是完全平等的，每个内核既运行操作系统，也运行应用程序，完全由繁忙程度来决定。每一个处理器都有私有的队列。 异构（CPU有不同之处，特别复杂，基本上用不到） 负载均衡：通过迁移进程来实现，会产生cache刷新，但是利大于弊。 操作系统是如何实现多级反馈的 太难了，不想了解！！！","link":"/789539749/"},{"title":"MySql基础操作","text":"本文简单介绍了数据库，和一些基本操作。 什么是数据库？ 数据库就是一个文件系统，只不过我们需要通过SQL命令来操作这个文件系统。 数据库（DataBase）是按照数据结构来组织，存储和管理数据的建立在计算机存储设备上的仓库。 作用：存储数据，数据的仓库，带有访问权限，限制不同的人可以有不同的操作。 java EE操作的都是后台数据，取到后台数据进行封装，然后交给前端去展现。 有哪些数据库 mysql：开源免费，适用于中小企业的免费数据库。 oracle：甲骨文公司，收费软件，适用于大型网站。 db2：IBM公司，做解决方案，软件和硬件，服务器架构，银行系统。 sqlserver：windows里，政府网站。asp.net 大学教学，图形化做得好。 Mysql的sql语句有哪些？ SQL(Structure Query Language)结构化查询语言 DDL数据定义语言：定义数据库，数据表他们的结构，create（创建），drop（删除），alert（修改） DML数据操纵语言：主要用来操作数据，insert（插入），update（修改），delete（删除） DCL数据控制语言：定义访问权限，取消访问权限，安全设置，grant DQL数据查询语言：select（查询） from子句 where子句 数据库的CRUD操作(增删改查) 登录数据库服务器 1mysql -uroot -pdaq 创建数据库： 1create database 数据库的名字; 1create database 数据库的名字 character set 字符集;//指定字符集 查看所有数据库 1show databases; 查看指定数据库： 1show create database 数据库的名字; 修改数据库的字符集 1alter database 数据库的名字character set 字符集; 删除数据库 1drop database 数据库的名字; 切换数据库（选中数据库） 1use 数据库的名字; 查看当前正在使用的数据库 1select database(); 表的创建 创建表 1create table 表名（列名 列的类型(长度) 约束，列名2 列的类型(长度) 约束）; 12345678列的类型：java sqlint intchar char（固定长度）String varchar（可变长度）长度代表字符的个数 text：主要用来存放文本 blob：存放的是二进制 1234列的约束： 主键约束：primary key 唯一约束：unique 非空约束：not null 12345create table student( sid int primary key, sname varchar(10), sex int, age int); 查看所有表： 1show tables; 查看表的定义： 1show create table 表名; 查看表结构： 1desc 表名; 修改表： 123456789101112- 添加列（add）：alter table 表名 add 列名 列的类型 列的约束;alter table student add greade int not null;- 修改列（modify）：alter table 表名 modify sex varchar（2）;- 修改列名（change）：alter table 表名 change sex gender varchar（2）;- 删除列（drop）alter table 表名 drop greade; 修改表名（rename） 1rename table student to 新表名; 修改表的字符集 1alter table 表名 character set 字符集; 删除表 1drop table 表名; Sql完成对表中数据的CRUD操作 插入数据 1234567891011121314insert into 表名（列名1，列名2，列名3）values(值1，值2，值3);如：insert into student(sid,sname,sex,age)values(1,'zhangsan',1,23);简单写法：插入的是全列名的数据，表名后面的列名可以省略insert into 表名values(值1，值2，值3);如:insert into student values(1,'zhangsan',1,23);如果插入的是部分数据，列名不能省略如：insert into student(sid,sname,sex)values(1,'zhangsan',1);批量插入：效率比单条插入效率高。但不能出错insert into student values(1,'zhangsan',1，23), (2,'lisi',0，22), (3,'wangwu',1，24); 查看表中数据 1select * from student; 表中插入数据中文乱码问题 12341.暂停Mysql服务2.在Mysql安装路径中找到my.ini配置文件3.将57行的编码改成GBK。4.保存，退出，启动mysql服务 删除记录 123delete from 表名[where 条件]delete from student where sid=10;delete from student; 如果没有指定条件，会将表中数据一条一条全部删除掉。 面试问题： 1234567请说一下delete 删除数据和truncate删除数据有什么差别？答：delete：属于DML数据操纵语言，一条一条删除表中的数据。 truncate：属于DDL数据定义语言，先删除表，在重建表。 关于那条执行效率高：具体要看表中的数据量。 如果数据比较少，delete比较高效。 如果数据比较多，truncate比较高效。 更新表记录 12345update 表名 set 列名=列的值，列名2=列的值2 [where 条件]需求：将sid为5的名字改成李四update student set sname='李四' where sid=5;//如果参数是字符串或者日期，要加上单引号 select查询的简单查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647select [distinct] [ * ] [列名，列名2] from 表名 [where 条件]distinct：去除重复的数据--简单商品：手机数码，鞋靴箱包1.分类的ID2.分类名称3.分类描述//创建表create table category( cid int primary key auto_increment, cname varchar(10), cdesc varchar(31) );//插入数据 insert into category values(null,'手机数码','电子产品');insert into category values(null,'鞋靴箱包','江南皮鞋厂');insert into category values(null,'香烟酒水','黄鹤楼');insert into category values(null,'酸奶饼干','安慕希');insert into category values(null,'家用电器','美的空调');--所有商品1.商品ID2.商品名称3.商品价格4，生产日期5，商品分类ID//创建表create table product( pid int primary key auto_increment, pname varchar(10), price double, pdate timestamp, cno int );//插入数据insert into product values(null,'xiaomi',998,null,1);insert into product values(null,'chuizi',2998,null,1);insert into product values(null,'nike',888,null,2);insert into product values(null,'laocunzhang',88,null,3);insert into product values(null,'jingjiu',32,null,3);insert into product values(null,'xiaoxiong',3,null,4);insert into product values(null,'weilong',0.5,null,5);insert into product values(null,'wangwang',0.5,null,5); 简单查询 12345678910111213141516171819202122232425262728293031323334353637381.查询所有的商品：select * from product;2.查询商品名称和商品价格select pname,price from product;3.别名查询，as 的关键字 ，as关键字可以省略 -表别名：select p.pname,p.price,from product p;(主要用在多表查询) select p.pname,p.price from product as p; -列别名：select pname as 商品名称,price as 商品价格 from product; select pname as 商品名称,price as 商品价格 from product;4.去掉重复的值 -查询商品所有的价格 select distinct price from product;5.select运算查询 select *,price*1.5 as 折后价 from product; 6.条件查询[where关键字] 指定条件，确定要操作的记录 -查询商品价格大于60元的所有商品信息 select * from product where price&gt;60;7.where 后的条件写法 -关系运算符：&gt; &gt;= &lt; &lt;= = != &lt;&gt; &lt;&gt; : 不等于 ：标准SQL语法 != : 不等于 ：非标准SQL语法 -查询商品价格不等于88的所有商品 select * from product where price &lt;&gt; 88; select * from product where price != 88; -查询商品价格在10到100之间的商品 select * from product where price&lt;100 and price &gt;10; select * from product where price between 10 and 100; -逻辑运算：and or not -查询出商品价格 小于100 或者大于900 select * from product where price &lt;100 or price &gt;900; 复杂查询 123456789101112131415161718192021222324252627282930313233341.like :模糊查询 _ ：代表的是一个字符 % ：代表的是多个字符 in：在某个范围内获得值 -查询出名字中带有饼的所有商品 ‘%饼%’ select * from product where pname like '%饼%'; -查询第二名字是熊的所有商品 '_熊%' select * from product where pname like '_熊%'; -查询出商品分类ID在1，4，5里面的所有商品 select * from product where cno in (1,4,5);2.排序查询: order by 关键字 asc: ascend 升序（默认的排序方式） desc： descend 降序 -查询所有商品，按照降序排序 select * from product order by price desc; -查询名称有“小”的商品，按照升序排序 select * from product where pname like '%小%' order by price asc;3.聚合函数： -获得所有商品价格总和： select sum(price) from product; -获得所有商品价格平均值： select avg(price) from product; -获得所有商品的个数： select count(*) from product;4.分组：group by -根据cno字段分组，分组后统计商品的个数 select cno,count(*) from product group by cno; -根据cno字段分组，分组后统计商品的平均价格，并且商品平均价格 &gt;60 select cno,avg(price) from product group by cno having avg(price) &gt;60; -having 关键字，他可以接聚合函数的， 出现在分组之后 -where 关键字，他不可以接聚合函数，出现在分组之前 补充： 123456编写顺序：S..F..W..G..H..Oselect..from..where..group by..having..drder by执行顺序：F..W..G..H..S..Ofrom..where..group by..having..select..drder by","link":"/81592902/"},{"title":"JavaSE---集合","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为什么要用集合？因为以前用数组存储数据，因为创建数组的时候就要初始化数组的长度，由于这个长度是不可变的，这就导致两个问题：定义数组长度值太大，实际用不了那么多，就会造成内存的浪费，那定义的太小了，不够用了又得扩容，这就得不偿失了，所以这个时候，集合横空出世，相当于一个没有上限的盒子，数据直接丢进去。 集合框架 它有什么好处？ 集合包括了各种常用的数据结构：List表，Set集合，Map映射等等。 封装成了一个工具类，使用者不必了解底层实现，方便使用。 从JavaSE5.0，使用了泛型，这样集合中对象的数据类型就可以被记住，使用者不用担心，把对象丢进集合中，就丢失了他的数据类型。 特点在哪里？ java集合框架采用接口与实现相分离（就是面向接口编程的理念）。图中最底层的都是实现类，其他的都是接口，实现了接口中的方法，可以直接拿来用 java的集合中只能存储对象，而不能存储基本数据类型。 根据Colletion和Map框架，可以将集合分为三大类： list集合 有序集合 元素可以重复 set集合 无序集合 元素不可以重复 Map集合 键值对集合 key是无序集合Set，value是有序集合List Collection集合 通过分析源码，可以看到collection集合继承了Iterable接口，这里注意是Iterable而不是Iterator。 迭代器iterator 查看Iterable接口源码：可以看到有iterator这个方法，还有一个forEach（）方法，也就是我们所说的增强for循环，这也是javaSE5.0以后，for循环一种优雅的写法。 如上面所看到的，iterable接口里面，还有一个Iterator接口，点进去是这样的：这里面的方法就是日常所用到的：hasNext()，next()，remove()方法。 iterator迭代器怎么用？说到底，迭代器的作用就是遍历集合而已。 123456789101112Collection c = new ArrayList();//向ArrayList中添加元素c.add(\"DAQ\");c.add(\"LOVE\");c.add(\"WT\");//获取到迭代器Iterator it = c.iterator();//遍历集合while(it.hasNext()){ String element=(String)it.next(); System.Out.Println(element);} List集合 List是线性表结构，包括顺序表Arraylist和链表LinkedList两种实现方式 Arraylist 底层数据结构是数组，线程不安全可以存放null值。因为它有扩容这一概念，可以实现动态增长，就不像原本的数组那样，长度固定不变了。 ArrayList是基于动态数组实现的，在增删的时候，需要数组的拷贝复制。 ArrayList的默认容量是10，每次扩容的时候，变为原来的1.5倍，也就是15 删除元素的时候，容量不会减少，需要减少容量的时候，要调用trimToSize（）方法。 缺点： 从空间分配来看，除非预知数据的确切量或者近似值，否则频繁的扩容，或者大的容量初始值都会导致时间空间的浪费。 从运算时间来看，插入和删除的效率非常低。LinkedList 底层数据结构是双向链表，采用“按需分配”的原则为每个对象分配独立的存储空间，但是线程不安全。 LinkedList还实现了Deque接口，我们就可以像操作栈和队列一样操作LinkedList了。 只要有了头结点，其他的数据都可以轻松获取。 总结： 增删多用LinkedList，查询多用ArrayList。 Set集合 相比list集合而言，Set看起来清爽多了。 Set实现类依赖添加对象的equals（）方法检查对象的唯一性，只要两个对象使用equals比较结果为true，set就会拒绝加入此对象（哪怕他们是不同的对象），只要两个对象使用equals比较结果为false，set就会接受加入此对象（哪怕他们是相同的对象），所以在使用set时，重点就要重写equals（）方法，制定正规的比较规则。 HsahSet 可以看出HashSet就是封装了HashMap，操作HashSet实际上就是在操作HashMap 总结下来就是： 实现了Set接口，底层实际是一个HashMap实例 不保证迭代顺序，允许元素为null 非同步 初始容量影响迭代性能 TreeSet 总结： 实现了NavigableSet接口，底层实际是一个TreeMap实例 可以实现排序功能 非同步 LinkedHashSet 归纳： 迭代是有序的 允许为null 底层实际上是一个HashMap+双链表实例 非同步 与hashset相比，性能稍微差一点，因为要维护双链表 初始容量与迭代无关，LinkedHashSet迭代的是双链表 Vector集合 底层是数组，线程安全 从源码中看出，他给每个方法都加上了synchronized锁，这样很消耗性能。 而且Vector初始长度是10，超过这个长度的时候，翻倍增长。这就比ArrayList更加消耗内存。 Map集合 为什么需要map？map在java模型中称为映射，只要知道键值，就可以获取数据值。将键映射到值的对象，一个映射不能包含重复的键，每个键只能映射到一个值。 Map与Collection的区别： Map集合存储元素是成对出现的，Map的键是唯一的，值是可以重复的。 Collection集合存储元素是单独出现的，set是唯一，list是可重复的。 Map数据结构针对键有效，跟值无关 Collection数据结构针对元素有效 Map的功能 散列表工作原理 散列表根据每个对象计算出一个整数，称之为散列码。根据计算出来的散列码，保存在对应的位置上。 在java中，散列表用链表数组实现，每个链表称为桶。 很可能有很多元素算出来的hash值（散列码）相同，这就会存储在同一个位置上，这种情况就叫做哈希冲突（散列冲突）。 但也不可能无限制装下去，在JDK1.8中，桶满时，链表会变成平衡二叉树，也就是所说的红黑树。 HashMap 在另一篇文章中我有单独将HashMap拿出来分析，并且分为了JDK1.7和JDK1.8时的HashMap的结构，HashMap源码分析 TreeMap 根据源码前的注释可以得出总结: TreeMap实现了NavigableMap接口，而NavigableMap接口继承SortedMap接口，这就导致TreeMap是有序的。 TreeMap底层是红黑树，时间复杂度是log(n) 非同步的 使用Comparator和Comparable来比较Key是否相等，与排序的问题。","link":"/%E9%9B%86%E5%90%88/"},{"title":"TCP三次握手和四次挥手","text":"TCP位于传输层，作用是提供可靠的字节流服务，为了准确无误地将数据送达目的地，TCP协议采纳三次握手策略来建立连接。通过四次挥手来释放连接。 用wireshark抓包分析一次连接的报文信息 这是tcp报文的数据包格式。 序列号seq： 占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack： 占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。 确认ACK： 占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效 同步SYN： 连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。 终止FIN： 用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接 补充： ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。 三次握手过程与作用刚开始客户端处于CLOSE的状态，服务端处于LISTEN状态。第一次握手： 建立连接时，客户端发送SYN包（同时随机生成初始序列号seq=x，并进入SYN_SENT状态，等待服务器确认。 TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。这个三次握手中的开始。表示客户端想要和服务端建立连接。 第二次握手： 服务器收到SYN包，发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己随机初始化一个序列号 seq=y，此时服务器进入SYN_RECV状态。 这个报文也不能携带数据，但是同样要消耗一个序号。这个报文带有SYN(建立连接)和ACK(确认)标志，询问客户端是否准备好。 第三次握手： 客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。 第三次的ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。这里客户端表示我已经准备好。 三次握手的作用 确认双方的接受能力，发送能力是否正常。 指定自己的初始化序列号，为后面的可靠传送做准备。 如果是Https协议的话，三次握手这个过程，还会进行数字证书的验证，以及加密秘钥的生成。 面试常见问题：①（ISN）是固定的吗？ 三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number，初始序列号), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。 如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。 ②什么是半连接队列？ 服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。 补充一点关于SYN-ACK 重传次数的问题： 服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s, 2s, 4s, 8s, …. ③三次握手过程中可以携带数据吗？ 很多人可能会认为三次握手都不能携带数据，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。 假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。 而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。 ④为什么要三次握手呢？有人说两次握手就好了 举例：已失效的连接请求报文段。 客户端发送了第一个连接的请求报文，但是由于网络不好，这个请求没有立即到达服务端，而是在某个网络节点中滞留了，直到某个时间才到达server，本来这已经是一个失效的报文，但是server端接收到这个请求报文后，还是会想client发出确认的报文，表示同意连接。假如不采用三次握手，那么只要server发出确认，新的建立就连接了，但其实这个请求是失效的请求，client是不会理睬server的确认信息，也不会向服务端发送确认的请求，但是server认为新的连接已经建立起来了，并一直等待client发来数据，这样，server的很多资源就没白白浪费掉了，采用三次握手就是为了防止这种情况的发生server会因为收不到确认的报文，就知道client并没有建立连接。这就是三次握手的作用。 四次挥手过程详解第一次挥手： TCP发送一个FIN(结束)，用来关闭客户到服务端的连接。客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 第二次挥手 ​ 服务端收到这个FIN，他发回一个ACK报文 确认收到序号为收到序号+1，和SYN一样，一个FIN将占用一个序号。​ 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。 TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 第三次挥手： ​ 服务端发送一个FIN(结束)到客户端，服务端关闭客户端的连接。服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 第四次挥手： ​ 客户端发送ACK 报文确认，并将确认的序号+1，这样关闭完成。​ 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 面试常问：①为什么是4次挥手呢？ 为了确保数据能够完成传输。关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 ②tcp握手的时候为何ACK(确认)和SYN(建立连接)是一起发送。挥手的时候为什么是分开的时候发送呢？ 因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭 SOCKET，所以只能先回复一个ACK报文，告诉Client端，“你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 ③客户端突然挂掉了怎么办？ 正常连接时，客户端突然挂掉了，如果没有措施处理这种情况，那么就会出现客户端和服务器端出现长时期的空闲。解决办法是在服务器端设置保活计时器，每当服务器收到客户端的消息，就将计时器复位。超时时间通常设置为2小时。若服务器超过2小时没收到客户的信息，他就发送探测报文段。若发送了10个探测报文段，每一个相隔75秒，还没有响应就认为客户端出了故障，因而终止该连接。 SYN洪水攻击背景： 初始化连接的 SYN 超时问题Client发送SYN包给Server后挂了，Server回给Client的SYN-ACK一直没收到Client的ACK确认，这个时候这个连接既没建立起来，也不能算失败。这就需要一个超时时间让Server将这个连接断开，否则这个连接就会一直占用Server的SYN连接队列中的一个位置，大量这样的连接就会将Server的SYN连接队列耗尽。 让正常的连接无法得到处理。 ​ 目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s，TCP才会把断开这个连接。由于，SYN超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称SYN flood攻击)，用于耗尽Server的SYN队列。 什么是 SYN 攻击？ SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS攻击。 如何检测 SYN 攻击？ 检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的netstats 命令来检测 SYN 攻击。 如何防御 SYN 攻击？ ​ SYN攻击不能完全被阻止，除非将TCP协议重新设计。我们所做的是尽可能的减轻SYN攻击的危害，常见的防御 SYN 攻击的方法有如下几种：①缩短超时（SYN Timeout）②时间增加最大半连接数③过滤网关防护SYN④cookies技术","link":"/3524511244/"},{"title":"Tomcat发布项目的三种方式","text":"本文介绍Tomcat发布项目到服务器上的三种方式 一、拷贝这个文件到webapps/ROOT底下， 在浏览器里面访问。1http://localhost:8080/stu.xml 在webaps下面新建一个文件夹xml , 然后拷贝文件放置到这个文件夹中 http://localhost:8080/xml/stu.xml http://localhost:8080 ： 对应的是到webapps/root http://localhost:8080/xml/ : 对应是 webapps/xml 使用IP地址访问：http://本机ip:8080/xml/stu.xml 二、配置虚拟路径 使用localhost：8080 打开tomcat首页， 找到Tomcat 8.5 Documentation,进入Reference，点击configuration ，找到左边的context，点击进入，复制此页面路径： 1http://localhost:8080/docs/config/context.html 在conf/server.xml 找到host元素节点。加入以下内容。 在浏览器地址栏上输入： http://localhost:8080/daq/person.xml 配置虚拟路径2 在tomcat/conf/catalina/localhost/ 文件夹下新建一个xml文件，名字可以自己定义。 person.xml 在这个文件里面写入以下内容 12&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Context docBase=\"F：\\XML2\"&gt;&lt;/Context&gt; 在浏览器上面访问: 1http://localhost:8080/person/xml的名字即可","link":"/2665853047/"},{"title":"Git使用学习","text":"Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。也是程序员最常用工具之一，连接本地仓库与github仓库，提高了开发效率，github也是开源项目宝库。 一、概述原理Git是目前世界上最先进的分布式版本控制工具。 工作原理： 概念： Workspace：工作区 Index/Stage：暂存区 Respository：仓库区（本地仓库） Remote：远程仓库 SVN与Git的区别 SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，有时就得等很久了。 Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 ##二、使用目的 通过git管理github托管项目代码。##三、下载安装 下载地址：https://git-scm.com/download/win##四、Git工作区域 工作区（Working Directory）： 添加、编辑、修改文件。 暂存区 ： 暂存已经修改的文件最后统一提交到git仓库中。 留一个回旋的余地，没改好接着改，改好了再提交到仓库。 Git Repository （Git 仓库）：最终确定的文件保留到仓库，成为一个新的版本，并且对他人可见。 ##五、初始化配置 Git 设置用户名： 1git config --global user.name 'DAQ121' 设置用户名邮箱： 1git config --global user.email '2829025551@qq.com' 查看设置 1git config --list 注意： 该设置在github仓库主页显示谁提交了该文件。 创建相对应的仓库并初始化： 1234mkdir test;//创建仓库cd test;git init;//初始化仓库操作完之后会在test目录下出现一个.git的隐藏文件。 ##六、向仓库中添加文件 在test仓库里新建文件a1.java 12touch a1.java//创建git status //查看 添加到暂存区 1git add a1.java 将文件从暂存区提交到仓库 1git commit -m 'add a1.java' ##七、修改仓库文件 修改后，a1.java 还要add到暂存区中。 然后再从暂存区提交到仓库。 ##八、删除仓库文件 1234561.删除文件rm a1.java2.从Git中删除文件git rm a1.java3.提交操作git commit -m '描述' ##九、Git管理远程仓库 使用远程仓库的目的：作用：备份，实现代码共享集中化管理。 Git克隆操作目的：将远程仓库（github对应的项目）复制到本地 1git clone 仓库地址 将仓库里的内容克隆到本地，在本地修改之后，添加到暂存区，然后在提交到仓库。 将本地仓库同步到git远程仓库 1git push 无法同步，没有权限怎么办？或者想要设置权限，防止乱入 123456vi .git/config将[remote \"origin\"] url = https://github.com/用户名/仓库名.git修改为：[remote \"origin\"] url = https://用户名：密码@github.com/用户名/仓库名.git","link":"/339957974/"},{"title":"MySql安装与卸载","text":"MySql的卸载与安装 安装 运行安装程序，在启动配置教程之前，一路下一步，没有下一步的话就直接finish 第一次finish之后启动服务器配置教程 第一个注意：include mysql bin directory to windows path 第二个注意：端口号不要修改，字符集选择UTF-8 卸载 打开控制面板，删除软件 删除mysql安装目录的所有文件 删除mysql数据存放文件，C盘下面的Programe data里，它是隐藏文件，要点击查看隐藏文件。","link":"/3168578773/"},{"title":"XML学习","text":"XML: extendsible markup labguage 可扩展的标记语言 一、XML的作用？ 可以用来保存数据（数据多的时候用数据库，少量时候用XML） 可以用来做配置文件 数据传输载体 二、XML文档结构_倒状树形结构12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;stus&gt; &lt;stu&gt; &lt;name&gt;daiaoqi&lt;/name&gt; &lt;age&gt;18&lt;/age&gt; &lt;desc&gt;我要学编程&lt;/desc&gt; &lt;/stu&gt; &lt;stu&gt; &lt;name&gt;wt&lt;/name&gt; &lt;age&gt;20&lt;/age&gt; &lt;desc&gt;我要找工作&lt;/desc&gt; &lt;/stu&gt;&lt;/stus&gt; 三、文档定义&amp;声明 定义：其实就是一个文件，文件的后缀为 .xml 声明： 1234&lt;?xml version=\"1.0\" encoding=\"gbk\" standalone=\"no\" ?&gt;version : 解析这个xml的时候，使用什么版本的解析器解析encoding : 解析xml中的文字的时候，使用什么编码来翻译standalone : no：该文档会依赖关联其他文档，yes：这是一个独立的文档 encoding：默认文件保存的时候，使用的是GBK的编码保存。要想让我们的xml能够正常的显示中文，有以下解决办法： 让encoding也是GBK 或者 gb2312 。 如果encoding是 utf-8 ， 那么保存文件的时候也必须使用utf-8。 保存的时候见到的ANSI 对应的其实是我们的本地编码 GBK。 为了通用，建议使用UTF-8编码保存，以及encoding 都是 utf-8。 四、元素定义1.其实就是里面的标签， &lt;&gt; 括起来的都叫元素 。 成对出现。 如下： 1&lt;stu&gt; &lt;/stu&gt; 2.文档声明下来的第一个元素叫做根元素 (根标签)3.标签里面可以嵌套标签4.空标签：既是开始也是结束， 一般配合属性来用。 12345&lt;age/&gt; &lt;stu&gt; &lt;name&gt;张三&lt;/name&gt; &lt;age/&gt; &lt;/stu&gt; 5.标签可以自定义。XML 元素必须遵循以下命名规则： 123451.名称可以含字母、数字以及其他的字符 2.名称不能以数字或者标点符号开始 3.名称不能以字符 “xml”（或者 XML、Xml）开始 4.名称不能包含空格 5.命名尽量简单，做到见名知义 五、元素定义 简单元素：元素里面包含了普通的文字 复杂元素：元素里面还可以嵌套其他的元素 六、属性定义 定义在元素里面， &lt;元素名称 属性名称=”属性的值”&gt;&lt;/元素名称&gt; 12345678910&lt;stus&gt; &lt;stu id=\"10086\"&gt; &lt;name&gt;张三&lt;/name&gt; &lt;age&gt;18&lt;/age&gt; &lt;/stu&gt; &lt;stu id=\"10087\"&gt; &lt;name&gt;李四&lt;/name&gt; &lt;age&gt;28&lt;/age&gt; &lt;/stu&gt;&lt;/stus&gt; 七、xml注释与html的注释一样。 xml的注释，不允许放置在文档的第一行。 必须在文档声明的下面。 12345678&lt;!-- --&gt; 如： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!-- //这里有两个学生 //一个学生，名字叫张三， 年龄18岁， 学号：10086 //另外一个学生叫李四 。。。 --&gt; 八、CDATA区 所有 XML 文档中的文本均会被解析器解析，只有 CDATA 区段（CDATA section）中的文本会被解析器忽略。在 XML 元素中，”&lt;” 和 “&amp;” 是非法的。”&lt;” 会产生错误，因为解析器会把该字符解释为新元素的开始，”&amp;” 也会产生错误，因为解析器会把该字符解释为字符实体的开始。在html中，某些文本，比如 JavaScript 代码，包含大量 “&lt;” 或 “&amp;” 字符。为了避免错误，可以将脚本代码定义为 CDATA。 一般在数据传输的时候会出现，比如说服务器给客户端传数据。 严格地讲，在 XML 中仅有字符 “&lt;”和”&amp;” 是非法的。省略号、引号和大于号是合法的，但是把它们替换为实体引用是个好的习惯。 12&lt; &amp;lt;&amp; &amp;amp; CDATA区写法 1234CDATA区 开始于 \"&lt;![CDATA[\" 结束于 \"]]&gt;\" 如：&lt;des&gt;&lt;![CDATA[&lt;a href=\"http://www.baidu.com\"&gt;我要学编程&lt;/a&gt;]]&gt;&lt;/des&gt; 九、XML解析 其实就是获取元素里面的字符数据或者属性数据。 XML解析方式(面试常问)有很多种，常用的有两种（DOM和SAX）。 针对以上两种解析方式，给出的解决方案有哪些？ jaxp sun公司自带的， 比较繁琐 jdom dom4j （常用）使用比较广泛补充：jdom和dom4j的故事：刚开始都是一伙人做的，后来产生了分歧，另外一批人就做了dom4j，把jdom挤下去了。 十、Dom4j 基本用法 12element.element(\"stu\") : 返回该元素下的第一个stu元素element.elements(); 返回该元素下的所有子元素。 创建SaxReader对象 指定解析的xml 获取根元素。 根据根元素获取子元素或者下面的子孙元素 12345678910111213141516171819202122232425262728293031323334353637383940javapackage com.daq.test;import java.io.File;import java.util.List;import org.dom4j.Document;import org.dom4j.Element;import org.dom4j.io.SAXReader;public class MainTest { /** * @param args */ public static void main(String[] args) { try { //1.创建sax读取对象 SAXReader reader = new SAXReader();//jdbc--classloader //2.指定解析的xml源 Document document=reader.read(new File(\"src/xml/stus.xml\")); //3.得到元素 //得到根元素 Element rootElement=document.getRootElement(); //4.获取根元素下面的子元素age// rootElement.element(\"age\");// System.out.println(rootElement.element(\"stu\").element(\"age\").getStringValue()); List&lt;Element&gt; elements=rootElement.elements(); //遍历所有的stu元素 for (Element element : elements) { //获取stu下面的name元素 String name=element.element(\"name\").getText(); String age=element.element(\"age\").getText(); String adress=element.element(\"adress\").getText(); System.out.println(\"name=\"+name+\"age=\"+age+\"adress=\"+adress); } } catch (Exception e) { e.printStackTrace(); } }} 十一、Dom4j 的 Xpath使用 dom4j里面支持Xpath的写法。 xpath其实是xml的路径语言，支持我们在解析xml的时候，能够快速的定位到具体的某一个元素。 添加jar包依赖 ：jaxen-1.1-beta-6.jar 在查找指定节点的时候，根据XPath语法规则来查找 后续的代码与以前的解析代码一样。 1234567891011//要想使用Xpath， 还得添加支持的jar 获取的是第一个 只返回一个。 Element nameElement = (Element) rootElement.selectSingleNode(\"//name\"); System.out.println(nameElement.getText()); System.out.println(\"----------------\"); //获取文档里面的所有name元素 List&lt;Element&gt; list = rootElement.selectNodes(\"//name\"); for (Element element : list) { System.out.println(element.getText()); } 十二、XML 约束（了解即可）如下的文档， 属性的ID值是一样的。 这在生活中是不可能出现的。 并且第二个学生的姓名有好几个。 一般也很少。那么怎么规定ID的值唯一， 或者是元素只能出现一次，不能出现多次？ 甚至是规定里面只能出现具体的元素名字。 1234567891011121314&lt;stus&gt; &lt;stu id=\"10086\"&gt; &lt;name&gt;张三&lt;/name&gt; &lt;age&gt;18&lt;/age&gt; &lt;address&gt;深圳&lt;/address&gt; &lt;/stu&gt; &lt;stu id=\"10086\"&gt; &lt;name&gt;李四&lt;/name&gt; &lt;name&gt;李五&lt;/name&gt; &lt;name&gt;李六&lt;/name&gt; &lt;age&gt;28&lt;/age&gt; &lt;address&gt;北京&lt;/address&gt; &lt;/stu&gt;&lt;/stus&gt; 约束： DTD：语法自成一派， 早前就出现的。 可读性比较差。 Schema：其实就是一个xml ， 使用xml的语法规则， xml解析器解析起来比较方便 ， 是为了替代DTD 。但是Schema 约束文本内容比DTD的内容还要多。 所以目前也没有真正意义上的替代DTD","link":"/4122240603/"},{"title":"linux启动过程和目录结构","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;安装好了linux系统之后，第一步当然要对linux有一个基本的了解，它有哪些特点，应用场景有哪些，为什么要用linux，了解了这些，然后在作具体深入的命令行操作。 目录结构 bin：存放二进制可执行文件 sbin：存放二进制可执行文件，只有root才可以访问。 etc：存放系统配置文件 usr：用于存放共享的系统资源 home：存放用户文件的根目录 root：超级用户目录 dev：用于存放设备文件 lib：存放跟文件系统中的程序运行所需要的共享库以及内核模块 mnt：系统管理员安装临时文件的安装点 boot：存放用于系统引导时使用的各种文件 tmp：用于存放各种临时文件 var：用于存放运行时需要改变数据的文件 启动过程 BIOS自检 启动GRUB 2 加载内核 执行systemd进程 初始化系统环境 linux和windows的区别？从使用情况来看： windows比较倾向于给非专业办公人士用，图形化界面使办公更方便。linux面向开发人员。 windows平台：数量和质量的优势，不过大部分为收费软件；由微软官方提供重要支持和服务 linux平台：大都为开源自由软件，用户可以修改定制和再发布，由于基本免费没有资金支持，部分软件质量和体验欠缺；有全球所有的Linux开发者和自由软件社区提供支持。 从安全性上来看： Windows平台：三天两头打补丁安装系统安全更新，还是会中病毒木马什么的，各位用户自己感受。 Linux平台：要说linux没有安全问题，那当然是不可能的，不会中病毒什么的，也不可能，这一点仁者见仁智者见智，相对来说肯定比Windows平台要更加安全，使用linux你也不用装杀毒软件了。 linux的特点是什么？ 稳定的系统 ：安装Linux的主机连续运行一年以上不曾宕机、不必关机是很平常的事。 安全性和漏洞的快速修补 ：Linux是开发人员在使用，所以维护者众多，更新维护很快。 多任务，多用户 ：你可以在一个Linux主机上规划出不同等级的用户，而且每个用户登录系统时工作环境可以不同，还可以允许不同用户在同一时间登陆主机以使用主机的资源。 相对较少的系统资源占用 ：这是最吸引眼球的地方，目前市面上任何一款个人计算机都可以达到使用Linux搭建一个服务上百人以上的主机。 模块化程度高：Linux的内核设计非常精巧，分成进程调度、内存管理、进程间通信、虚拟文件系统和网络接口五大部分;其独特的模块机制可根据用户的需要，实时地将某些模块插入或从内核中移走，使得Linux系统内核可以裁剪得非常小巧，很适合于嵌入式系统的需要。 linux可以做什么？ linux简直太适合不过做服务器了，百分之95的服务器都是基于linux平台的，我自己也有一台云服务器，搭载的就是centOS7系统，目前这个博客网站就是运行在这台云服务器上的，它可以保证一年不关机，不宕机。 当然，除此之外，作为开发人员的开发工具也是很常见的。","link":"/3247955720/"},{"title":"git命令大全","text":"git分布式版本控制工具，在日常的开发中起到了非常重要的作用，掌握一些基本的命令也对工作效率的提高有很大的帮助，下面介绍一些基本的git操作。 一、配置相关 配置全局帐户，该账户对所有git仓库都有效 12git config --global user.name '你的账户名称'git config --global user.email '你的email' 配置局部账户，该账户只对当前Git仓库有效 12git config --local user.name '你的账户名称'git config --local user.email '你的email' 查看配置情况 12git config --global --listgit config --local --list 二、本地操作基础操作1.查看变更情况 1git status 2.查看当前工作在那个分支上 1git branch -v 3.切换到指定分支 1git checkout 指定分支名称 4.把当前目录及子目录下所有变更都加入到暂存区 1git add . 5.把仓库内所有变更都加入到暂存区 1git add -A 6.把指定文件添加到暂存区 1git add 文件1 文件2 ... 文件n 7.创建正式的commit，也就是把当前更改提交，并附加描述 1git commit -m \"本次提交的描述\" 比较差异1.比较某文件工作区和暂存区的差异 1git diff 某文件 2.比较某文件暂存区和HEAD的差异 1git diff --cache 某文件 3.比较工作区和暂存区的所欲差异 1git diff 4.比较暂存区和HEAD的所有差异 1git diff --cache 暂存区与工作区之间回滚1.把工作区指定文件恢复和暂存区一样 1git checkout 文件1 文件2... 文件n 2.把暂存区指定文件恢复和HEAD一样 1git reset 文件1 文件2 ... 文件n 3.把暂存区和工作区所有文件恢复和HEAD一样 1git reaet --head 4.用difftool比较两个commit的差异 1git difftool commit1 commit2 5.查看哪些文件没有被git管控 1git ls-files --others 6.补充：从工作区回滚到暂存区用checkout， 否则用reset 三、 加塞临时任务处理1.把未处理完的变更先保存到stash中 1git stash 2.临时任务处理处理完之后继续之前的工作 123git stash pop //pop相当于出栈和入栈一样，把之前的任务弹出来或者git stash apply //与pop不同的是，apply相当于从栈顶把任务取出来，但是不会从栈中把任务移除 3.查看所有stash的变更 1git stash list 4.取回某次stash的变更 1git stash pop stash @｛n｝ 四、修改个人分支历史 仓库在每次变更执行commit的时候，会生成一个新的commit，有时候不想生成新的，只是修改一下之前的，该如何操作呢？ 1.修改最后一次commit 123在工作区中修改文件 git addgit commit --amend 2.修改第（N）次的commit 1234git rebase -i N前面一个commit的id在工作区修改文件git addgit rebase --contiue 五、查看变更日志1.当前分支的各个commit 1git log --online 2.显示最近n个commit 1git log -n 3.用图示显示所有的历史分支 1git log --online --graph --all 4.查看涉及到某文件变更的所有commit 1git log 某文件 5.某文件各行最后修改对应的commit以及作者 1git blame 文件名 六、分支与标签①创建新分支1.基于当前分支创建新分支 1git branch 新分支 2.基于指定分支创建新分支 1git branch 新分支 已有分支 3.基于某个commit创建分支 1git branch 新分支 某个commit 的id 4.创建分支并切换到该分支 1git cheakout -b 新分支 ②列出分支1.列出本地分支 1git branch -v 2.列出本地和远端分支 1git branch -av 3.列出远端所有分支 1git branch -rv 4.列出名称符合某样式的远端分支 1git branch -rv -l '某样式' ③删除分支1.安全删除本地分支 1git branch -d 要删除的分支 2.强制删除本地分支 1git branch -D 分支 3.删除已经合并到master分支的所有本地分支 1git branch --merged master | grep -v '^\\*\\| master' | xargs -n 1 git branch -d 4.删除远端origin已不存在的所有本地分支 1git remote prune origin 5.打标签：从commit上打标签 1git tag 标签名 commit 的id 七、两分支之间的集成1.把A分支合入到当前分支，且为merge创建commit 1git merge A分支 2.把A分支和入到B分支，且为Merge创建commit 1git merge A分支 B分支 3.把当前分支基于B分支作为rebase，以便B分支合入到当前分支 1git rebase B分支 4.把A分支基于B分支做rebase，以便B分支合入到A分支 1git rebase B分支 A分支 八、和远端交互1.列出所有的remote 1git remote -v 2.增加remote 1git remote add URL地址 3.删除remote 1git remote remove remote的名称 4.改变remote的名称 1git remote rname 旧名称 新名称 5.把远端所有分支和标签的变更都拉到本地 1git fetch remote 6.把远端分支变更拉到本地，且merge到本地分支 1git pull remote名称 分支名 7.把本地分支push到远端 1git push remote名称 分支名 8.删除远端分支 123git push remote --delete 远端分支名或者git push remote：远端分支名 9.向远端提交指定标签 1git push remote 标签名 10.向远端提交所有标签 1git push remote --tags","link":"/2557304751/"},{"title":"MySql多表操作","text":"问： 分类表和商品表之间是不是有关系? 如果有关系,在数据库中如何表示这种关系？ 创建多表及多表的关系 问： 分类表和商品表之间是不是有关系? 如果有关系,在数据库中如何表示这种关系？ 123456789101112131415161718192021222324252627282930313233343536373839create table category( cid int primary key auto_increment, cname varchar(10), cdesc varchar(31));insert into category values(null,'手机数码','电子产品,黑马生产');insert into category values(null,'鞋靴箱包','江南皮鞋厂倾情打造');insert into category values(null,'香烟酒水','黄鹤楼,茅台,二锅头');insert into category values(null,'酸奶饼干','娃哈哈,蒙牛酸酸乳');insert into category values(null,'馋嘴零食','瓜子花生,八宝粥,辣条');select * from category;select cname,cdesc from category;--所有商品1.商品ID2.商品名称3.商品的价格4.生产日期5.商品分类ID商品和商品分类 : 所属关系create table product( pid int primary key auto_increment, pname varchar(10), price double, pdate timestamp, cno int);insert into product values(null,'小米mix4',998,null,1);insert into product values(null,'锤子',2888,null,1);insert into product values(null,'阿迪王',99,null,2);insert into product values(null,'老村长',88,null,3);insert into product values(null,'劲酒',35,null,3);insert into product values(null,'小熊饼干',1,null,4);insert into product values(null,'卫龙辣条',1,null,5);insert into product values(null,'旺旺大饼',1,null,5); 多表之间的关系如何来维护 1234567外键约束: foreign key -给product中的cno 添加一个外键约束 alter table product add foreign key(cno) references category(cid); -从分类表中,删除分类为5信息 delete from category where cid =5; //删除失败, 首先得去product表, 删除所有分类ID5 商品 delete from product where cno=5; 建数据库原则: 通常情况下,一个项目/应用建一个数据库 多表之间的建表原则 123456789101112131415161. 一对多 : 商品和分类 建表原则: 在多的一方添加一个外键,指向一的一方的主键2.多对多: 老师和学生, 学生和课程 建表原则: 建立一张中间表,将多对多的关系,拆分成一对多的关系,中间表至少要有两个外键,分别指向原来的那两张表。3.一对一: 班级和班长, 公民和身份证, 国家和国旗 建表原则: - 将一对一的情况,当作是一对多情况处理,在任意一张表添加一个外键,并且这个外键要唯一,指向另外一张表 - 直接将两张表合并成一张表 - 将两张表的主键建立起连接,让两张表里面主键相等4.实际用途: 用的不是很多. (拆表操作 ) 如：相亲网站: - 个人信息 : 姓名,性别,年龄,身高,体重,三围,兴趣爱好,(年收入, 特长,学历, 职业, 择偶目标,要求) - 拆表操作 : 将个人的常用信息和不常用信息,减少表的臃肿, 网上商城表案例分析：用户购物流程 商品分类表(分类ID,分类名称,分类描述 1234567891011create table category( cid int primary key auto_increment, cname varchar(15), cdesc varchar(100) ); insert into category values(null,'手机数码','电子产品,黑马生产'); insert into category values(null,'鞋靴箱包','江南皮鞋厂倾情打造'); insert into category values(null,'香烟酒水','黄鹤楼,茅台,二锅头'); insert into category values(null,'酸奶饼干','娃哈哈,蒙牛酸酸乳'); insert into category values(null,'馋嘴零食','瓜子花生,八宝粥,辣条'); 商品表 (商品ID, 商品名称,商品价格,外键cno) 12345678910111213141516create table product( pid int primary key auto_increment, pname varchar(10), price double, cno int, foreign key(cno) references category(cid) ); insert into product values(null,'小米mix4',998,1); insert into product values(null,'锤子',2888,1); insert into product values(null,'阿迪王',99,2); insert into product values(null,'老村长',88,3); insert into product values(null,'劲酒',35,3); insert into product values(null,'小熊饼干',1,4); insert into product values(null,'卫龙辣条',1,5); insert into product values(null,'旺旺大饼',1,5); 用户表 12345678create table user( uid int primary key auto_increment, username varchar(31), password varchar(31), phone varchar(11) ); insert into user values(1,'zhangsan','123','13811118888'); 订单表 (订单编号,总价,订单时间 ,地址,外键用户的ID) 12345678910create table orders( oid int primary key auto_increment, sum int not null, otime timestamp, address varchar(100), uno int, foreign key(uno) references user(uid) ); insert into orders values(1,200,null,'学校',1); insert into orders values(2,250,null,'家里',1); 订单项: 中间表(订单ID,商品ID,商品数量,订单项总价) 123456789101112131415create table orderitem( ono int, pno int, foreign key(ono) references orders(oid), foreign key(pno) references product(pid), ocount int, subsum double ); --给1号订单添加商品 200块钱的商品 insert into orderitem values(1,7,100,100); insert into orderitem values(1,8,101,100); --给2号订单添加商品 250块钱的商品 () insert into orderitem values(2,5,1,35); insert into orderitem values(2,3,3,99); 内连接查询 1234567-隐式内连接 select * from product p,category c where p.cno=c.cid;-显式内连接 select * from product p inner join category c on p.cno=c.cid;-区别： 隐式内连接：在查询出结果的基础上去做where 条件过滤 显式内连接：带着条件去查询结果，执行效率高。 连接查询左外连接：会将左表中的所有数据都查询出来，如果右表中没有对应的数据，用NULL代替。右外连接：会将右表中的所有数据查询出来如果左表没有对应数据的话 分页查询每页数据数据3，起始索引从0 ，第1页: 0，第2页: 3。起始索引: index 代表显示第几页 页数从1开始，每页显示3条数据 1startIndex = (index-1)*3 第一个参数是索引第二个参数显示的个数 12select * from product limit 0,3;select * from product limit 3,3; 子查询 sql的嵌套：查询语句里面嵌套查询语句","link":"/1663071716/"},{"title":"Servlet学习笔记","text":"java Web离不开Servlet，它其实就是一个java程序，运行在我们的web服务器上，用于接收和响应 客户端的http请求。 一、Web资源介绍 在http协议当中，规定了请求和响应双方， 客户端和服务器端。与web相关的资源。 有两种分类： 静态资源：html 、 js、 css 动态资源：servlet/jsp 二、Servlet介绍 servlet是什么? 其实就是一个java程序，运行在我们的web服务器上，用于接收和响应 客户端的http请求。 更多的是配合动态资源来做。 当然静态资源也需要使用到servlet，只不过是Tomcat里面已经定义好了一个 DefaultServlet 三、Selvlet简单使用Web工程 得写一个Web工程 ， 要有一个服务器。 测试运行Web工程： 1234567891011121314151617181920得写一个Web工程 ， 要有一个服务器。测试运行Web工程 1. 新建一个类， 实现Servlet接口`public class HelloServlet implements Servlet{}` 2. 配置Servlet ， 用意： 告诉服务器，我们的应用有这么些个servlet。 在webContent/WEB-INF/web.xml里面写上以下内容： &lt;!-- 向tomcat报告， 我这个应用里面有这个servlet， 名字叫做HelloServlet , 具体的路径是com.itheima.servlet.HelloServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.itheima.servlet.HelloServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!-- 注册servlet的映射。 servletName : 找到上面注册的具体servlet， url-pattern: 在地址栏上的path 一定要以/打头 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/a&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 3. 在地址栏上输入 http://localhost:8080/项目名称/a 四、Servlet执行过程 五、Servlet的通用写法 实现Servlet接口，但接口里的方法很多，有些用不到。 Servlet (接口) GenericServlet HttpServlet （用于处理http的请求） 定义一个类，继承HttpServlet ,复写doGet 和 doPost 六、Servlet的生命周期方法 生命周期： 从创建到销毁的一段时间 生命周期方法： 从创建到销毁，所调用的那些方法。 1234567891011121314151617181920212223242526272829301. init方法 在创建该servlet的实例时，就执行该方法。 一个servlet只会初始化一次， init方法只会执行一次 默认情况下是 ： 初次访问该servlet，才会创建实例。 2.service方法 只要客户端来了一个请求，那么就执行这个方法了。 该方法可以被执行很多次。 一次请求，对应一次service方法的调用 3.destroy方法 servlet销毁的时候，就会执行该方法 1. 该项目从tomcat的里面移除。 2. 正常关闭tomcat就会执行 shutdown.bat4. doGet 和 doPost不算生命周期方法。所谓的生命周期方法是指，从对象的创建到销毁一定会执行的方法， 但是这两个方法，不一定会执行。``` ## 七、让Servlet创建实例的时机提前。1. 默认情况下，只有在初次访问servlet的时候，才会执行init方法。 有的时候，我们可能需要在这个方法里面执行一些初始化工作，甚至是做一些比较耗时的逻辑。 2. 那么这个时候，初次访问，可能会在init方法中逗留太久的时间。 为了提升用户的体验，需要让这个初始化的时机提前一点。 3. 在配置的时候， 使用load-on-startup元素来指定， 给定的数字越小，启动的时机就越早。 一般不写负数， 从2开始即可。 ```java&lt;servlet&gt; &lt;servlet-name&gt;HelloServlet04&lt;/servlet-name&gt; &lt;servlet-class&gt;com.itheima.servlet.HelloServlet04&lt;/servlet-class&gt; &lt;load-on-startup&gt;2&lt;/load-on-startup&gt;&lt;/servlet&gt; 八、ServletConfig Servlet的配置，通过这个对象，可以获取servlet在配置的时候一些信息。 12345678910111213141516171819//1. 得到servlet配置对象 专门用于在配置servlet的信息ServletConfig config = getServletConfig(); //获取到的是配置servlet里面servlet-name 的文本内容String servletName = config.getServletName();System.out.println(\"servletName=\"+servletName); //2. 可以获取具体的某一个参数。 String address = config.getInitParameter(\"address\");System.out.println(\"address=\"+address);//3.获取所有的参数名称Enumeration&lt;String&gt; names = config.getInitParameterNames();//遍历取出所有的参数名称while (names.hasMoreElements()) { String key = (String) names.nextElement(); String value = config.getInitParameter(key); System.out.println(\"key===\"+key + \" value=\"+value); } 参数在哪里配置？在web.xml中 123456789101112131415&lt;servlet&gt; &lt;servlet-name&gt;aa&lt;/servlet-name&gt; &lt;servlet-class&gt;com.daq.servlet.HelloServletConfig&lt;/servlet-class&gt; &lt;!-- 可以添加初始化参数 --&gt; &lt;init-param&gt; &lt;param-name&gt;adress&lt;/param-name&gt; &lt;param-value&gt;bejing&lt;/param-value&gt; &lt;/init-param&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet02&lt;/servlet-name&gt; &lt;url-pattern&gt;/HelloServlet02&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 九、为什么需要有ServletConfig？ 未来我们自己开发的一些应用，使用到了一些技术，或者一些代码，我们不会。 但是有人写出来了。做成了jar包，它的代码放置在了自己的servlet类里面。 刚好这个servlet 里面需要一个数字或者叫做变量值。 但是这个值不能是固定了。 所以要求使用到这个servlet的公司，在注册servlet的时候，必须要在web.xml里面，声明init-params 在开发当中比较少用。","link":"/441652674/"},{"title":"linux安装常用环境","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;手里有一台免费的阿里云服务器是真的很香，但是我也不能让他就这样只放一个博客网站吧，于是乎，我想在这片几乎空白的区域，开拓出一块儿良好的开发环境，也顺便熟悉一下linux系统的操作。这篇主要就是讲了，如何在云服务器上安装JDK，MySql，Tomcat 一、安装JDK1.8①查看有无自带的JDK 有很多linux系统自带了OpenJDK，OpenJDK不包含Deployment（部署）功能，源代码不完整，而且精简化，只适合个人使用。 123456781. 查看有无jdk，如果有，则会出现openjdkjava -version2.查看关于java的所有文件rpm -qa | grep java3. 删除掉openjdk（后面跟你自己的版本进行删除）rpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64 ②下载JDK 去ORACLE官网下载对应的linux版本。记得后缀是.tar.gz结尾。先下载到本地，再通过工具上传到linux上。这里推荐使用的工具是finalshell。详情使用请另参考。 ③安装JDK 在usr/local/src目录下新建一个文件夹jdk 1mkdir /usr/local/src/jdk 将本地JDK上传到这个目录下。 进入文件夹，并解压 12cd /usr/local/src/jdktar zvxf 你的压缩包 安装完成 ④配置环境变量 进入环境变量的配置文件,编辑 1vim /etc/profile 在最下面添加以下代码： 1234export JAVA_HOME=/usr/local/src/jdk/jdk1.8.0_161 （这里填写你自己的文件路径）export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 编写完之后：ESC-&gt;:wq退出。 查看是否安装成功 1java -version 二、安装Tomcat①下载tomcat我下载的是Tomcat8.5，和安装JDK几乎一样的步骤，点击下载对应的版本。 ②上传，解压 新建存放目录 1mkdir /usr/local/src/Tomcat 用工具上传到该目录中。 解压 12cd //usr/local/src/Tomcattar zvxf 你的安装包 ③配置环境变量 修改/etc/profile，加入Tomcat环境变量 1234567891.vim /etc/profile2.加入以下代码：export CATALINA_HOME=你的tomcat路径export PATH=$PATH:${CATALINA_HOME}/bin3.刷新环境变量source /etc/profile ④启动tomcat12cd /usr/local/src/Tomcat/apache-tomcat-8.5.53/binsh start.sh 查看端口号和日志 123451.查看端口号ss -tan2.查看日志tail -f ../logs/catalina.out 三、安装Mysql①查看自带版本 查看有没有mysql，有则卸载。 12341. 查看rpm -qa | grep mysql2. 卸载rpm -e --nodeps 查出来的mysql ②命令下载mysql 如果直接去官网下载，不知道要等多久，于是我找到了一个镜像网站，点击找到你的对应版本，这里以mysql-5.6.44-linux-glibc2.12-x86_64.tar.gz为例 命令安装：既然找到了具体网址，那我们就用wget命令安装，省去上传的时间。 1wget http://mirrors.sohu.com/mysql/MySQL-5.6/mysql-5.6.44-linux-glibc2.12-x86_64.tar.gz 解压 1tar -zxvf mysql-5.6.44-linux-glibc2.12-x86_64.tar.gz 创建mysql用户组及用户 12groupadd mysqluseradd -r -g mysql mysql 修改配置文件 12cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnfvi my.cnf 123456789101112131415161718192021[mysqld] #设置3306端口 port = 3306 # 设置mysql的安装目录 根据实际目录进行配置basedir=/usr/local/mysql # 设置mysql数据库的数据的存放目录 根据实际目录进行配置datadir=/usr/local/mysql/data # 允许最大连接数 max_connections=200 # 服务端使用的字符集默认为8比特编码的latin1字符集 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB max_allowed_packet=16M 安装autoconf库，赋权并执行初始化数据库 1yum -y install autoconf 12chown -R mysql.mysql /usr/local/src/mysql5.6/usr/local/src/mysql5.6/scripts/mysql_install_db --verbose --user=mysql --defaults-file=/etc/my.cnf --datadir=/usr/local/src/mysql5.6/data --basedir=/usr/local/src/mysql5.6 ③ 启动msyql：1service mysql start 如果出现以下情况：请按照以下步骤来 1Failed to start mysql.service: Unit not found. 123456781.查询/etc/init.d/下是否存在mysql，一般都没有，如果有的话，记得备份ll /etc/init.d/ | grep mysql2. 到你的mysql安装目录下，查看是否有mysql.serverfind / -name mysql.server3.如果有，把他复制到/etc/init.d/mysqlcp /usr/local/src/mysql5.6/support-files/mysql.server /etc/init.d/mysql 再次启动mysql 1service mysql start 查看mysql运行状态 1service mysql status 配置环境变量 12341.vim ~/.bash_profile添加：export PATH=$PATH:/usr/local/src/mysql5.6/bin2.source ~/.bash_profile ③登录12mysql -u root -p Enter password: 直接回车 -出现如下 123456789101112Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 2Server version: 5.7.29Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; ④修改密码123set password for root@localhost = password('new password');;new password替换成你要设置的密码注意:密码设置必须要大小写字母数字和特殊符号（,/';:等）,不然不能配置成功 开启远程连接前提： 必须要开启了3306端口才可以 123456781.开启端口firewall-cmd --zone=public --add-port=3306/tcp --permanent 2.重启firewall-cmd --reload3.查看是否有3306firewall-cmd --zone=public --list-ports 方法一：（不建议） 在linux上登陆mysql，登陆成功后，依次执行命令： 123use mysql;update user set host = '%' where user = 'root' and host ='localhost'; flush privileges; 并不建议对root账户进行开启远程访问权限，因为一旦拿到root权限之后，就可以对数据库执行任何操作，不安全。 方法二 新建一个用户并开启远程访问权限： 登录MySQL 123use mysql;grant all privileges on 库名.表名 to '用户名'@'IP地址' identified by '密码' with grant option;flush privileges; 详细参数解释库名要远程访问的数据库名称,所有的数据库使用*表名 要远程访问的数据库下的表的名称，所有的表使用*用户名 要赋给远程访问权限的用户名称（这里写一个你自己创建的用户）IP地址 可以远程访问的电脑的IP地址，所有的地址使用%密码要赋给远程访问权限的用户对应使用的密码 本地连接 保证本地mysql服务是打开的，3306端口是开的。 打开sqlyong，新建连接，填入以下数据 大功告成！！！","link":"/2004179649/"},{"title":"建站系列之---美化网站","text":"说明： 展现在你眼前的，只是部分功能，很基础的，根据个人喜好，如果说追求美观，那么多去找一些方案，网上很多美化小技巧，装饰在自己博客上面，看着也赏心悦目，但是装饰太对，终究会拖加载速度的后腿，这就需要更多的技术来优化，例如SEO优化，但是博客嘛，以简洁为主还是很好的。不要太多了累赘，反而看着很舒服！ 更换Next主题 在blog文件夹下，右键打开git bash here，输入： 1git clone https://github.com/iissnan/hexo-theme-next themes/next 可以看到themes文件夹下多了一个next文件，这就是next主题文件。 启用主题：打开F: \\ blog \\ _config.yml,找到 theme 标签，更改为： 1theme: next 打开F:\\blog\\themes\\next\\_config.yml,找到scheme，启用pisices 12345# Schemes #scheme: Muse #scheme: Mist scheme: Pisces #scheme: Gemini 网站基本设置 打开F: \\ blog \\ _config.yml,找到 Site 标签 123456789# Sitetitle: 代澳旗's Blogsubtitle: Welcome to my World！！！description: 这是我在学习过程中用hexo搭建的一个基于github的个人博客网站，用来存储学习笔记！keywords: ''author: 代澳旗#avatar: 网站头像外部链接 language: zh-Hanstimezone: Asia/Shanghai 添加页面 打开站点配置文件，修改如下 123456789menu: home: /|| home about: /about/|| user tags: /tags/|| tags categories: /categories/|| th archives: /archives/|| archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 打开命令行，输入：hexo n page categories其他的页面也是如此。会看到source文件夹下有相应的文件生成。 打开里面的index.md，添加一个字段type： categories，其他的也是如此 动态背景 找到主题文件F:\\blog\\themes\\next\\_config.yml改为 true 12# Canvas-nestcanvas_nest: true 鼠标点击效果图 在F:\\blog\\themes\\next\\source\\js\\src里新建love.js，写入以下内容 1!function(e,t,a){function n(){c(\".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}\"),o(),r()}function r(){for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText=\"left:\"+d[e].x+\"px;top:\"+d[e].y+\"px;opacity:\"+d[e].alpha+\";transform:scale(\"+d[e].scale+\",\"+d[e].scale+\") rotate(45deg);background:\"+d[e].color+\";z-index:99999\");requestAnimationFrame(r)}function o(){var t=\"function\"==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e){t&amp;&amp;t(),i(e)}}function i(e){var a=t.createElement(\"div\");a.className=\"heart\",d.push({el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()}),t.body.appendChild(a)}function c(e){var a=t.createElement(\"style\");a.type=\"text/css\";try{a.appendChild(t.createTextNode(e))}catch(t){a.styleSheet.cssText=e}t.getElementsByTagName(\"head\")[0].appendChild(a)}function s(){return\"rgb(\"+~~(255*Math.random())+\",\"+~~(255*Math.random())+\",\"+~~(255*Math.random())+\")\"}var d=[];e.requestAnimationFrame=function(){return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e){setTimeout(e,1e3/60)}}(),n()}(window,document); 打开F:\\blog\\themes\\next\\layout\\_layout.swig,在末尾添加代码。 12&lt;!-- 页面点击效果 --&gt;&lt;script type=\"text/javascript\" src=\"/js/src/love.js\"&gt;&lt;/script&gt; 设置站点建立时间 找到主题文件F:\\blog\\themes\\next\\_config.yml，找到since标签 设置头像 将头像图片放到F:\\blog\\themes\\next\\source\\images 打开F:\\blog\\themes\\next\\_config.yml，找到avatar，修改如下代码 1234# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/touxiang.jpg 修改网站图标 图标素材网站：iconfont 下载16x16以及32x32大小的PNG格式图标，置于/themes/next/source/images/下 打开themes/next/下的_config.yml，查找favicon，修改要更换的图标名字即可。 1234567favicon: small: /images/wangzhantubiao-16.png medium: /images/wangzhantubiao-32.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 添加RSS 在Git bash here中添加插件 1cnpm install --save hexo-generator-feed 在站点配置文件中添加如下代码 1234# Extensions## Plugins: http://hexo.io/plugins/#RSS订阅plugin: hexo-generator-feed 在主题配置文件下添加 1234# Set rss to false to disable feed link.# Leave rss as empty to use site's feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml 添加fork me Github 点击http://tholman.com/github-corners/挑选自己喜欢的样式，并复制代码。 找到themes/next/layout/_layout.swig文件，(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href改为你的github地址。 修改文章底部带#号的标签 修改模板/themes/next/layout/_macro/post.swig，搜索 rel=&quot;tag&quot;&gt;#，将 # 换成 1&lt;i class=\"fa fa-tag\"&gt;&lt;/i&gt; 在每篇文章末尾统一添加“本文结束”标记 在 \\themes\\next\\layout\\_macro 中新建 passage-end-tag.swig文件,添加你想说的内容： 12345&lt;div&gt; {% if not is_index %} &lt;div style=\"text-align:center;color: #ccc;font-size:14px;\"&gt;-------------结束啦&lt;i class=\"fa fa-paw\"&gt;&lt;/i&gt;感谢阅读-------------&lt;/div&gt; {% endif %}&lt;/div&gt; 打开\\themes\\next\\layout\\_macro\\post.swig文件，在 &lt;footer class=&quot;post-footer&quot;&gt; 之后， post-footer 之前添加： 12345&lt;div&gt; {% if not is_index %} {% include 'passage-end-tag.swig' %} {% endif %}&lt;/div&gt; 博文压缩 安装插件 12cnpm install gulp -gcnpm install gulp-minify-css gulp-htmlmin gulp-htmlclean gulp --save 在blog下面新建gulpfile.js,写入： 123456789101112131415161718192021222324252627282930313233var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');// 压缩 public 目录 cssgulp.task('minify-css', function() { return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public'));});// 压缩 public 目录 htmlgulp.task('minify-html', function() { return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('./public'))});// 压缩 public/js 目录 jsgulp.task('minify-js', function() { return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));});// 执行 gulp 命令时执行的任务gulp.task('default', [ 'minify-html','minify-css','minify-js']); 以后在生成博文是执行 hexo g &amp;&amp; gulp就会根据 gulpfile.js 中的配置，对 public 目录中的静态资源文件进行压缩。 修改代码块自定义样式 打开\\themes\\next\\source\\css\\_custom\\custom.styl,向里面加入： 12345678910111213141516//代码块自定义样式// Custom styles. code { color: #ff7600; background: #fbf7f8; margin: 2px;}// 大代码块的自定义样式.highlight, pre { margin: 5px 0; padding: 5px; border-radius: 3px;}.highlight, code, pre { border: 1px solid #d6d6d6;} 侧边栏社交链接小图标 打开F:\\blog\\themes\\next\\_config.yml,搜索social_icons: 1234567891011121314151617181920212223social: GitHub: https://github.com/DAQ121 || github csdn: https://blog.csdn.net/weixin_44861399 || crosshairs weibo: https://weibo.com/呜啦啦咦1 || weibo #E-Mail: mailto:yourname@gmail.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: enable: true #weibo: weibo GitHub: github csdn: crosshairs icons_only: false transition: false 添加热度 打开/themes/next/layout/_macro/post.swig,加上&lt;span&gt;°C&lt;/span&gt; 打开/themes/next/languages/zh-Hans.yml，找到visitors标签，改为热度。 添加音乐 安装插件 12npm install hexo-tag-dplayernpm install hexo-tag-aplayer 在网易云音乐生成外链，复制代码 打开F:\\blog\\themes\\next\\layout\\_macro里的sidebar.swig，在此处添加复制胡链接 网站底部字数统计 安装插件 1$ cnpm install hexo-wordcount --save 在/themes/next/layout/_partials/footer.swig文件尾部加上： 1234&lt;div class=\"theme-info\"&gt; &lt;div class=\"powered-by\"&gt;&lt;/div&gt; &lt;span class=\"post-count\"&gt;博客全站共{{ totalcount(site) }}字&lt;/span&gt;&lt;/div&gt; 实现统计功能 在主题配置文件中，配置： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true totalcount: false separated_meta: true 添加顶部加载条 打开：/themes/next/layout/_partials/head.swig，添加代码： 12&lt;script src=\"//cdn.bootcss.com/pace/1.0.2/pace.min.js\"&gt;&lt;/script&gt;&lt;link href=\"//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css\" rel=\"stylesheet\"&gt; 修改网页底部的桃心 打开：/themes/next/layout/_partials/footer.swig，修改你想用的图标 123&lt;span class=\"with-love\"&gt; &lt;i class=\"far fa-grin-tongue-wink\"&gt;&lt;/i&gt; &lt;/span&gt; 添加百度分享 给next主题添加了百度分享功能,在本地一切正常,但是当发布到github的时候,却不能正常显示，因为github上百度分享不支持在https上使用。 所以将主题配置_config.yml文件中关于baidushare部分的内容改为（其中type亦可以选择button）： 123baidushare: type: slide baidushare: true 下载static文件夹，地址：https://github.com/hrwhisper/baiduShare，将static文件夹保存至themes\\next\\source目录下。 修改文件：themes\\next\\layout_partials\\share\\baidushare.swig末尾部分的代码： 1.src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)]; 改为： 1.src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];","link":"/551144596/"},{"title":"操作系统---中断机制","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;中断机制可以说是操作系统里程碑上最划时代的一次变革。它在系统中起着通信网络的作用，协调系统对各种外部事件的响应和处理，中断是实现多道程序设计的必要条件，中断是CPU 对系统发生的某个事件作出的一种反应。因为有了它，我们才可以有条不紊的使用电脑！ 举个例子，CPU老板是一家公司的光杆司令，所有的顾客都要他亲自跑去处理，还要跟有关部门打点关系，CPU觉得顾客和公关这两样事它一个人搞不来，这就是轮询；终于这家公司升级发展了，CPU老板请了一个秘书，所有的顾客都先由秘书经手，CPU心情好的时候就去看一下，大部分时间都忙着去公关了，这时它觉得轻松了很多，这就是中断了~~ 也就是说，中断和轮询是从CPU老板的角度来看的，不管怎样，事件都还是有人来时刻跟踪才能被捕获处理，不过是老板还是秘书的问题。所有的中断（或者异步，回调等）背后都有一个轮询（循环，listener）。 中断机制的本质：CPU执行完每条指令时，都会去检查一个中断标志位","link":"/1622515277/"},{"title":"了解操作系统","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;计算机三件套之一：计算机操作系统，我刚开始看学校发的教材的时候，根本看不进去，一是知识太过于理论化，而且关于底层的东西，动手实践起来真的很难。但是一些简单的东西还是要了解一下的。其实在我看来，没有太大追求的话，就了解一些基本的就可以了，操作系统就那点儿东西：CPU调度，死锁，中断机制，进程管理，内存管理，文件系统，虚拟内存，就没了~ 操作系统有哪些？1.简单的批处理操作系统一批一批处理任务的系统，用户将一批作业提交给操作系统后便不再干预，由操作系统控制它们自动运行。用户一次可以提交多个作业，但系统一次只处理一个作业，处理完一个作业后，再调入下一个作业进行处理。这些调度、切换系统自动完成。 2.多道程序批处理操作系统简单批处理系统一次只能处理一个作业，系统资源的利用率就不高，因此出现多道程序批处理系统。把同一个批次的作业调入内存，存放在内存的不同部分，当一个作业由于等待输入输出操作而让处理机出现空闲，系统自动进行切换，处理另一个作用，这就是多道程序批处理系统。相对简单批处理系统，由于充分利用了处理机的空闲时间，因此多道程序批处理系统的资源利用效率要高。 3.分时操作系统分时操作系统：“分时”的含义是指多个用户使用同一台计算机，多个程序分时（分时间片）共享硬件和软件资源。分时操作系统是指在一台主机上连接多个带有显示器和键盘的终端，同时允许多个用户通过主机的终端，以交互方式使用计算机，共享主机中的资源。分时操作系统将CPU的时间划分成若干个片段，称为时间片，操作系统以时间片为单位，轮流为每个终端用户服务 。 总结：一个作业只能在一个时间片的时间内使用CPU,时间到时，系统将剥夺作业CPU的使用权，然后根据一定的算法将CPU分配给其他作业使用。 4.实时操作系统指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统作出快速响应，并控制所有实时任务协调一致运行的操作系统。 5.网络操作系统指的是一台计算机通过一个网络接口控制器(网卡)连接到网络上，可以进行网络通信功能，网络资源的管理和使用。根据使用环境的不同，操作系统又可以分为服务器操作系统、桌面操作系统、嵌入式操作系统等 操作系统的发展一、手工操作 二、单道批处理 三、多道批处理操作系统 四、分时操作系统","link":"/1988581478/"},{"title":"事务-学习笔记","text":"事务（Transaction），一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。 一、事务（Transaction）概述 其实指的一组操作，里面包含许多个单一的逻辑。只要有一个逻辑没有执行成功，那么都算失败。 所有的数据都回归到最初的状态(回滚)。 为什么要有事务?为了确保逻辑的成功。 如： 银行转账。 二、演示事务 命令行方式 123456开启事务： start transaction;提交： commit; 提交事务， 数据将会写到磁盘上的数据库回滚： rollback ; 数据回滚，回到最初的状态。 代码里面的事务，主要是针对连接来的。 123-通过conn.setAutoCommit（false ）来关闭自动提交的设置。-提交事务 conn.commit();-回滚事务 conn.rollback(); 123456789101112131415161718192021222324252627282930313233343536373839404142@Testpublic void testTransaction(){ Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { conn = JDBCUtil.getConn(); //连接，事务默认就是自动提交的。 关闭自动提交。 conn.setAutoCommit(false); String sql = \"update account set money = money - ? where id = ?\"; ps = conn.prepareStatement(sql); //扣钱， 扣ID为1 的100块钱 ps.setInt(1, 100); ps.setInt(2, 1); ps.executeUpdate(); int a = 10 /0 ;//有了异常，下面代码就不会执行了 //加钱， 给ID为2 加100块钱 ps.setInt(1, -100); ps.setInt(2, 2); ps.executeUpdate(); //成功： 提交事务。 conn.commit(); } catch (SQLException e) { try { //失败： 回滚事务 conn.rollback(); } catch (SQLException e1) { e1.printStackTrace(); } e.printStackTrace(); }finally { JDBCUtil.release(conn, ps, rs); }} 三、事务特性ACID（面试） 原子性（Atom）指的是 事务中包含的逻辑，不可分割。 一致性（Consistent）指的是 事务执行前后，数据完整性。 隔离性（Isolate）指的是 事务在执行期间不应该受到其他事务的影响。 持久性（Durable）指的是 事务执行成功，那么数据应该持久保存到磁盘上。 四、安全问题&amp;隔离级别（面试） 不考虑隔离级别设置，那么会出现以下问题。 读 问题 脏读一个事务读到另外一个事务还未提交的数据。 不可重复读一个事务读到了另外一个事务提交的数据 ，造成了前后两次查询结果不一致。 幻读一个事务读到了另一个事务已提交的插入的数据，导致多次查询结果不一致。 写 问题 丢失更新：B事务如果提交，会造成A事务的操作无效。B事务回滚，也会造成A事务更新失效。 解决方法：悲观锁，乐观锁 悲观锁指事务在一开始就认为丢失更新一定会发生， 这是一件很悲观的事情。 具体操作步骤如下： 1234567891.所以事务在执行操作前，先查询一次数据， 查询语句如下： select * from student for update ; 后面的for update 其实是数据库锁机制 、 一种排他锁。2.哪个事务先执行这个语句， 哪个事务就持有了这把锁， 可以查询出来数据， 后面的事务想再执行这条语句，不会有任何数据显示，就只能等着。 3.一直等到前面的那个事务提交数据后， 后面的事务数据才会出来，那么才可以往下接着操作。 4.补充：就像排队上厕所一样，只有里面的人出来了，才能进去。 这其实就是 java 中的同步的概念。 乐观锁乐观锁是指，从来不会觉得丢失更新会发生。要求程序员在数据库中添加字段，然后在后续更新的时候，对该字段进行判定比对， 如果一致才允许更新。 12345678910111213例：1.数据库表中，额外添加了一个version字段， 用于记录版本， 默认从0 开始， 只要有针对表中数据进行修改的，那么version就+1.2.开启A事务， 然后开启B事务 。3.A 先执行数据库表操作。 因为以前都没有人修改过。 所以是允许A事务修改数据库的，但是修改完毕，就把version的值变成 1 了 。4.B事务， 这时候如果想执行修改，那么是不允许修改的。 因为B事务以前是没有查询过数据库内容的，所以它认为数据库版本还是0 。 但是数据库的版本经过A修改，已经是1了。所以这时候不允许修改， 要求其重新查询 。5.B重新查询后， 将会得到version 为 1的数据，这份数据就是之前A 事务修改的数据了， B 在进行修改，也是在A的基础上修改的。 所以就不会有丢失更新的情况出现了。补充：乐观锁的机制 ，其实是通过比对版本或者比对字段的方式来实现的，与版本控制软件【SVN , GIT】机制是一样的。 隔离级别12345- 按效率划分，从高到低 读未提交 &gt; 读已提交 &gt; 可重复读 &gt; 可串行化- 按拦截程度 ，从高到底 可串行化 &gt; 可重复读 &gt; 读已提交 &gt; 读未提交 Read Uncommited【读未提交】指的是 ： 一个事务可以读取到另一个事务还未提交的数据。 这就会引发 “脏读” 读取到的是数据库内存中的数据，而并非真正磁盘上的数据。 123456例子： 1.开启一个命令行窗口A， 开始事务，然后查询表中记录。 设置当前窗口的事务隔离级别为：读未提交 命令如下： set session transaction isolation level read uncommitted;2.另外在打开一个窗口B， 也开启事务， 然后执行 sql 语句， 但是不提交3.在A窗口重新执行查询， 会看到B窗口没有提交的数据。 Read Commited 【读已提交】与前面的读未提交刚好相反，这个隔离级别是 ，只能读取到其他事务已经提交的数据，那些没有提交的数据是读不出来的。屏蔽了脏读的情况，但是这会造成一个问题是： 前后读取到的结果不一样。 发生了不可重复!!!, 所谓的不可重复读，就是不能执行多次读取，否则出现结果不一样。 123456789例子：1. 开启一个命令行窗口A， 开始事务，然后查询表中记录。 设置当前窗口的事务隔离级别为：读已提交 命令如下： set session transaction isolation level read committed;2. 另外在打开一个窗口B， 也开启事务， 然后执行 sql 语句， 但是不提交 3. 在A窗口重新执行查询， 是不会看到B窗口刚才执行sql 语句的结果，因为它还没有提交。4. 在B窗口执行提交。5. 在A窗口中执行查看， 这时候才会看到B窗口已经修改的结果。6. 但是这会造成一个问题是： 在A窗口中， 第一次查看数据和第二次查看数据，结果不一样。 Repeatable Read 【重复读】MySql 默认的隔离级别就是这个。该隔离级别， 可以让事务在自己的会话中重复读取数据，并且不会出现结果不一样的状况，即使其他事务已经提交了，也依然还是显示以前的数据。（读到的不是最新更新的数据，确保本事务不受其他事务影响） 12345678例子：1. 开启一个命令行窗口A， 开始事务，然后查询表中记录。 2. 设置当前窗口的事务隔离级别为：重复读 命令如下： set session transaction isolation level repeatable read;3. 另外在打开一个窗口B， 也开启事务， 然后执行 sql 语句， 但是不提交 4. 在A窗口重新执行查询， 是不会看到B窗口刚才执行sql 语句的结果，因为它还没有提交。5. 在B窗口执行提交。6. 在A窗口中执行查看， 这时候查询结果，和以前的查询结果一致。不会发生改变。 Serializable 【可串行化（序列化）】该事务级别是最高级的事务级别了，如果有一个连接设置隔离级别为可串行化，那么谁先打开事务，谁就有了先执行的权利，谁后打开事务，就只能等着，等前面的那个事务，提交或者回滚后才会执行。这种隔离级别比前面几种都要强大一点，也就是前面几种的问题【脏读、不可重复读、幻读】都能够解决。但是都使用该隔离级别也会有些问题。 比如造成并发的性能问题。 其他的事务必须得等当前正在操作表的事务先提交，才能接着往下，否则只能一直在等着。所以比较少用，容易造成性能上的问题，效率比较低。 12345678例子：1.开启一个命令行窗口A， 开始事务，然后查询表中记录。 2.设置当前窗口的事务隔离级别为：serializable 命令如下： set session transaction isolation level read serializable;3.另外在打开一个窗口B， 也开启事务， 然后执行 sql 语句， 但是不提交 4.在A窗口重新执行查询， 会卡主，没有任何信息显示。 5.在B窗口执行提交。6.在A窗口中执行查看， 这时候才会显示结果。 五、总结1.在代码里面使用事务 123conn.setAutoCommit(false);conn.commit();conn.rollback(); 2.事务只是针对连接连接对象，如果再开一个连接对象，那么那是默认的提交。3.事务是会自动提交的。4.安全隐患： 123456读 脏读：一个事务读到了另一个事务未提交的数据。 不可重复读：一个事务读到了另一个事务已提交的数据，造成前后两次查询结果不一致。 幻读：一个事务读到了另一个事务insert的数据 ，造成前后查询结果不一致 。写 丢失更新。 5.隔离级别 12345678读未提交&gt; 引发问题： 脏读 读已提交&gt; 解决： 脏读 ， 引发： 不可重复读可重复读&gt; 解决： 脏读 、 不可重复读 ， 未解决： 幻读可串行化&gt; 解决： 脏读、 不可重复读 、 幻读。 导致：性能下降 6.补充： 12mySql 默认的隔离级别是 可重复读Oracle 默认的隔离级别是 读已提交","link":"/1680230579/"},{"title":"操作系统---内存管理","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在学习计算机操作系统的时候，CPU调度，进程管理，内存管理，是最最重要的，尤其是内存管理，要领悟这其中的理念。对编程来讲，代码实际没有问题了，而且经常要考虑的就是内存了。 一、小知识 socket是指套接字，原义是接口。 Agent：智能体 Architect：架构师 每个进程都有一个系统给定的权限，不能做超出自己权限的事。 cpu，内存，文件：是操作系统最具代表性的资源。 逻辑地址（虚拟地址，偏移地址） 这个地址都是由cpu发出的地址（程序运行的时候，我们看的到的地址） 物理地址： 真实存在的，计算机里实实在在的内存，从0开始。 MMU内存管理单元： (Memory Management Unit)作用：把逻辑地址映射到物理地址，是CPU内部的一个小部件。 cpu只能访问（内存/寄存器）。所以对内存的管理很重要。 内存管理的主要问题：给每个进程分配内存的时候，内存怎么放？放多少？ 二、内存分配策略寄存器 每个进程的寄存器中都包括Base（基质寄存器和Limit（内存地址上限寄存器） 当进程发出访问地址请求的时候，就要做两次验证，这就是安全保护的基本策略，限制了访问范围只能在（base-limit）。 但是这样每次访问都要验证，会带来很大速度时间延迟，怎么解决呢？ 每一个进程，每个程序的每次运行，被放在内存中的位置是不固定的。这怎么解决呢？这就涉及到一个，指令和数据在内存当中地址绑定的一个问题。 加载时刻（Load time） Load time（加载时刻）编译器编译运行的时候，并不知道程序会被放在内存的哪个位置。我们可以通过设定一些标记。当程序被加载到内存的时候，这个加载程序（loader）知道要放在哪个位置，放入之后，他就对这个程序里的所有（对地址访问的代码的数值）进行一个完整的修改，修改为目前放的位置。这个策略（由loader做动态的复制）很好的解决了多进程同时存在的问题。 执行时处理（Execution time） 最好的策略：Execution time（执行时处理）不仅可以在内存中放多个进程。而且这个程序已经在内存的时候，甚至可以挪动他。但需要硬件支持，通过修改base的值，就可以实现挪动进程在内存中的位置。 三、内存管理策略 目的是是内存空间利用率最大化，尽量让他放更多的进程，为了做到这一点，设计了很多策略动态加载（Dynamic Loading） 解决的问题：程序运行到退出，并不会把所有的代码都执行一遍，总有一些用不到的。那为什么要把所有的程序代码都加载到内存呢？动态加载 就可以很好的解决这个问题，只加载要用的部分，不用的部分不加载。这样使得内存空间利用率获得很大的提升。 局部性原理 DLL:动态链接库（Dynamic Link Library），可以看到我们下载的许多软件中，有很多后缀名为.dll的文件，这就是动态链接库。使用有很多好处。①需要使用某个功能的时候，就去加载这个.dll文件。这就实现了动态加载。②很好的实现了共享，他在内存中只存在一份，但是很多程序都可以使用他。③很容易更新，windows主要更新的漏洞就是这个.dll文件。 交换技术（Swapping） 解决的问题：系统中有好多进程在运行，但是有些时候有的进程已经占据了内存，由于各种原因，这个进程属于休眠状态，好长时间不会运行，但是又有进程要进来，却没有空间。这就形成了内存空间的浪费。怎么解决呢？ 将这个占着茅坑不拉屎的进程写到硬盘上去，这个内存空间就腾出来了。过一会儿时间，它又具备了运行条件，就把他写进来。 好处：用硬盘做他的补充，就好像内存变大了一样，可以放更多的进程。 连续分配（Contiguous Allocation） 现在操作系统中已经很少用了 首次适应算法（使用最多），下次适应算法，最佳适应算法，最差适应算法 最大的问题：对内存的申请释放的随机性， 无法很好的适应它，就不能保证用量很好。 对编程人员：对内存的使用可以是随机的，也可以自己来设定，总结出来规律之后，就能更好的管理这块儿空间。但是你申请到了内存，其实你并没有得到她，当你真正访问它的时候，才得到 碎片（外部碎片&amp;内部碎片） 四、页式存储管理（重点） 内部碎片：页式存储管理是产生外部碎片的罪魁祸首。因为计算机分配内存是按照2的指数次幂个字节来分配，比如说，4字节，8字节，16字节，但是进程有的时候用不完这些，比如只需要5字节，就会多出来3字节，这就成了碎片。 特点：①非连续性：（物理空间非连续）进程在物理内存中占据哪些内存，是不连续的，会把进程切成小碎片，散落在各个区域，（逻辑空间非连续） 从图中可以看出，进程在内存中保存的位置是散乱的，这样带来的好处就是，每一个页面都会被利用到，不会产生外部碎片，使得物理内存管理起来非常方便。但是这样做还是很麻烦。 为什么页面大小是2的整数次幂？如果不是2的整数次幂，就没有办法计算偏移地址，没办法从中间分隔开， 神奇的二进制。 页式存储管理：也许这图只有我自己才能看懂吧，口头概述加深记忆，从逻辑地址 中拿出编号，写成四位二进制数，因为每页是四个字节（2的2次幂），所以要从第二位切一刀，（如果每页面是八字节，2的3次方，就要从第三位切）前面的是虚页号，后面的是页内偏移地址，根据虚页号，在页表中找到对应的物理页号，在将物理页号写成二进制数，加在虚页号前面，拼接成一个新的二进制数，然后再转化为十进制数，根据得到的数字，就可以找到物理地址 中对应的数据 这个页面越大越好吗？ （页面的大小是2的整数次幂）①页面小的话，内部碎片越少，但是会增加页表的大小（有多少个页面，页表里就要有多少个项），每一个页表项都是要占空间的，他在内存中。这样的话虚拟地址到物理地址的映射就会慢。②页面大的话，内部碎片就变多了，页表会减少。虚拟地址到物理地址的映射会很快。③折中（4k的页面用的多），所以要看使用情况的不同了，对大进程来说，页表的体积就会缩小，从内部碎片来看，进程也不多，浪费就浪费吧。④在未来开发或者管理过程中，都可以通过改变页面大小调优，从而提高系统效率，内存使用更充分。（调整一定要遵从硬件的架构） 页表是怎么实现的？在内存中，有两个参数，放在寄存器中，一个叫页表基址寄存器（指向页表起始位置），页表长度寄存器（页表的长度），这两个地址都是绝对的物理地址，不跟虚拟进程有任何的瓜葛。 问题：数据，指针每次都要访问两次内存。（先进内存查页表，得到物理地址，再进内存中查到该数据。）怎么解决？用TLB（ranslation look-aside buffers） 快表—相当于硬件的cache，思想也是跟cache一样（加快访问内存的速度）。cache是将当前最热的数据放在里面。TLB也是如此，把你当前用到的，最热的拿过来放入表中，就省去了根据虚页号去查物理页号。 在快表中，存储的多了，查找起来也费时间，那么怎么加快查找速度呢？使用硬件并行搜索 （涉及到电路问题），软件实现并行很麻烦，但硬件很简单。只用查找一次。如果一次没找到（未命中），就会去普通的页表查找，并且更新到快表中。 内存保护 如何实现多个进程互相之间不能访问到彼此的内存？对指令严加把控，读，写，执行。Valid-invalid bit（有效无效位） 有效V即可访问。无效i触发一个中断，操作系统意识到这个进程执行了一个非法操作，就会杀死该进程。 共享内存 在页式存储管理中，实现内存共享是简单的。该共享的就共享，该私有就私有 Copy-on-write(写时复制)两级/三级页表结构（Two-Level Page-Table Scheme） 由外层页表算出来，对应的是哪个项，再根据这个项，找到对应的内存页表，再根据虚页号，找到物理页号，进而找到对应的实际物理地址。 4k物理页面的页内偏移是12位（因为4k=2的12次方），剩下的20位属于页面号。然后再将这20位页面号分割成两部分。 在根据p1（前面页面号）和p2（内存页面号），查找。 64位系统如果采用两级页面的话，就要维护42位的前面页面号。这是一个很大的开销，所以出现了三级页表，再将页面好进行划分。64位系统的开销比32位的大。现在的64位系统采用的就是三级页表。 哈希表 页表耗费的时间还是挺大的，出现了哈希表，这样在内存中维护的就不是页表，而是哈希表。但是哈希表存在碰撞。 反表（Inverted Page Table） 这是64位系统使用的方法，因为我们实际上要管理的是物理内存，如果把系统中所有进程的所有列表项放在一起看的话，这些页表项里，有用的，有价值的，只是那些和物理内存相对应的，没有对应关系的页表项是没有存在价值的。如果我们把所有没价值的列表项都扔掉，那么页表的体积就可以得到控制了。控制到：有多少个物理内存，有多少个物理页面，那么就有多少个页表项，一一对应。 全系统中只有一张页表。但是！！！ 这种方法cpu不支持，我们现在用的方法就是多级页表。因为要兼容32位，64位。 五、段式内存管理（Segmentation） 把程序分成若干段，程序段，代码段，栈，等等等等。在进程的逻辑空间中，自己划分出若干块，每块放不同的东西，执行不同的功能。 六、段页式管理 inter的cpu做得非常强大，你可以段式管理，页式管理，也可以段页式管理。 这是，我们目前cpu里面的机制，每执行一个指令，就要执行这个过程。","link":"/4128545857/"},{"title":"github下载项目加速","text":"在github上面找好的开源项目，想要clone到本地，自己调试运行一下，但是由于github的服务器在国外，所以下载速度真的是惊人的慢，有的时候2k/s，如果是一个小项目的话。那还好，等个两三分钟，但是项目大一点的，那就很鸡肋了，这里就介绍一个投机取巧的方法，来加速git clone 核心思想： 利用gitee（码云）做中间工具 注册好码云，并配置好本地仓库，保证可以从gitee上git clone 在github上复制你要克隆的项目的url。在码云中选择新建仓库的从github/github导入仓库，选择从url导入。粘贴刚才github上的URL到其中，点击导入即可。 然后在从码云将项目克隆到本地。 但是现在的项目，关联的是码云，而不是github。所以就要修改配置文件。 打开项目的.git，找到config文件，找到里面的url关键字，修改gitee为github，即可。 补充： 修改，提交四步走 git status git add &quot; 文件&quot; git commit -m &quot;本次提交操作的相关描述&quot; git push","link":"/3770390475/"},{"title":"区块链的架构模型以及核心技术","text":"- 一.架构模型一般说来，区块链系统由数据层、网络层、共识层、激励层、合约层，应用层组成。 数据层： 封装了底层数据区块以及相关的数据加密和时间戳等基础数据和基本算法。 网络层： 则包括分布式组网机制、数据传播机制和数据验证机制等。 共识层： 主要封装网络节点的各类共识算法。 激励层： 将经济因素集成到区块链技术体系中来，主要包括经济激励的发行机制和分配机制等。 合约层： 主要封装各类脚本、算法和智能合约，是区块链可编程特性的基础。 应用层： 则封装了区块链的各种应用场景和案例。 区块链技术最具代表性的创新点： 基于时间戳的链式区块结构、分布式节点的共识机制。 基于共识算力的经济激励和灵活可编程的智能合约。 二.核心技术 1.分布式账本：分布式账本指的是交易记账由分布在不同地方的多个节点共同完成，而且每一个节点记录的是完整的账目，因此它们都可以参与监督交易合法性，同时也可以共同为其作证 。跟传统的分布式存储有所不同，区块链的分布式存储的独特性主要体现在两个方面：一是区块链每个节点都按照块链式结构存储完整的数据，传统分布式存储一般是将数据按照一定的规则分成多份进行存储。二是区块链每个节点存储都是独立的、地位等同的，依靠共识机制保证存储的一致性，而传统分布式存储一般是通过中心节点往其他备份节点同步数据。没有任何一个节点可以单独记录账本数据，从而避免了单一记账人被控制或者被贿赂而记假账的可能性。也由记账节点足够多，理论上讲除非所有的节点被破坏，否则账目就不会丢失，从而保证了账目数据的安全性。 2.非对称加密：存储在区块链上的交易信息是公开的，但是账户身份信息是高度加密的，只有在数据拥有者授权的情况下才能访问到，从而保证了数据的安全和个人的隐私。3.共识机制就是所有记账节点之间怎么达成共识，去认定一个记录的有效性，这既是认定的手段，也是防止篡改的手段。区块链提出了四种不同的共识机制，适用于不同的应用场景，在效率和安全性之间取得平衡 。区块链的共识机制具备“少数服从多数”以及“人人平等”的特点，其中“少数服从多数”并不完全指节点个数，也可以是计算能力、股权数或者其他的计算机可以比较的特征量。“人人平等”是当节点满足条件时，所有节点都有权优先提出共识结果、直接被其他节点认同后并最后有可能成为最终共识结果。以比特币为例，采用的是工作量证明，只有在控制了全网超过51%的记账节点的情况下，才有可能伪造出一条不存在的记录。当加入区块链的节点足够多的时候，这基本上不可能，从而杜绝了造假的可能。4.智能合约：基于这些可信的不可篡改的数据，可以自动化的执行一些预先定义好的规则和条款。以保险为例，如果说每个人的信息（包括医疗信息和风险发生的信息）都是真实可信的，那就很容易的在一些标准化的保险产品中，去进行自动化的理赔。在保险公司的日常业务中，虽然交易不像银行和证券行业那样频繁，但是对可信数据的依赖是有增无减。因此，笔者认为利用区块链技术，从数据管理的角度切入，能够有效地帮助保险公司提高风险管理能力。具体来讲主要分投保人风险管理和保险公司的风险监督。","link":"/714656305/"},{"title":"区块链简单理解","text":"对近年来很火的区块链的简单了解 区块链是什么：区块链是分布式数据存储、点对点传输、共识机制、加密算法等计算机技术的新型应用模式。区块链（Blockchain），是比特币的一个重要概念，它本质上是一个去中心化的数据库，同时作为比特币的底层技术，是一串使用密码学方法相关联产生的数据块，每一个数据块中包含了一批次比特币网络交易的信息，用于验证其信息的有效性（防伪）和生成下一个区块。 起源：区块链起源于比特币，2008年11月1日，一位自称中本聪(Satoshi Nakamoto)的人发表了《比特币:一种点对点的电子现金系统》，阐述了基于P2P网络技术、加密技术、时间戳技术、区块链技术等的电子现金系统的构架理念，这标志着比特币的诞生。两个月后理论步入实践，2009年1月3日第一个序号为0的创世区块诞生。几天后2009年1月9日出现序号为1的区块，并与序号为0的创世区块相连接形成了链，标志着区块链的诞生。近年来，世界对比特币的态度起起落落，但作为比特币底层技术之一的区块链技术日益受到重视。在比特币形成过程中，区块是一个一个的存储单元，记录了一定时间内各个区块节点全部的交流信息。各个区块之间通过随机散列(也称哈希算法) 实现链接，后一个区块包含前一个区块的哈希值，随着信息交流的扩大，一个区块与一个区块相继接续，形成的结果就叫区块链 。 概述： 从科技层面来看： 区块链涉及数学、密码学、互联网和计算机编程等很多科学技术问题。 从应用视角来看： 区块链是一个分布式的共享账本和数据库，具有去中心化、不可篡改、全程留痕、可以追溯、集体维护、公开透明等特点。这些特点保证了区块链的 “诚实” 与 “透明” ，为区块链创造信任奠定基础。而区块链丰富的应用场景，基本上都基于区块链能够解决信息不对称问题，实现多个主体之间的协作信任与一致行动。 类型： 公有区块链（Public Block Chains)：世界上任何个体或者团体都可以发送交易，且交易能够获得该区块链的有效确认，任何人都可以参与其共识过程。公有区块链是最早的区块链，也是应用最广泛的区块链，各大bitcoins系列的虚拟数字货币均基于公有区块链，世界上有且仅有一条该币种对应的区块链。 行业区块链（Consortium Block Chains)：由某个群体内部指定多个预选的节点为记账人，每个块的生成由所有的预选节点共同决定（预选节点参与共识过程），其他接入节点可以参与交易，但不过问记账过程(本质上还是托管记账，只是变成分布式记账，预选节点的多少，如何决定每个块的记账者成为该区块链的主要风险点），其他任何人可以通过该区块链开放的API进行限定查询。 私有区块链（Private Block Chains)：仅仅使用区块链的总账技术进行记账，可以是一个公司，也可以是个人，独享该区块链的写入权限，本链与其他的分布式存储方案没有太大区别。传统金融都是想实验尝试私有区块链，而公链的应用例如bitcoin已经工业化，私链的应用产品还在摸索当中。 特性： 去中心化。区块链技术不依赖额外的第三方管理机构或硬件设施，没有中心管制，除了自成一体的区块链本身，通过分布式核算和存储，各个节点实现了信息自我验证、传递和管理。去中心化是区块链最突出最本质的特征。 开放性。区块链技术基础是开源的，除了交易各方的私有信息被加密外，区块链的数据对所有人开放，任何人都可以通过公开的接口查询区块链数据和开发相关应用，因此整个系统信息高度透明。 独立性。基于协商一致的规范和协议(类似比特币采用的哈希算法等各种数学算法)，整个区块链系统不依赖其他第三方，所有节点能够在系统内自动安全地验证、交换数据，不需要任何人为的干预。 安全性。只要不能掌控全部数据节点的51%，就无法肆意操控修改网络数据，这使区块链本身变得相对安全，避免了主观人为的数据变更。 匿名性。除非有法律规范要求，单从技术上来讲，各区块节点的身份信息不需要公开或验证，信息传递可以匿名进行。","link":"/2068677160/"},{"title":"客户端会话技术：Cookie","text":"类型为“小型文本文件”，是某些网站为了辨别用户身份，进行Session跟踪而储存在用户本地终端上的数据（通常经过加密），由客户端计算机暂时或永久保存的信息。 Cookie概述 概述： 一份小数据， 是服务器给客户端，并且存储在客户端上的一份小数据 应用场景： 自动登录、浏览记录、购物车。 为什么要有这个Cookie： http的请求是无状态。 客户端与服务器在通讯的时候，是无状态的，其实就是客户端在第二次来访的时候，服务器根本就不知道这个客户端以前有没有来访问过。 为了更好的用户体验，更好的交互 [自动登录]，其实从公司层面讲，就是为了更好的收集用户习惯 [大数据]。 如何使用Cookie发送Cookie给客户端 在响应的时候，添加cookie 1234Cookie cookie = new Cookie(\"aa\", \"bb\"); //给响应，添加一个cookie response.addCookie(cookie); 客户端收到的信息里面，响应头中多了一个字段 Set-Cookie 获取客户端带过来的Cookie123456789//获取客户端带过来的cookieCookie[] cookies = request.getCookies(); if(cookies != null){ for (Cookie c : cookies) { String cookieName = c.getName(); String cookieValue = c.getValue(); System.out.println(cookieName + \" = \"+ cookieValue); } } 常用方法1234567891011121314//关闭浏览器后，cookie就没有了。 ---&gt; 针对没有设置cookie的有效期。// expiry： 有效 以秒计算。//正值： 表示 在这个数字过后，cookie将会失效。//负值： 关闭浏览器，那么cookie就失效， 默认值是 -1cookie.setMaxAge(60 * 60 * 24 * 7); //赋值新的值cookie.setValue(newValue); //用于指定只有请求了指定的域名，才会带上该cookiecookie.setDomain(\".itheima.com\"); //只有访问该域名下的cookieDemo的这个路径地址才会带cookiecookie.setPath(\"/CookieDemo\"); 典型案例：显示最近访问的时间12345678910111213141516171819202122232425262728293031323334351. 判断账号是否正确2. 如果正确，则获取cookie。 但是得到的cookie是一个数组， 我们要从数组里面找到我们想要的对象。3. 如果找到的对象为空，表明是第一次登录。那么要添加cookie4. 如果找到的对象不为空， 表明不是第一次登录。 if(\"admin\".equals(userName) &amp;&amp; \"123\".equals(password)){ //获取cookie last-name --- &gt; Cookie [] cookies = request.getCookies(); //从数组里面找出我们想要的cookie Cookie cookie = CookieUtil.findCookie(cookies, \"last\"); //是第一次登录，没有cookie if(cookie == null){ Cookie c = new Cookie(\"last\", System.currentTimeMillis()+\"\"); c.setMaxAge(60*60); //一个小时 response.addCookie(c); response.getWriter().write(\"欢迎您, \"+userName); }else{ //1. 去以前的cookie第二次登录，有cookie long lastVisitTime = Long.parseLong(cookie.getValue()); //2. 输出到界面， response.getWriter().write(\"欢迎您, \"+userName +\",上次来访时间是：\"+new Date(lastVisitTime)); //3. 重置登录的时间 cookie.setValue(System.currentTimeMillis()+\"\"); response.addCookie(cookie); } }else{ response.getWriter().write(\"登陆失败 \"); } 显示商品浏览记录 jspJava Server Pager —&gt; 最终会翻译成一个类， 就是一个Servlet 12345678910111213jsp中写java代码： &lt;% 只能写java代码 %&gt;定义全局变量: &lt;%! int a = 99; %&gt;定义局部变量: &lt;% int b = 999; %&gt;在jsp页面上，显示 a 和 b的值: &lt;%=a %&gt; &lt;%=b %&gt; 删除浏览记录清除浏览记录 其实就是清除Cookie， 删除cookie是没有什么delete方法的。只有设置maxAge 为0 。 1234Cookie cookie = new Cookie(\"history\",\"\");cookie.setMaxAge(0); //设置立即删除cookie.setPath(\"/CookieDemo02\");response.addCookie(cookie); 总结1.服务器给客户端发送过来的一小份数据，并且存放在客户端上。 2.获取cookie， 添加cookie request.getCookie(); response.addCookie();3.Cookie分类 1234567会话Cookie 默认情况下，关闭了浏览器，那么cookie就会消失。持久Cookie 在一定时间内，都有效，并且会保存在客户端上。 cookie.setMaxAge(0); //设置立即删除 cookie.setMaxAge(100); //100 秒 4.Cookie的安全问题。由于Cookie会保存在客户端上，所以有安全隐患问题。 还有一个问题， Cookie的大小与个数有限制。 为了解决这个问题 —&gt; Session .","link":"/887317365/"},{"title":"建站系列之---基于github搭建hexo网站","text":"日常在网上找答案的时候，发现了一种干干净净的，类似于个人主页的网站，就很好奇，后来深入了解了一下，原来这是基于hexo博客框架搭建起来的网站，用github的page服务托管博文，于是我也想上手整一个，于是乎，就花了前前后后大概半个月的时间，搭建起来网站，并买了域名部署到了服务器上面，此时怀着欣慰的心情，写下了这个系列！！！！ 概述： 本文主要讲的是基于github，利用hexo博客框架搭建网站。购买域名（9块）并绑定。实现效果：可以看到网站首页。 一、下载安装Git下载地址：https://git-scm.com/download/win安装过程就不赘述了！ 二、下载安装Node.js下载地址：http://nodejs.org/download/安装的时候，选择add to path，他会自动配置环境变量。 换镜像（亲身体验，可以省去以后好多麻烦） 1npm install -g cnpm --registry=https://registry.npm.taobao.org 三、安装Hexo 用cnpm全局安装，在桌面右键打开Git bash here输入： 1cnpm install -g hexo-cli 安装完成后，在命令行里输入hexo -v检查是否安装成功。 四、配置hexo12345678910基本命令了解： 1. hexo -v //查看版本 2. hexo init //初始化一个项目 3. cnpm install 4. hexo clean //清理生成的文件 5. hexo g //生成静态网页文件，g是generate的缩写 6. hexo s //运行到服务器端，s是server的缩写 7. hexo d //部署到远端GitHub, d是deploy的缩写 8. hexo s -p 5000 //在4000端口被占用的时候，修改指定端口 9. cnpm uninstall hexo-cli -g //卸载hexo 在本地新建一个文件夹，我命名它为blog 在这个文件夹下，右键打开Git Bash here，输入hexo init，我在这个地方出现了一个WARN，暂时不用管它。 继续输入cnpm install可以看到blog文件夹里出现： 12345678910目录介绍： 1. node_modules #本地依赖模块 2. public #hexo g生成的目录，包含静态网页文件，就是看到的博客 2. source #源文件，用来存放我们的写好的博客源文件 3. themes #主题文件夹，里面存放主题 4. _config.yml #站点配置文件，用来配置博客具体的显示内容等 5. db.json #存储一些用到的数据 6.package.json #依赖配置 .deploy_git #hexo s部署到远端的时候会生成的文件夹，是根据public文件夹生成的，内容是差不多的 输入：hexo g 输入：hexo s 打开浏览器输入localhost：4000，可以看到部署好了，有一篇hello World的博客 到这一步，本地部署就已经成功了！！ 五、连接到远端Github 安装 deployer 插件 1cnpm install hexo-deployer-git --save 打开F:\\blog\\_config.yml,找到 deploy。修改如下，其中repo填写你自己的仓库名字。 生成公私钥 1ssh-keygen -t rsa -C \"注册git使用的邮箱\" 找到生成的 id_rsa.pub 公钥文件（在C:\\Users\\pc\\.ssh下），复制公钥内容。 到Github你的网站仓库界面：Setting -&gt; Deploy keys -&gt; add deploy key -&gt; Add key，选择Allow write access（允许推送），这样方便以后推送的时候，不用每次都输入密码。 开始推送 1hexo deploy 这样在博客和github都可以看到推送的内容。 六、购买绑定域名阿里云：https://wanwang.aliyun.com/domain/ 在阿里云或者腾讯云购买一个域名，我买的是阿里云的.top后缀名的，后缀名不同，价格不同，top最便宜，一年只要九块。 如何买域名以及解析域名不做描述，注意要是实名认证，解析域名的意思就是，把ip地址和域名做一个映射，它让你填的ip地址就是你github网站仓库的ip。如何得到这个ip： 填入ip，完成解析。 在F:\\blog\\source下新建一个CNAME.txt,在里面写入你的域名，不要前缀，如： 去掉.txt后缀 绑定域名，到github，找到你的仓库，找到Setting，一直拉到最先面下面。 这样就绑定好了。 1234每次部署的执行次序 1. hexo clean 2. hexo g 3. hexo d 执行一次，查看效果。","link":"/167674660/"},{"title":"try-catch-finally总结","text":"在日常编译运行程序出错的时候，编译器就会抛出异常，抛出异常要比终止程序灵活的多，这是因为Java提供了一个”捕获”异常的处理器对异常情况进行处理，如果没有提供处理器机制，程序就会终止，try-catch-finally可以保证程序发生错误的时候继续执行下去。下面就谈一下使用的总结，和注意事项。 总结 try，catch，finally语句中，如果try语句有return语句，此后做任何修改，都不影响try中return的返回值。 如果finally块中有return语句，则try或catch中中的返回语句忽略。 如果finally块中抛出异常，则整个try，catch，finally块中抛出异常。 注意 在使用try- catch-finally的时候，要注意以下问题：①尽量在try或者catch中使用return语句。通过finally块中达到对try或者catch返回值修改是不可行的。②finally块中避免使用return语句，因为finally块中如果使用return语句，会显式的消化掉try，catch块中的异常信息，屏蔽错误的发生。③finally块中避免再次抛出异常，否则整个包含try语句块的方法会抛出异常，并且会消化掉try，catch块中的异常。","link":"/2774241439/"},{"title":"建站系列之---部署网站到云服务器","text":"由于这次的疫情，最爱的马云爸爸的阿里云推出了学生在家上机实践的活动，免费领六个月的ECS云服务器，天呐，2核4G啊，六个月之后还可续费六个月，整整一年呐，市场价780软妹币呢，不过投放量少，而且还是每天早上八点领，连续7:55闹钟起早，终于，在第三个早上，马云爸爸眷顾了我，我领到了。领到了就不能让他吃灰吧，于是先部署个博客再说。因为之前博客是托管在github上面的。而github的服务器又在国外，所以访问速度十分感人，但是有了国内的服务器就不一样了，瞬间嗖嗖嗖。。。 写在开头的话： 对于一个刚接触的门外汉来说，搭建博客，到部署到服务器真的让人崩溃，但是在不断地排错过程中，也渐渐弄懂了一些东西。很值得！由于我的域名还在备案中，DNS解析已经停掉了，所以暂时只能用公网IP访问：123.57.60.151，后期等备案成功后再做修改，并且进一步优化。还想做一点SEO的东西。 一、云服务器配置①建立博客存放的目录 我的目录是：home/www/blog 1234cd /homemkdir wwwcd /wwwmkdir /blog ②安装nginx 搭建服务器环境，以nginx做服务器。 123456781.安装yum install -y nginx2.启动服务器systemctl start nginxsystemctl enable nginx3.在浏览器地址栏中输入你的公网ip，如果打开了有内容网页，说明成功了。 配置服务器的路由：通过公网ip访问，这个地址指向的是nginx，得让他指向我们的博客，就要修改配置文件，找到配置文件etc/nginx/nginx.conf,并不建议直接修改配置文件，应该先创建一个新的文件，然后采用include的方式，将这个文件包含进nginx.conf中。 1.新建配置文件 1234cd /etc/nginx/mkdir vhostcd vhostvim blog.conf 2.编写配置文件 12345678编辑blog.conf 如下：server{ listen 80; root /home/www/blog;这里填博客目录存放的地址 server_name 这里填域名如(www.baidu.com) 如果暂时没有域名就填阿里云的公网ip，以后有了再改回来; location /{ }} 3.用include插入到nginx.conf中 4.如果以后还想添加新的网站，也可以在vhost目录下新建一个conf配置文件。然后再用include装入到nginx.conf中。5.（先跳过这一步，等到最后有问题了，再回来）最后可能会出现只能访问centOS的怪相，所以，如果出现那个问题了，请你回到这一步，增加一个操作，就是上图中那个server里面的root后面的路径，替换成你的博客存放位置：例如我的是/home/www/blog（这是我经验所得，可能你就会卡在这一步）。 ③安装Nodejs1234567891.换源curl -sL https://rpm.nodesource.com/setup_10.x | bash -2.安装yum install -y nodejs3.检查版本node -vnpm -v ④安装Git以及配置仓库 目的： 使本地主机可以通过ssh方式连接到云服务器，我们就可以在本地使用git将我们的博客部署到服务器上。 1.安装git并查看版本。 123451.安装yum install git2.查看版本git --versiongit version 1.8.3.1 2.新建git用户，并修改权限 123451.新建git用户adduser -m git2.修改用户权限chmod 740 /etc/sudoersvi /etc/sudoers 3.添加Git ALL=(ALL) ALL 4.保存退出后，将权限改回去。 1chmod 400 /etc/sudoers 5.设置git密码 1passwd git 6.切换到git用户，在~目录下，可以看到有一个.ssh文件夹 1234su gitcd ~mkdir .sshcd /.ssh 7.生成公钥密钥文件 12ssh-keygen此时在目录下就会有两个文件，分别是id_rsa 和 id_rsa.pub 8.id_rsa.pub 就是公钥文件，将他复制一份。目录下就会多出一个authorized_keys文件，它和id_rsa.pub一模一样。 1cp id_rsa.pub authorized_keys 9.修改权限 12chmod 600 ~/.ssh/authorized_keyschmod 700 ~/.ssh 10.在本地主机上打开cmd，使用ssh方式连接云服务器。 1ssh -v git@123.57.60.151(这里填的是服务器公网ip) 11.输入密码之后，看到如图，即代表成功！！！！ 12.创建一个git的仓库，并且新建一个post-receive文件。 1234567891011121.创建并初始化Git仓库cd ~git init --bare blog.git2.新建post—receive文件vi ~/blog.git/hooks/post-receive3.输入以下内容：git --work-tree=/home/www/website --git-dir=/home/git/blog.git checkout -f4.保存退出之后赋予可执行权限chmod +x ~/blog.git/hooks/post-receive 至此，服务器端的配置完成！！！！！！！！ 二、本地主机配置说明： 因为我之前没有云服务器的时候，是把博客部署在github仓库中的，所以，在下面的config.yml中会出现两个仓库，这并不影响，他会同时部署到github中和云服务器上，想要了解的话可以去看这篇文章：https://blog.csdn.net/weixin_44861399/article/details/104673527，下面就是正式的，将本地主机与服务器连接起来的具体步骤了。 ①安装git下载地址：https://git-scm.com/download/win ②安装Node.js下载地址：http://nodejs.org/download/ 安装的时候，选择add to path，他会自动配置环境变量。 123node -vnpm -v出现版本号说明安装成功 换镜像（亲身体验，可以省去以后好多麻烦） 1npm install -g cnpm --registry=https://registry.npm.taobao.org ③安装Hexo 用cnpm全局安装，在桌面右键打开Git bash here输入： 1cnpm install -g hexo-cli 安装完成后，在命令行里输入hexo -v检查是否安装成功。 ④hexo本地部署 在本地新建一个文件夹，我命名它为blog 在这个文件夹下，右键打开Git Bash here，输入hexo init，我在这个地方出现了一个WARN，暂时不用管它。 继续输入cnpm install可以看到blog文件夹里出现： 输入：hexo g 输入：hexo s 打开浏览器输入localhost：4000，可以看到部署好了，有一篇hello World的博客 ⑤连接到远端服务器 安装 deployer 插件 1cnpm install hexo-deployer-git --save 打开F:\\blog\\_config.yml,找到 deploy。填写你自己的仓库名字。不能同时又相同的repo，需要删除一个。 至此，本地主机的配置也完毕了！！！！ 三、发布文章 写一篇文章： 123451.新建文章，并编写，如何编写，百度hexo new \"Hello My First Blog\"2. 发布(要在blog文件夹下打开git)hexo clean &amp;&amp; hexo generate --deploy 重启服务器的nginx 1nginx -s reload 浏览器地址栏中输入公网ip查看成果。 四、美化博客请参考我的这篇文章：https://blog.csdn.net/weixin_44861399/article/details/104646946","link":"/3010328778/"},{"title":"建站系列之---备份本地站点到github上","text":"试想一下，就你自己的电脑上配置了hexo，平时写博客，部署都是在自己电脑上，那万一有一天，用的不是自己电脑，又想要写博客，那怎么办呢？此时就要用到git了，将你的站点配置等信息备份到github上，要用的时候，用 git clone到本地。而且好处不仅如此，万一哪天出了问题，有个备份，岂不美哉？ 一、本地配置 由于是在个人电脑上配置的hexo，部署也不方便，如果在另外一台机子上写博客，没有hexo的配置也不行，另一方面出于备份项目的目的，最好的办法是将本地hexo站点备份到Github上。 1.新建hexo文件夹存放分支工作目录。 1mkdir hexo 2.把你的GitHub的远程仓库克隆到hexo文件夹 1git clone https://github.com/DAQ121/DAQ121.github.io hexo 3.删除除了版本管理的.git之外的所有文件和文件夹 12cd hexorm -r * 4.把要备份的文件复制到hexo目录 123456scaffolds/source/themes/.gitignore_config.ymlpackage.json 5.如果使用的主题是从Github克隆的，那么使用命令删除它的Git文件（以next主题为例）,否则无法将主题文件push 1rm -R themes/next/.git* 二、github配置1.github创建一个hexo分支 1git checkout -b hexo 2.保存所有文件到暂存区 1git add --all 3.提交变更 1git commit -m \"创建hexo分支\" 4.推送到github，并用--set-upstream与origin创建关联，将hexo设置为默认分支 1git push --set-upstream origin hexo 三、合并管理 现在有两个需要管理的文件夹，一个是blog，一个是hexo，但是每次发布文章的时候如果要提交两次就很失效率， 1.将本地hexo分支中的.git文件夹复制到blog根目录中 1cp -a .git ../blog 2.master分支的文件则由hexo管理，编辑hexo配置文件_config.yml 1234deploy: type: git repo: https://github.com/DAQ121/DAQ121.github.io branch: master 四、发布文章1.新建文章 1hexo new test 2.将相关更改推送到hexo分支 123git add .git commit -m \"发表文章test\"git push origin hexo 3.将静态文件推送到master分支 12hexo clean hexo d -g 五、使用的时候如何迁移1.将hexo分支克隆下来 1git clone -b hexo http://github.com/DAQ121/DAQ121.github.io 2.安装hexo依赖 1cnpm install 3.只不过每次发文章的时候，要输入用户名和密码。","link":"/3220545803/"},{"title":"操作系统的结构与功能","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对操作系统的种类和发展历史有了一个基本了解之后，就正式开始学习操作系统了，首先要明白操作系统是做什么的，它的结构是什么样的，我粗略总结出以下知识点。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我在此推荐一个B站视频，是哈工大的一位叫孙志岗的老师，讲课很幽默，而且干货很多，他的视频是平时上课时候得一些录播，虽然播放量不是很理想，但我个人觉得，比那些照着PPT念，播放量动辄几十万的老师强太多。课程链接：点我直达！ 操作系统的结构基础知识点 系统调用：可以理解为在操作系统内核当中的一个函数，这个函数对应用程序来说，是不可以被直接访问的。应用程序可以访问的是API接口，API有办法进系统内核中去执行相应的程序 windows操作系统提供出API应用编程接口，但是linux不一样，linux不需要通过这个接口来调用。 目前世界上有三套API接口，WIN32 API，POSIX API（被unix广泛应用，很多应用程序是针对他编写的，就要提供相应的接口，以及参数），JAVA API(JVM)。 系统中就像是有一条分割线，上面是用户模式（运行的都是应用程序），下面是内核模式（操作系统的内核）。分割起到保护作用，用户态里的应用程序，不可能随便访问内核里的资源。交互就要用到系统调用了。 例如C语言里面的printf（），它就是调用了系统程序write（）， 应用程序不可以访问内核，但是系统可以访问应用程序的内核。只不过要多一些步骤。 系统程序通常和系统中的功能比较近，帮助我们完成系统里的重要职能。 比较常用的系统程序：复制拷贝文件（属于资源管理器就是系统程序） 一般很少用到的系统程序（磁盘分区，系统快照，磁盘碎片整理） 操作系统的设计之道 软件的体系结构是根据操作系统来的，操作系统就是早期最大的软件。 而操作系统的体系结构是从建筑学中学来的 操作系统的结构 由于用户应用程序可以直接调用系统程序，所以 DOS系统结构很惧怕病毒。 做到了对内核的保护，应用层和系统层分离，但是在内核中是没有结构的，就造成了内核中错综复杂混乱的局面，牵一发而动全身，有一点出问题，内核全完蛋。 层次结构：上层调用下层的功能，下层向上层返回数据，不允许跨层访问。这种理念也映射到信息封装，隐藏，方方面面都有。 微内核，相比以前的大内核，有了很多好处，把更多的功能分给了用户空间（磁盘，网络管理都放到了用户空间）。这样的微内核带来了系统的稳定和安全，但是做什么都要经过内核，这样就导致效率低下。 Solaris Modular系统，无可比拟，强大，比uniux， linux强很多。 Macos，混合系统，两个内核BSD（聚内核）+Mach（微内核） 虚拟机结构（在操作系统之上装一个虚拟机，虚拟机中又可以再装不同的操作系统。） 未来的虚拟机结构（在硬件之上直接装一个虚拟机，在虚拟机中装不同的内核），集群系统，大型机房常用。 小故事 最初设计unix的时候，是用汇编语言写的，但是太费劲了，于是找人开发出了C语言，所以uniux和c语言就像鸡和蛋的关系，不知道谁先有，而最初设计uniux就是为了玩游戏。所以说C语言非常适合用来编写操作系统。 跟硬件实打实的打交道的程序，只能用汇编语言来编写，其他语言更别说了，C语言也不行。 操作系统的功能一、进程管理（cpu管理） 进程控制：（创建，暂停，唤醒，撤销） 进程调度：调度策略，优先级 进程撤销：进程间通信 二、内存管理 内存分配 内存共享 内存保护 虚拟内存管理 三、设备管理 设备的分配和调度 设备的无关性 设备传输控制 设备驱动 四、文件管理 存储空间管理 文件的操作 目录的操作 文件和目录存取权限的管理 总结： 提供接口供用户使用 分配和管理资源","link":"/3546768407/"},{"title":"JSP模式&&MVC模式","text":"一个项目有一个好的设计模式很重要，有一个好的设计模式，使得开发和维护也变得简单。MVC是一种程序开发设计模式，他实现了显示模块与功能模块分离，提高了程序的可维护性，可移植性，可扩展性，可重用性，降低了程序的开发难度。 JSP模式&amp;MVC模式 MVC=model（模型）+view（视图）+contorller（控制） 商城=仓库（模型）+店铺（视图），（控制）店铺去仓库拿货（取数据） MVC工作机制 用户操作，将指令送到Conntoller（控制器）。 控制器将指令和数据传递给业务模型（model）。 模型进行业务逻辑判断，数据库存取。 根据业务逻辑选择不的视图（View）展示给用户 MVC设计模式可以分为两种：闭环和开放，但是开放派中（controllor）的职责过重。下面是闭环的优点： 耦合性低，实现了用户显示模块与功能（业务逻辑）模块的分离 提高应用系统的可维护性，可扩展性，可维护性，以及模块功能的复用性。 缺点： 对于简单的页面来说，会增加结构的复杂性，产生过多的更新操作，降低运行效率，而且使用的时候要精心计划，由于模型和视图严格分离，给调试程序带来了一定的困难。 不适合中小应用程序，设计比较麻烦，用在中小应用上，或者改造一些工具来适应MVC，也是得不偿失的！！","link":"/2199266903/"},{"title":"数据库连接池","text":"数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个；释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。这项技术能明显提高对数据库操作的性能。 一、概述 数据库的连接对象创建工作，比较消耗性能。 一开始现在内存中开辟一块空间（集合） ， 一开先往池子里面放置 多个连接对象。 后面需要连接的话，直接从池子里面去。不要去自己创建连接了。 使用完毕， 要记得归还连接。确保连接对象能循环利用。 连接池指：创建一个池子（容器） ， 专门用来管理连接对象。 二、作用 创建和管理连接，对数据的操作没有影响。 更快响应速度，连接池里的连接在一开始就已经创建好了，后面如果需要直接拿就可以了，无需创建。 资源的重复利用、避免重复创建对象，连接对象使用完毕后，再归还到池子中进行统一管理即可。 三、自定义数据库连接池12345678910111213141516171819202122232425262728293031323334/* * 这是一个数据库连接池 * 一开始先往池子里面放十个连接 */public class MyDataSource implements DataSource {//创建一个集合用来存放连接对象 List&lt;Connection&gt; list=new ArrayList&lt;Connection&gt;(); //用一个构造方法，刚开始就给这个池子里放入10个连接对象 public MyDataSource() { for (int i = 0; i &lt; 10; i++) { Connection conn = JDBCUtil.getconn(); list.add(conn); } } // 该连接池对外公布的获取连接的方法 @Override public Connection getConnection() throws SQLException { //来拿连接的时候，先看看，池子里面有没有，没有了就再添加，扩容 if(list.size()==0) { for (int i = 0; i &lt; 5; i++) { Connection conn = JDBCUtil.getconn(); list.add(conn); } } Connection conn=list.remove(0); return null; } //用完之后返回连接对象 public void addBack(Connection conn) { list.add(conn); } 使用连接池 1234567891011121314151617181920212223242526public class TestPool { @Test public void testPool() { Connection conn=null; PreparedStatement ps=null; MyDataSource dataSource=new MyDataSource(); try { conn=dataSource.getConnection(); String sql=\"insert into category values(null,'lisi',daq)\"; ps=conn.prepareStatement(sql); ps.executeUpdate(); } catch (SQLException e) { e.printStackTrace(); }finally { try { ps.close(); } catch (Exception e) { e.printStackTrace(); } //归还连接对象 dataSource.addBack(conn); } }} 出现的问题 对象没有做成单例。在哪里使用，都需要new MyDataSource(). 这就会造成有多个对象的情况出现， 那就不只一个池子了。 需要额外记住 addBack方法。由于sun公司定义的数据库连接池里面并没有这个addBack方法，所以要用这个连接池的时候，需要记住这个方法是用来回收连接对象的。 无法面向接口编程。由于连接池直接定义成了一个类，并且里面还额外添加了一个addBack方法，这就造成了无法面向接口编程。 解决思路：由于多了一个addBack 方法，所以使用这个连接池的地方，需要额外记住这个方法，并且不能面向接口编程。 修改接口中的close方法。 原来的Connection对象的close方法，是真的关闭连接。 修改此close方法，以后在调用close， 并不是真的关闭，而是归还连接对象。如何扩展某一个方法? 原有的方法逻辑，不是我们想要的。 想修改方法的逻辑，怎么办？ 直接改源码 无法实现。 继承， 必须得知道这个接口的具体实现是谁。 使用装饰者模式。 动态代理 解决方式：装饰者模式两个不同的人，去实现同一个接口，先把我的方法执行了，再执行你的。 四、开源连接池DBCP DBCP（DataBase Connection Pool）数据库连接池，是java数据库连接池的一种，由Apache开发，通过数据库连接池，可以让程序自动管理数据库连接的释放和断开。 12345678910111213141516171819202122232425262728293031323334353637383940411.导入jar包 commons-dbcp.jar和commons-pool.jar2.不使用配置文件方式（不常用） // 1.构建数据源对象 BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); //Url格式-主协议：子协议：//本地//数据库 dataSource.setUrl(\"jdbc:mysql://localhost/users\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"daq\"); // 2.得到连接对象 conn = dataSource.getConnection(); String sql = \"insert into user values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1,\"daq\"); ps.setInt(2,23); ps.executeUpdate(); ...3.使用配置文件方式。(常用) 1. 在 src 下定义配置文件 dbcp.properties. 内容如下： //连接设置 driverClassName=com.mysql.jdbc.Driver url=jdbc:mysql://localhost:3306/jdbc username=root password=daq ... 2. 使用代码读取配置文件，即可获取连接池 BasicDataSourceFactory factory=new BasicDataSourceFactory(); Properties properties = new Properties(); properties.load(new FileInputStream(\"src/dbcp.properties\")); DataSource dataSource =factory.createDataSource(properties); conn = dataSource.getConnection(); String sql = \"insert into user values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1,\"daq\"); ps.setInt(2,23); ps.executeUpdate(); ... C3P0（重点） C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate，Spring等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748491. 拷贝jar 文件 c3p0-0.9.1.2.jar2. 不使用配置文件方式（开发的时候不会用） //默认会找 xml 中的 default-config 分支。 ComboPooledDataSource dataSource = new ComboPooledDataSource(); //2. 设置连接数据的信息 dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/users\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"daq\"); //3. 获取连接对象 conn = dataSource.getConnection(); String sql = \"insert into user values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1,\"daq\"); ps.setInt(2,23); ps.executeUpdate(); ... 3. 使用配置文件方式。（开发常用）c3p0的配置文件 支持 properties , 也支持 xml 方式。 不过开发中，一般使用xml方式来配置 1. src下， 创建xml文件，名为：c3p0-config.xml 注意此处，名字需要固定了。 &lt;c3p0-config&gt; &lt;default-config&gt; &lt;property name=\"driverClass\"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=\"jdbcUrl\"&gt;jdbc:mysql://localhost/user&lt;/property&gt; &lt;property name=\"user\"&gt;root&lt;/property&gt; &lt;property name=\"password\"&gt;daq&lt;/property&gt; &lt;!-- 可选配置 --&gt; &lt;property name=\"initialPoolSize\"&gt;10&lt;/property&gt; //初始容量 &lt;property name=\"maxIdleTime\"&gt;30&lt;/property&gt; // &lt;property name=\"maxPoolSize\"&gt;100&lt;/property&gt; //最大容量 &lt;property name=\"minPoolSize\"&gt;10&lt;/property&gt; //最小容量 &lt;property name=\"maxStatement\"&gt;200&lt;/property&gt; // &lt;/default-config&gt; &lt;/c3p0-config&gt; //1. 代码中获取连接dataSource对象 ComboPooledDataSource dataSource = new ComboPooledDataSource(); //2. 获取连接对象 conn = dataSource.getConnection(); String sql = \"insert into user values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1,\"daq\"); ps.setInt(2,23); ps.executeUpdate();","link":"/1664209794/"},{"title":"Ubuntu18.04系统安装，修改源","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于疫情在家，看着家里有一台吃了一两年灰的台式电脑，大概是初三的时候买的，抹一下灰就跟新的一样，哈哈，于是突然心生一计，就开始动手整理这台电脑，首先重装系统，不过这次，我装的是win10+Ubuntu18.04双系统。 一. 准备： 终端如何复制粘贴？在文本区域左键复制，到终端里面直接按下鼠标滚轮即可。 如何切换root权限？安装之后root是不设置密码的，以普通用户输入su root按照步骤设置自己的密码 工具： 大于4G的U盘一只，事先将里面的文件备份到电脑中。 第一步：下载Ubuntu系统镜像——-后缀.iso的配置文件。因为是外网，所以去官网下载需要自备**（真是把我累伤心了），于是我找到了国内的开源网站：https://blog.csdn.net/davidhzq/article/details/102575343 第二步： 制作U盘启动盘—–需要下载USBWiter这个工具用来写入ISO镜像，下载地址：http://mydown.yesky.com/pcsoft/413551662.html 解压后打开小工具： 第三步： 还要在硬盘腾出一块空间用来安装Ubuntu系统，具体操作如下：以管理的身份打开“我的电脑”，如图所示： 压缩完之后，就不用管了，会看到你刚才压缩的那个卷之后，会有一块空闲的空间。 二.开始安装：第四步： 拿着你做好的U盘，插到你要安装系统的电脑上，在开机的时候，会看到： 如果没有的话，可能是你开机设置里不允许用U盘启动，我当时就遇到了这种情况，然后狂点F12，进入BIOS，主要是为了进入BIOS，不同型号的电脑按键不一样，自己上网查，按如下图设置后，按F10，保存并重启。 第五步：)) )) 后面就一步一步点击继续就可以了，最后等待安装完成 在安装过程中遇到的问题： 最后的最后，还是一个人抗下了所有，安装崩溃了，我心态也奔溃了，但是重振旗鼓，找到问题：GRUB的引导问题，也找到了解决方案：https://blog.csdn.net/weixin_44123547/article/details/103243238最终还是安装完成了： 三. 修改源：因为Ubuntu默认下载源是国外源，我们修改为国内源，我改的是清华的源。打开终端，切换到root权限输入以下命令： 1、备份1cp /etc/apt/sources.list /etc/apt/sources.list.bak 2、修改sources.list文件1vi sources.list 3、修改源（复制进去）12345678910deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricteddeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricteddeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricteddeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security multiverse 4、 更新源1sudo apt-get update 完成后，输入： 1sudo apt-get upgrade 5、大功告成","link":"/linux/"},{"title":"<<小狗钱钱>>","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在B站看了半佛仙人一期关于理财的视频，视频里面也推荐了很多值得一看的书，有《小狗钱钱》，《海龟交易法则》，《经济学原理》，我首先看的是小狗钱钱，写下了这篇读后感。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这本书是美国的一版儿童理财读物，虽然说是儿童读物，但在我看来，实际上就是用孩子能够理解的故事，讲述一些大人都未必清楚的一些道理，这些道理可能直白的说出来，成人都懂，可是又有谁能够贯彻到生活中呢？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大致内容讲的是，小女孩吉娅的爸爸妈妈陷入了财政窘迫的时期，吉娅意外的捡到了一条狗，而这是一条会说话的狗，名字就叫钱钱，机缘巧合，钱钱开始教吉娅理财知识，吉娅一步一步富有了起来，并且也帮助爸爸妈妈摆脱了财政窘境。我看完这本书，并不能说从中学到了什么知识，知识把以前了解到的理财观念加深了，就像那句话：道理咱都懂！！！可他并没有深入你的骨髓，这才是关键。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我将重要的理念罗列以下： (一)做自己喜欢做的事&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不要为了挣钱而去挣钱，尤其是在我们这个年纪，通过打工，兼职挣来的钱，如果只是满足自己的消费欲望，那将毫无意义，如果将这些钱用在正道上，比如说买书，买课程，提高自己的修养与知识积累，那暂且还花对了地方，对我们这个年纪的学生，真正的意义是提升自己的能力，然后再去赚钱，换句话说，就是用自己的专业技能变现，如果专业技能达不到要求，那就将赚钱一事先放在一边，提升技能放在第一位，毕竟以后还是要靠本事吃饭，当你的专业技能足够好时，就不愁赚不到钱，这个时候就要找渠道了。 (二)把钱分成日常开销。梦想目标，和账户三部分&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;日常开销是刚需，这个必不可少，但也不要追求过高的消费，如果超出了自己经济承担范围，那么将所剩无几，梦想目标是指，心中有一个或者多个明确的目标，并且用小本本将他们记下来，估计达成这个目标需要多少钱，多少时间。单独为他们开一个账户，当然这里的账户是指形式上的，目的就是为了实现这些目标而去存钱。 (三)进行明智的投资&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;投资是一门高深的学问，我觉得入个门还是很有必要的，毕竟等到以后，人到中年了，还是靠着储蓄过日子，并不是理想的生活，我身边有很多长辈有观念上的错误，他们就是将挣到的钱定期存进银行里，一存就是五到十年，吃定期的利息，然而他们并想不清楚，你吃银行的利息，通货膨胀在吃你的本金，对于他们那一代人，这个观念既然不能扭转，那就从我们这一代人做起吧，培养理财意识，学习投资方式，也是一种赚钱的利器，万年亘古不变的道理：投资有风险！！！明智的投资会帮你入账不少，而一旦看错了眼，亏损也是常有的事，这就需要长期的积累经验，形成意识了，投资—得先从韭菜做起。 (四) 关键在于自信程度&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是一个老生常谈的话题，听过很多道理，喝过很多鸡汤，尝试过很多次，然而至少就我个人而言，我是一个没有自信的人，我顶多算是一个脸皮比较厚的人，自信和自卑是对立的，但是他们同样都是骨子里的东西，我们都活了二十多年了，经历的事也不少了，生活环境等等因素，到底是帮我们养成了自信，还是形成了自卑，只有我们自己清楚，深入骨髓的东西很难完全改变，但未必是坏事，在做任何事情的时候，保持谦逊的同时，也要掌握50%的主动权。 (五) 你最好想清楚你喜欢做什么，然后再考虑怎么用它来挣钱&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正如上面所说的，不为挣钱而做一些没有意义的事，年轻人，多提升以下自己。花时间花精力修炼内功，学习，比什么都重要。 (六)欠债的人应该毁掉所有的信用卡&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里毁掉信用卡，并不是真正意义上的毁掉，就像那些段子：只要你卸载掉支付宝，你就不用还花呗了，对于花呗这个东西，该怎么去形容你最贴切？拿什么跟你作比较才算特别？还是要看用途的，如果是为了缓解经济压力，（这里的经济压力是指，你做了某些有意义的事后，欠下的债），有短期之内不要利息的钱用，何乐而不为呢？但是如果要是为了用这个花呗满足自己的消费欲望，那我觉得还是大可不必了，个人觉得，这种做法，是最low的，买不起我就不买。又不是必需品。还花呗的时候，也要在不收取利息的时候，还最低还款，但是要保证，最终能还清。 (七)真的有必要吗？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;花钱买一样东西的时候，事先考虑有没有必要，你是真的需要他吗？买了之后有什么用？能给你带来你预期的效果吗？能用多久？有更好的替代品吗?一般，扪心自问这些问题之后，你就应该知道，该不该买了。得出买不买的结论之后，就要考虑，买什么样的？现在这个信息错综复杂的互联网时代，各种测评，各种推荐，各种大数据分析，最后到你手里的，也许达不到你的预期，什么性价比乱七八糟的，哪儿有什么性价比，都是些商家搞出来唬人的噱头，你真的能看准东西吗？所谓性价比，大部分就是低价配low货，想买的东西，就别去占便宜。你占的便宜最终都会反映在产品上。 (八)当你定下大目标的时候，就意味着你必须付出比别人更多的努力。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我以前考四级的时候，考教师资格证，都没过，包括这次四级430分险过，是因为我没有努力吗？不是，我努力了，周围也有人裸考过了的，并且分比我高多了，羨慕吗？不羡慕，因为我努力过，我没过的原因是我的方法不对，也是努力的不够，你努力了不一定会成功，但你不努力，一定不会有结果，当然也有幸存者偏差，对于天生聪明，基础好的人，可能有些时候会听到这样说：没那个必要，这个也没什么实际意义。但是我始终会坚持自己的理念：当我定下大目标的时候，就意味着必须付出比别人更多的努力。幸运其实是充分准备加上努力工作的结果。 (九)克服畏惧心理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;恐惧总是在我们设想事情会如何不顺利的时候出现，我们对失败的可能性想得越多，就越害怕，当你朝着积极地目标去思考的时候，就不会心生畏惧，我从小一直到现在，都没有真正意义上上台讲演过，我永远都是那个坐在台下为他人喝彩的观众，感叹她们真有魄力啊，就连在班级里做个自我介绍我都会脸红，我害怕面对很多人，害怕出糗，也不是没有过讲演的机会，因为我的畏惧，我也不知道我什么时候能踏出这一步，但是我会尽力克服自己的恐惧，等下次机会到来的时候，我不会拱手让人的。 (十)72定理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;72定理：用72除以投资的年收益率的百分比，得出的数字就是这笔钱翻一倍所需要的年数，用72除以通货膨胀率的百分比，得出的数字就是这笔钱贬值一倍所需要的年数。还补充一点就是挑选基金时注意哪些问题：1.基金至少有十年历史，也就是所谓的老基金2.选择大型的跨国股票基金，以分散投资风险3.了解基金的走势图，合理利用72定理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其实之前说看完这本书，我并没有学到多少知识，这句话太过于自大，文章写到这里，我才发现，原来小狗钱钱教会我的东西并不少。去合理利用自己的money吧！！！","link":"/read.html/"},{"title":"操作系统---死锁","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。简单理解就是： 我想要你手里的东西，同时你也想要我手里的资源，我俩同时都不让出来，谁也拿不到。 为什么会产生死锁？ 系统资源的竞争： 当系统中供多个进程共享的资源如打印机、公用队列的等，其数目不足以满足诸进程的需要时，会引起诸进程对资源的竞争而产生死锁。 进程运行推进顺序不当引起死锁： 若P1保持了资源R1,P2保持了资源R2，系统处于不安全状态，因为这两个进程再向前推进，便可能发生死锁。例如，当P1运行到P1：Request（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2：Request（R1）时，也将因R1已被P1占用而阻塞，于是发生进程死锁。 产生死锁的必要条件 互斥条件： 指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。 请求与保持条件： 进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 不可剥夺条件： 进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。 循环等待条件： 指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 解决策略：死锁的避免与预防死锁避免的基本思想：系统对进程发出每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，如果分配后系统可能发生死锁,则不予分配，否则予以分配。这是一种保证系统不进入死锁状态的动态策略。理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。只要打破四个必要条件之一就能有效预防死锁的发生： 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。 打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。 打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。 死锁预防和避免的区别 死锁预防是设法至少破坏产生死锁的四个必要条件之一，严格的防止死锁的出现。 死锁避免则不那么严格的限制产生死锁的必要条件的存在，因为即使死锁的必要条件存在，也不一定发生死锁。死锁避免是在系统运行过程中注意避免死锁的最终发生。 死锁的检测和恢复 并没有实际卵用 鸵鸟算法 核心思想： 装作没看见 为什么会用鸵鸟算法？上面的一些做法，组织啊，恢复啊，无一例外会给系统带来很多沉重的负担。一方面给系统添加，另一方面解决的问题发生的概率不大，吃力还不讨好。而且，死锁发生的原因是由于程序设计人员写出来的问题，操作系统当然不会予以理会。所以死锁的问题都是交给程序设计人员来解决。","link":"/1179211128/"},{"title":"比特币的价格是怎么算出来的","text":"- 首先了解一下拍卖 英式拍卖： 如果拍卖方（卖方）要卖一个商品，那么买方则通过集体竞价的方式进行拍卖，价高者得，最后和卖方成交的一定只有一个买家，而这个买家一定是出价最高的那位。 荷兰式拍卖： 假如有一个买家想要买一个商品，但是卖方有很多，那么卖方递减报出新的价位，最终和买方成交的一定是卖价最低的那位。 实际定价方式在交易所看到的一排排红色的数字和一排排绿色的数字其实就是许多的买方和许多的卖方不断报出的买进价和卖出价，价格随供求变化而不断变动。买者和卖者彼此竞争，双向拍卖，买者对想要买进的出价，通过竞争以最低价买入;卖者也互相竞争，试图以最高价格出售，然而最新成交价一定是买卖双方达成一致的那个价格。买卖双方不断成交，最新一笔的成交价就是我们看到的不断变化的价格，这就是为什么价格在一直变化的原因。报价后面的数量，即代表当前的买方或者卖方想要购买或者卖出的币的数量。买卖一旦成交，则不得反悔。在未成交以前，也可以撤单，撤单程序与买卖委托的过程基本相同。 限价，市价，止盈止损 限价：是自己设定价格进行挂单，需价格波动到设定价格并有对手愿意交易才可以成交。 市价：市价是以当前最新成交价挂单，一般马上成交。 止盈止损：止盈止损即是带有预期的未来买入或者卖出行为，比如当价格跌破某一价位时进行止损（你预期跌破此价格可能还会继续跌），或者当价格突破某一价位时进行买入（你预期价格一旦突破该价位时将会继续上涨）。 补充如果你是买方，想要尽快购入比特币，当然是设置买入价格与当前最低卖出价格一致，这样双方就可以达成交易了，想要尽快卖出比特币，那就设置卖出价格与当前最高买入价格一致。但是市场上的人并不是都急切的想要卖出或者买入，会带有预期的进行买入卖出报价。","link":"/2526071924/"},{"title":"操作系统---文件系统","text":"正在更新中。。。。 常见的文件系统 常见的文件系统有：：FAT、NTFS、ExtFAT、ext2、ext3、reiserFS、VFAT、APFS FAT: FAt12、FAT16、FAT32均是Fat文件系统，最初是为软盘设计的文件系统，但是后来随着微软推出dos和win 9x系统，FAT文件系统经过适配被逐渐用到了硬盘上。 NTFS： 对FAT和HPFS作了若干改进，例如，支持元数据，并且使用了高级数据结构，以便于改善性能、可靠性和磁盘空间利用率，并提供了若干附加扩展功能。NTFS是一个日志文件系统，这意味着除了向磁盘中写入信息，该文件系统还会为所发生的所有改变保留一份日志。这一功能让NTFS文件系统在发生错误的时候（比如系统崩溃或电源供应中断）更容易恢复，也让这一系统更加强壮。在这些情况下，NTFS能够很快恢复正常，而且不会丢失任何数据。在很少出错情况下，微软表示你需要运行CHKDSK修复程序来对磁盘卷进行维护的概率特别低，其概率不到1%。 ExFAT： 也是微软开发的文件系统，它是专门为闪存盘设计的文件系统，单个文件突破了4G的限制，而且分区的最大容量可达64ZB，建议512TB。 ExFAT在windows，Linux以及Mac系统上，都可以读写，作为U盘或者是移动硬盘的格式还是比较合适的。 补充：EFI 系统分区： 通常指数据存储介质中的一个分区，通常用于硬盘或固态硬盘。它通常应用于 Unified Extensible Firmware Interface (UEFI)。当电脑通电启动时，UEFI会读取ESP 用来安装操作系统和各种实用工具。ESP需要格式化成FAT文件系统并且挂载至UEFI指定的位置。UEFI： 统一可扩展固件接口（Unified Extensible Firmware Interface）是一种个人电脑系统规格，用来定义操作系统与系统固件之间的软件界面，作为BIOS的替代方案。可扩展固件接口负责加电自检（POST）、联系操作系统以及提供连接操作系统与硬件的接口。","link":"/2892727560/"},{"title":"数字货币的种类","text":"当前的数字货币大致有以下几种。 BTC： 比特币 ETH： 以太币 USDT： 泰达币（与同数量的美元是等值的） EOS： 为商用分布式应用设计的一款区块链操作系统。EOS是引入的一种新的区块链架构，旨在实现分布式应用的性能扩展。注意，它并不是像比特币和以太坊那样的货币，而是基于EOS软件项目之上发布的代币，被称为区块链3.0 。 XRP： 瑞波币。它是基于Ripple协议的虚拟货币，主要功能有二：1.防止恶意攻击；2.桥梁货币。 LTC： 莱特币。 HT： 火币 HUSD： 稳定币 BCH：","link":"/undefined/"},{"title":"火币网--币币交易图解","text":"如何在火币网上执行币币交易 BTC/USDT：BTC对USDT的交易对，相当于平均1个BTC当前需要9211.76个USDT来购买，后面的64574.43CNY是说9211.76个USDT约等于64574.43人民币。 涨幅+0.01%是今天此时此刻比特币的价格相对于昨天的这个时候价格涨了0.01%，如果是红色的-0.01%就代表跌了0.01%。 高9320.00 低9100.00是过去24小时最高9320.00USDT最低9100.00USDT。 24H量：是过去24小时火币网交易了28878个比特币。这只是在火币网交易的数量。 上面一排时间是，选择显示这个时间段的数据，比如我选择的是1min，那么k线图中每一个红色或者绿色的柱就代表这一分钟内的走势。 时间下面的一排：11：24这个时间点的开盘价，最高价，最低价，收盘价，成交量。 MA均线：（MA）理论是股市最常见的一种技术分析方法，它对股市操作具有神奇的指导作用。 绿色柱状：柱底代表开盘价，柱顶代表收盘价，红色则相反。 柱上下的细线：上影线，下影线，分别代表在这一分钟内的最高价和最低价。 图中标有今日最高，和今日最低。严谨理解为：从今日凌晨到目前为止的最高价与最低价。 均线分析方法：","link":"/undefined/"},{"title":"股票基本术语","text":"股票基本术语了解。 A/B/H/蓝筹股&amp;债券&amp;基金 A股： 人民币普通股票，由我国境内的公司发行，供境内机构、组织、或个人(不含台、港、澳投资者)以人民币认购和交易的普通股票。 B股： 人民币特种股票，以人民币标明面值，以外币认购和买卖，在境内(上海、深圳)证券交易所上市交易的。B股公司的注册地和上市地都在境内。 H股： 港股：即注册地在内地、上市地在香港的外资股。 在香港上市外资股就叫做H股，纽约和新加坡上市的股票分别叫做N股和S股。 蓝筹股： 多指长期稳定增长的、大型的、传统工业股及金融股。“蓝筹”一词源于西方赌场，在西方赌场中，有三种颜色的筹码（蓝，红，白）、其中蓝色筹码最为值钱。 债券： 政府、企业、银行等债务人为筹集资金,按照法定程序发行并向债权人承诺于指定日期还本付息的有价证券。 开放式基金：（Open-end Funds）又称共同基金,是指基金发起人在设立基金时，基金单位或者股份总规模不固定，可视投资者的需求，随时向投资者出售基金单位或者股份，并可以应投资者的要求赎回发行在外的基金单位或者股份的一种基金运作方式。投资者既可以通过基金销售机构买基金使得基金资产和规模由此相应的增加，也可以将所持有的基金份额卖给基金并收回现金使得基金资产和规模相应的减少。 基础知识 原始股： 是公司在上市之前发行的股票。在中国股市初期，在股票一级市场上以发行价向社会公开发行的企业股票。 概念股： 是指具有某种特别内涵的股票，与业绩股相对而言的。业绩股需要有良好的业绩支撑。而概念股是依靠某一种题材比如资产重组概念，三通概念等支撑价格。而这一内涵通常会被当作一种选股和炒作题材，成为股市的热点。概念股是股市术语，作为一种选股的方式。相较于绩优股必须有良好的营运业绩所支撑，概念股只是以依靠相同话题，将同类型的股票列入选股标的的一种组合。由于概念股的广告效应，因此不具有任何获利的保证。 权重股：（weighted stock）就是总股本巨大的上市公司股票，它的股票总数占股票市场股票总数的比重很大，权重就很大，权重股的涨跌对股票指数的影响很大。 借壳上市： 是指一家私人公司（Private Company）通过把资产注入一家市值较低的已上市公司（壳，Shell），得到该公司一定程度的控股权，利用其上市公司地位，使母公司的资产得以上市。通常该壳公司会被改名。 交易时间： 大多数股票的交易时间是四小时，分两个时段：周一至周五上午9：30-11：30和下午13：00至15：00 交易费用： 股票的交易费用通常包括印花税，佣金，过户费，其他费用等。 总市值: 是指在某特定时间内总股本数乘以当时股价得出的股票总价值。 流通市值: 在某特定时间内当时可交易的流通股股数乘以当时股价得出的流通股票总价值。 总股本： 包括新股发行前的股份和新发行的股份的数量的总和。 市盈率： 由股价除以年度每股盈余(EPS)得出(以公司市值除以年度股东应占溢利亦可得出相同结果)。用来评估股价水平是否合理的指标之一。 市净率： 每股股价与每股净资产的比率。市净率可用于投资分析，一般来说市净率较低的股票，投资价值较高，相反，则投资价值较低。 基准日： 就是因股票分红或配股，而进行股价调整的那天。相应的，在这天，红利和红股会配到投资者帐号里。而在基准日前，还有股权登记日。在股权登记日前买入该股票的投资者，享有分红或配股的权利。红利和红股会在基准日打到帐号里。 大盘： 指沪市的“上证综合指数”和深市的“深证成份股指数”的股票。大盘指数是运用统计学中的指数方法编制而成的，反映股市总体价格或某类股价变动和走势的指标。 个股： 是一种无偿还期限的有价证券，按股票持有者可分为国家股、法人股、个人股三种。个人股（individual stock）投资资金来自个人，可以自由上市流通。 涨跌幅=(现价-上一个交易日收盘价）/上一个交易日收盘价*100% 委差 = 委买手数－委卖手数。 委比 = (委买手数-委卖手数)/(委买手数+委卖手数)×100% 换手率： 也称“周转率”，指在一定时间内市场中股票转手买卖的频率，是反映股票流通性强弱的指标之一。成交量/股票总流通量×100% 成交额： 某只股票在一定时间内成交的股票总金额。 平均成交量： 每笔交易的平均成交量，成交量/成交笔数。 成交量： 包括某只股票 当天的成交股数、成交金额、换手率；狭义的也是最常用的是仅指成交股数/手数(1手=100股)；通常人们说的大盘成交量指的是成交金额。 仓位： 是指投资者买入股票所耗资金占资金总量的比例。当一个投资者的所有资金都已买入股票时就称为满仓，若不持有任何股票就称为空仓。 股票操作术语内盘&amp;外盘 内盘（S）：以买入价成交的交易，成交数量统计后加入内盘。 外盘（B）：以卖出价成交的交易。成交数量统计后加入外盘。 内盘，外盘这两个数据大体可以用来判断买卖力量的强弱。若外盘数量大于内盘，则表现买方力量较强，若内盘数量大于外盘则说明卖方力量较强。 洗盘&amp;盯盘 洗盘：投机者先把股价大幅度杀低，使大批小额股票投资者(散户)产生恐慌而抛售股票，然后再把股价抬高，以便乘机渔利。 盯盘：俗称看盘，是股票投资者主要的日常工作。股票市场每时每刻都在变化，股票投资者尤其是短期投资者要掌握股票市场的动向，就要观察分析股市行情的变化，即要学会盯盘。 做多&amp;做空 做多： 指的是多仓，也可以叫利多，买入某种货币，看涨。 做空： 指的是卖仓，也可以叫利空，卖出某种货币，看跌。 多头&amp;空头 多头： 指投资者对股市看好，预计股价将会看涨，于是趁低价时买进股票，待股票上涨至某一价位时再卖出，以获取差额收益。 空头： 空头是投资者和股票商认为现时股价虽然较高，但对股市前景看坏，预计股价将会下跌，于是把借来的股票或者是原有持仓及时卖出（补空），待股价跌至某一价位时再买进，以获取差额收益。 涨停&amp;跌停 涨跌停板：是证券管理部门为了防止过度的投机而采取的一种措施，是指一只个股每天的最大涨跌幅度不能超过前一交易日的百分比。普通的股票最大涨跌幅为前一交易日的10%。新股上市首日不设涨跌幅限制。 熔断 熔断机制（Circuit Breaker），也叫自动停盘机制，是指当股指波幅达到某设定条件（熔断点）时，交易所为控制风险采取的暂停交易措施，不同于涨跌停板；例如，新股上市首日的规定： 深交所：新股首日盘中成交价较开盘价首次上涨或下跌达到或超过10%即暂停交易，新股首日换手率超50%触发暂停交易。 上交所：新股首日盘中成交价较开盘价首次上涨或下跌达到10%暂停交易30分钟。达到20%，停牌到14时55分，首日换手率超80%触发暂停交易。 回档&amp;反弹 回档：股价呈不断上涨趋势，终因股价上涨速度过快而反转回跌到某一价位，这一调整现象称为回档。一般来说，股票的回档幅度要比上涨幅度小，通常是反转回跌到前一次上涨幅度的三分之一左右时又恢复原来上涨趋势。 反弹：股价呈不断下跌趋势，终因股价下跌速度过快而反转回升到某一价位的调整现象称为反弹。一般来说，股票的反弹幅度要比下跌幅度小，通常是反弹到前一次下跌幅度的三分之一左右时，又恢复原来的下跌趋势。 跳空&amp;补空 跳空：指受强烈利多或利空消息刺激，股价开始大幅度跳动。跳空通常在股价大变动的开始或结束前出现。 补空：是空头买回以前卖出的股票的行为。 阻力线&amp;支撑线 阻力线：股市受利多信息的影响，股价上涨至某一价格时，做多头的认为有利可图，但实际却有大量卖出，使股价至此停止上升，甚至出现回跌。股市上一般将这种遇到阻力时的价位称为关卡，股价上升时的关卡称为阻力线。（大量卖出抑制了价格继续攀升） 支撑线：股市受利空信息的影响，股价跌至某一价位时，做空头的认为有利可图，大量买进股票，使股价不再下跌，甚至出现回升趋势。股价下跌时的关卡称为支撑线。（大量买入支撑起股价，由跌转升） 金叉&amp;死叉 黄金交叉：指短期移动平均线向上穿过中期移动平均线或短期、中期移动平均线同时向上穿过长期移动平均线的走势图形，表示股价将继续上升。 死亡交叉(死叉)：指下降中的短期移动平均线由上而下穿过下降的长期移动平均线，这个时候支撑线被向下跌破，表示股价将继续下落。 补充： 在股票名称前冠以“ST”的股票表示该上市公司最近两年连续亏损，或亏损一年，但净资产跌破面值、公司经营过程中出现重大违法行为等情况之一，交易所对该公司股票交易进行特别处理。股票交易日涨跌幅限制5%。 F10： 股票非行情类的基本面资料统称为股票F10。在各种金融行情终端软件中，用户通过键盘上的F10快捷键，可迅速查看上市公司的非行情信息，诸如：公司概况、财务数据、公司公告、公司新闻、经营分析等等信息数据。","link":"/undefined/"},{"title":"认识web服务器&Eclipse配置部署Tomcat","text":"Web服务器一般指网站服务器，是指驻留于因特网上某种类型计算机的程序，可以向浏览器等Web客户端提供文档，也可以放置网站文件，让全世界浏览；可以放置数据文件，让全世界下载。目前最主流的三个Web服务器是Apache、 Nginx 、IIS。 一、程序架构 C / S (client / server)如：QQ 微信 LOL优点：有一部分代码写在客户端，用户体验比较好。缺点：占用资源大，比较吃硬盘，服务器更新，客户端也要随之更新。 B / S (browser / server)如：网页QQ， 网页游戏。优点：客户端只要浏览器就可以了，占用资源小，不用更新。缺点：用户体验不佳。 二、web服务器 服务器：其实服务器就是一台电脑。 配置比一般的要好。 Web服务器软件 ：客户端在浏览器的地址栏上输入地址 ，然后web服务器软件，接收请求，然后响应消息。 处理客户端的请求， 返回资源 | 信息 Web应用 需要服务器支撑。 index.html 常用web服务器： Tomcat —–apache 免费 WebLogic —–BEA 收费 Websphere —–IBM 收费 IIS —–微软三、安装tomcat 直接解压 ，然后找到bin/startup.bat 安装启动之后，如果能够正常看到黑窗口，表明已经成功安装。 为了确保万无一失， 最好在浏览器的地址栏上输入 ： http://localhost:8080 , 如果有看到内容 就表明成功了。在黑窗口开着的同时输入网址。 出现控制台乱码问题，右键控制台，查看是GBK，还是UTF-8。然后在安装目录中找到conf–logging.properties文件，修改里面的编码方式，保持一致即可。 如果双击了startup.bat, 看到一闪而过的情形，一般都是 JDK的环境变量没有配置。四、Tomcat目录介绍 bin： 包含了一些jar , bat文件 。 startup.bat。 conf：tomcat的配置 server.xml ， web.xml。 lib：tomcat运行所需的jar文件。 logs：运行的日志文件。 temp：临时文件。 webapps：发布到tomcat服务器上的项目，就存放在这个目录。 work：jsp翻译成class文件存放地。 五、Eclipse配置Tomcat Java EE 的视图下，在server里面，右键新建一个服务器， 选择到apache分类， 找到对应的tomcat版本， 接着一步一步配置即可。 配置完毕后， 在server 里面， 右键刚才的服务器，然后open ， 找到上面的Server Location , 选择中间的 Use Tomcat installation… 创建web工程， 在WebContent下新建html文件， 右击工程， run as server 至此成功！！！","link":"/629938038/"},{"title":"比特币的两种交易方式","text":"比特币的交易有很多种，本文了解一下 比特币交易的几种种方式： 场外交易： 也称为法币交易，法币就是法定货币，人民币就是我们国家的法定货币，顾名思义，法币交易就是由法币（人民币）直接与比特币（数字货币）进行交易的行为（购买/出售),可以简单理解为网购。 场内交易： 也称之为币币交易，就是用一种币交易兑换另一种币。 杠杆交易： 利用小额的资金来进行数倍于原始金额的投资。以期望获取相对投资标的物波动的数倍收益率，抑或亏损。由于保证金（该笔小额资金）的增减不以标的资产的波动比例来运动，风险很高。不推荐。 合约交易： 合约交易是指交易双方，在交易所通过买卖合约，并根据约定在未来某一特定时间和地点，以特定价格买卖规定数量商品的行为。合约交易是在现货远期合约交易基础上发展起来的，在交易所内买卖标准化合约的一种新型交易方式。 补充： 法币交易很耗时间，即使交易双方操作熟练，但是还是不排除人为因素造成交易时间拖长，不利于双方观察局势，很有可能在分分钟内错过行情。 币币交易可以在极短时间内成交（按下买入键的瞬间与对手成交）且支持购买的币种更多。 ，","link":"/2670976354/"},{"title":"操作系统---虚拟内存","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是不是经常听到虚拟内存这个名词，尤其是在玩Linux的时候，其实不然，哪个是交换分区，跟虚拟内存还是有差别的。 对一个程序来说，他在某一段时间内，只有某一些部分是需要在内存里面的。（局部性原理），虚拟内存管理，属于一个完全黑盒的封装，我们在使用的时候，几乎不需要考虑他的存在。 虚拟内存的两种实现方式：请求页，请求段。 请求页：如果有一个页面，只有当你真正需要他的时候，才把他加载到内存中来，有很多好处：降低IO操作， 虚拟内存也是一种缓存思想：虚拟内存将主存看成是一个磁盘的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。 从概念上来说，虚拟内存被组织成为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组，也就是字节数组。每个字节都有一个唯一的虚拟地址作为数组的索引。虚拟内存的地址和磁盘的地址之间建立影射关系。磁盘上活动的数组内容被缓存在主存中。在存储器层次结构中，磁盘(较低层L5，参见我们上篇文章图4)的数据被分割成块(block)，这些块作为和主存(较高层,L4)之间的传输单元。主存作为虚拟内存(或者说磁盘)的缓存。 虚拟内存（VM）系统将虚拟内存分割成称为大小固定的虚拟页（Virtual Page,VP），每个虚拟页的大小为固定字节。同样的，物理内存被分割为物理页（Physical Page,PP）,大小也为固定字节（物理页也称作页帧，page frame）。 在任意时刻，虚拟页面都分为三个不相交的部分：①未分配的(Unallocated) ：VM 系统还未分配（或者创建）的页，未分配的页没有任何数据和它们关联，因此不占用任何内存/磁盘空间。②缓存的(Cached)： 当前已缓存在物理内存中的已分配页。③未缓存的(UnCached) ：该页已经映射到磁盘上了，但是还没缓存在物理内存中。 swap分区的作用 linux有一个swap分区。Swap空间的作用可简单描述为：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间中的信息被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。系统总是在物理内存不够时，才进行Swap交换。 电脑开着一个进程，几天不关机，也一直没关闭这个进程，随着运行的程序越来越多，内存快不够用了，所以操作系统就选择将这个音乐播放器的内存状态(包括堆栈状态等)都写到磁盘上的swap区进行保存。这样就腾出来一部分内存供其他需要运行的程序使用。等你要使用到这个进程了。此时， 系统会从磁盘中的swap区重新读取该进程的相关信息，送回内存接着运行。 补充注意在window下也有类作用的硬盘空间，属于对用户不可见的匿名磁盘空间(在C盘)。 特别注意：按照字面意思，swap交换区也可以称为虚拟内存硬盘上的swap交换区，其实就相当于承担了内存的作用(只是速度很慢罢了)。swap交换区起到了扩大内存的作用。所以从某些意义上来讲，swap区也可以叫做虚拟内存，但是这个虚拟内存是字面意思。和我们本文当中站在计算机系统的角度来解释的虚拟内存不是一个概念。所以特别注意这一点。因为有些人理解的虚拟内存，就是swap交互区。此虚拟内存非彼虚拟内存，所以明白各自的概念和作用。 linux环境下叫做swap分区，window下这块区域不叫swap分区，就直接按照字面意思叫做”虚拟内存”了。所以两个含义不同的虚拟内存","link":"/1080640073/"},{"title":"服务器端会话技术：Session","text":"Session对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在Session对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。他是用来解决Cookie带来的安全问题。 一、Session概述 会话 ， Session是基于Cookie的一种会话机制。 Cookie是服务器返回一小份数据给客户端。并且存放在客户端上。 Session是，数据存放在服务器端。 二、常用方法1234567891011//得到会话IDString id = session.getId();//存值session.setAttribute(name, value); //取值session.getAttribute(name); //移除值session.removeAttribute(name); 三、Session的创建与销毁。 创建如果有在servlet里面调用了 request.getSession() 销毁session 是存放在服务器的内存中的一份数据。 当然可以持久化. Redis . 即使关了浏览器，session也不会销毁。 关闭服务器 session会话时间过期。 有效期过了，默认有效期： 30分钟。 四、移除Session中的元素12345//强制干掉会话，里面存放的任何数据就都没有了。session.invalidate(); //从session中移除某一个数据session.removeAttribute(\"cart\"); 五、总结 Session： 也是基于cookie的一种会话技术， 数据存放存放在服务器端。 123456会在cookie里面添加一个字段 JSESSIONID . 是tomcat服务器生成。 setAttribute 存数据getAttribute 取数据removeAttribute 移除数据getSessionId(); 获取会话idinvalidate() 强制让会话失效。 创建和销毁 调用request.getSesion创建 服务器关闭 ， 会话超时（30分） setAttribute 存放的值， 在浏览器关闭后，依然不会丢失！","link":"/3004142873/"},{"title":"操作系统---进程管理","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进程，也就是任务，这里有必要说一下进程和线程的区别：进程是资源分配的最小单位，线程是程序执行的最小单位，通俗来讲，一个爹可以有很多儿子，但儿子之后一个爹，并且还遗传这个爹，爹能做大事，而儿子，做一些杂七杂八的给爹打下手，你细细品。这篇文章主要讲进程管理的策略。 进程概念 进程：打开任务管理器，里面正在执行的任务，一个程序运行起来了，它就是一个进程。 jobs是最早的进程原型，也就是单道批处理系统，cpu一次只运行一个程序，其他的程序要事先放在内存中，等待上一个程序执行完了，他再去执行。 后来出现了分时操作系统，大家轮着执行。使用cpu，称之为任务。 进程组成 程序计数器（pc）和各种寄存器 数据段 代码段 栈 堆 栈内存，堆内存慢慢增长，到一定程度，会导致内存不足的情况。 进程状态 操作系统就是通过切换进程的状态，达到进程控制的目的。也实现了很多进程同时运行，周而复始。有条不紊 new（新建） ready（就绪态）：一个进程是完全可以运行的，万事俱备，只差cpu。 running（运行态）：拥有cpu的进程，一个cpu上只能运行一个进程，什么时候它会把cpu交出去？①中断interrupt：她本可以继续运行下去的，但是操作系统觉得它运行的太久了。或者是有更重要的要做，所以就把他给中断了，打回到就绪态。②主动让出cpu：这个进程要去做一个io操作，或者是等待一个事件（等不到这个指令，他就不知道要做什么），这个时候就会让出cpu。进入就绪状态。 waiting（等待态）：被唤醒（有响应了，知道自己该做什么了）之后进入就绪态。 terminated（结束） 进程控制块PCB 进程控制块PCB（Process Control Block）是一个结构体，通过它来控制进程。每个进程都有一个PCB。通过PCB能找到这个进程的位置，状态，信息。 进程1切换的时候，将这个进程的所有信息保存到PCB寄存器中，以保证下次在运行的时候，就是上次停止的状态。 如何挑选下一个进程来执行呢，这就涉及到内核的调度算法了。 所有的PCB结构体，在一起构成了一个队列。 进程是在不同的队列之间，来回迁移。例如：就绪队列，I/O等待队列。 用一个大数组来装所有的PCB结构体，用一个指针来指向PCB数组中的这个进程。 软件做不了的事，硬件可以做。 进程的创建 一开机就会发现有进程，这些都是系统级的进程 ，如shell，资源管理器，一些应用程序设置的开机自启动就是通过shell来启动的，相当于捆绑销售一样 。 打开应用程序，双击，这个命令给了资源管理器，或者命令行下，是把指令给了shell 父进程与子进程 unix创建进程：fork（）生成一个子进程 top 命令，监视现在所有进程的状态，每隔一秒种刷新一次。 windows创建进程：create process msdn—微软的百科全书。 杀死进程：kill 进程间通信多进程模式模块化 消息传递（Mwssage passing） ：A进程把消息从自己的内存空间复制一份到内核中，然后内核再把消息复制一份给进程B。用系统调用进行信息传递。 共享内存（Shared memory）： 每个进程都有自己独立的地址空间，但是两个进程，甚至更多的进程通过协商（也是系统调用来协商）划分出来一块儿共享内存。在每个进程的地址空间都有。A在这块儿空间里一写数据，B马上就可以读取到。 共享内存在协商的时候，要经过一系列的系统调用。而且还要约定好，过程很麻烦。如果进程之间共享内存，就要负责任，实现同步，不要同时写在同一个地方。 消息传递 很方便。经常用到。分为两种：①阻塞型：（更好用）当你调了这个系统调用之后，如果你请求的结果不能立即得到。那么你当前这个进程就会被挂起，被放到等待状态，被阻塞。②非阻塞型：（考虑的比较多 ）当你调了这个系统调用之后，如果你请求的结果不能立即得到。那么这个请求会在后台去操作，同时这个系统调用会返回，空闲时候会回到你的进程，这个系统调用的返回值会告诉你，这个操作没有完成，进程根据这个返回值来判断是否完成操作，并做其他操作。 多进程编程 父进程会把所有的信息复制一份给子进程，自此变成两个独立的进程，互相不影响。 以我们的角度来看，这样的子进程，父进程是不是太浪费内存了，但是，操作系统只是表面上让你看到它是把父进程复制给了子进程，但其实，他可以做到父进程和子进程之间完全相同的部分之间共享内存。所以大可不必担心这个问题。 多进程编程最重要的一个特性，也是我们首先要了解到的，独立性，直观上来看，他们两个进程之间互相不干扰。 线程 进程的特点是分离，而线程就是不分离。 互相协作的关系 线程有： 线程ID，PC寄存器，栈 。。。 引入进程的目的就是让一个进程里面同时有多条执行路线，同时发挥作用。 多线程优点：①快速的响应能力：有比较耗时的操作是，创建线程去做，主线程用来和用户 交互。②资源共享：协作更方便，数据传递更方便③经济实惠：线程更加节约资源。 用户级线程：①优点：效率高，可定制性好，。②缺点：用户线程中任何一个线程，如果调用了阻塞性的系统调用，那么所有用户线程就全被阻塞。因为在操作系统看来，这么这个线程就是同一个线程，就会被阻塞掉。用户线程不能在多个处理器上并行运行。 内核级线程：操作系统提供的线程。 线程池：先创建多少个线程，要用的时候 就去拿，但是也有缺点。","link":"/853277148/"},{"title":"区块链技术的应用领域","text":"- 金融领域区块链在国际汇兑、信用证、股权登记和证券交易所等金融领域有着潜在的巨大应用价值。将区块链技术应用在金融行业中，能够省去第三方中介环节，实现点对点的直接对接，从而在大大降低成本的同时，快速完成交易支付。比如Visa推出基于区块链技术的 Visa B2B Connect，它能为机构提供一种费用更低、更快速和安全的跨境支付方式来处理全球范围的企业对企业的交易。要知道传统的跨境支付需要等3-5天，并为此支付1-3%的交易费用。Visa 还联合 Coinbase 推出了首张比特币借记卡，花旗银行则在区块链上测试运行加密货币“花旗币”。 物联网和物流领域区块链在物联网和物流领域也可以天然结合。通过区块链可以降低物流成本，追溯物品的生产和运送过程，并且提高供应链管理的效率。该领域被认为是区块链一个很有前景的应用方向。区块链通过结点连接的散状网络分层结构，能够在整个网络中实现信息的全面传递，并能够检验信息的准确程度。这种特性一 定程度上提高了物联网交易的便利性和智能化。区块链+大数据的解决方案就利用了大数据的自动筛选过滤模式，在区块链中建立信用资源，可双重提高交易的安全性，并提高物联网交易便利程度。为智能物流模式应用节约时间成本。区块链结点具有十分自由的进出能力，可独立的参与或离开区块链体系，不对整个区块链体系有任何干扰。区块链 +大数据解决方案就利用了大数据的整合能力，促使物联网基础用户拓展更具有方向性，便于在智能物流的分散用户之间实现用户拓展。 公共服务领域区块链在公共管理、能源、交通等领域都与民众的生产生活息息相关，但是这些领域的中心化特质也带来了一些问题，可以用区块链来改造。区块链提供的去中心化的完全分布式DNS服务通过网络中各个节点之间的点对点数据传输服务就能实现域名的查询和解析，可用于确保某个重要的基础设施的操作系统和固件没有被篡改，可以监控软件的状态和完整性，发现不良的篡改，并确保使用了物联网技术的系统所传输的数据没用经过篡改。 数字版权领域通过区块链技术，可以对作品进行鉴权，证明文字、视频、音频等作品的存在，保证权属的真实、唯一性。作品在区块链上被确权后，后续交易都会进行实时记录，实现数字版权全生命周期管理，也可作为司法取证中的技术性保障。例如，美国纽约一家创业公司Mine Labs开发了一个基于区块链的元数据协议，这个名为Mediachain的系统利用IPFS文件系统，实现数字作品版权保护，主要是面向数字图片的版权保护应用。 保险领域在保险理赔方面，保险机构负责资金归集、投资、理赔，往往管理和运营成本较高。通过智能合约的应用，既无需投保人申请，也无需保险公司批准，只要触发理赔条件，实现保单自动理赔。一个典型的应用案例就是LenderBot, 是 2016 年由区块链企业 Stratumn、德勤与支付服务商 Lemonway 合作推出，它允许人们通过 Facebook Messenger 的聊天功能，注册定制化的微保险产品， 为个人之间交换的高价值物品进行投保，而区块链在贷款合同中代替了第三方角色 。 公益领域区块链上存储的数据，高可靠且不可篡改，天然适合用在社会公益场景。公益流程中的相关信息，如捐赠项目、募集明细、资金流向、受助人反馈等，均可以存放于区块链上，并且有条件地进行透明公开公示，方便社会监督。","link":"/undefined/"},{"title":"手写链表","text":"看过很多面经，看得出来，数据结构和算法在面试中是很重要的，在之前也听说过，面试过程中，出现手撕代码的场景，而我刚好又看到链表这一章，顺便对链表做一下巩固，也打个预防针，万一真遇到要手写代码的时候，也有了一手准备。 一、链表结构 每个节点结构是由数据域和指针域组成，数据域是存放数据的，而指针域存放下一结点的地址。 但是不可能只有一个节点呀，这时候就使用 Class 来声明一个类，为类添加两个属性，一个属性是存放数据的属性data，另一个属性是存放指向下一个结点的指针属性next。这样就可以创造出多个结点实例。 123456class Node{ constructor(data){ this.data = data; this.next = null; }} 二、插入删除 插入到单链表的头部 插入到中间 插入到尾部 删除头部节点 删除中间节点 删除尾部节点 三、边界条件 输入边界：先考虑用户输入的参数，比如传入一个链表，我们首先要判断链表是否为空，如果为空我们就不能让它执行下边的程序。再比如插入一个结点到指定结点的后边，那么你也要判断输入的结点是否为空，而且还要判断该结点是否存在该链表中。对于这些输入值的判断，就叫做输入边界。 特殊边界：考虑到一些特殊情况，比如插入数据，我们插入数据一般考虑到插入尾部，但要是插入到头部，插入尾部的代码并不适用于插入到头部，所以呢需要考虑这种情况，删除节点也是同样要考虑这种情况。其实特殊边界最主要考虑到一些逻辑上的特殊情况。 四、示例例：在链表中间增加和删除节点 1. 定义节点：123456class Node{ constructor(data){ this.data = data; this.next = null; }} 2. 增加节点：①保存临时地址（4结点的地址）,需要进行遍历查找到3结点，也就是下列代码的currentNode 结点。 1234//先查找该元素let currentNode = this.findByValue(element);// 保存 3 结点的下一结点地址（4 结点的地址）let pre = currentNode.next ②创建新结点，将新结点（5结点）的指针指向下一结点指针（4结点地址，已经在上一步骤保存下来了） 12let newNode = new Node(value);newNode.next = pre; ③将3 的结点地址指向新结点（5结点） 1currentNode.next = newNode; 3. 删除节点：①断开3结点的指针（断开3结点相当于让2结点直接指向4结点） 12345678910 let currentNode = this.head; // 用来记录 3 结点的前一结点 let preNode = null; // 遍历查找 3 结点 while(currentNode !== null &amp;&amp; currentNode.data !== value){ // 3 结点的前一结点 preNode = currentNode; // 3 结点 currentNode = currentNode.next;} ②让结点2的指针指向4结点，完成删除。 1preNode.next = currentNode.next; 五、代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * 功能：单链表的插入、删除、查找 * 【插入】：插入到指定元素后方 * 1、查找该元素是否存在？ * 2、没有找到返回 -1 * 3、找到进行创建结点并插入链表。 * * 【查找】：按值查找/按索引查找 * 1、判断当前结点是否等于null，且是否等于给定值？ * 2、判断是否可以找到该值？ * 3、没有找到返回 -1； * 4、找到该值返回结点； * * 【删除】：按值删除 * 1、判断是否找到该值？ * 2、找到记录前结点，进行删除； * 3、找不到直接返回-1； */ //定义结点 class Node{ constructor(data){ this.data = data; this.next = null; } } //定义链表 class LinkList{ constructor(){ //初始化头结点 this.head = new Node('head'); } //根据 value 查找结点 findByValue = (value) =&gt;{ let currentNode = this.head; while(currentNode !== null &amp;&amp; currentNode.data !== value){ currentNode = currentNode.next; } //判断该结点是否找到 console.log(currentNode) return currentNode === null ? -1 : currentNode; } //根据 index 查找结点 findByIndex = (index) =&gt;{ let pos = 0; let currentNode = this.head; while(currentNode !== null &amp;&amp; pos !== index){ currentNode = currentNode.next; pos++; } //判断是否找到该索引 console.log(currentNode) return currentNode === null ? -1 : currentNode; } //插入元素(指定元素向后插入) insert = (value,element) =&gt;{ //先查找该元素 let currentNode = this.findByValue(element); //如果没有找到 if(currentNode == -1){ console.log(\"未找到插入位置!\") return; } let newNode = new Node(value); newNode.next = currentNode.next; currentNode.next = newNode; } //根据值删除结点 delete = (value) =&gt;{ let currentNode = this.head; let preNode = null; while(currentNode !== null &amp;&amp; currentNode.data !== value){ preNode = currentNode; currentNode = currentNode.next; } if(currentNode == null) return -1; preNode.next = currentNode.next; } //遍历所有结点 print = () =&gt;{ let currentNode = this.head //如果结点不为空 while(currentNode !== null){ console.log(currentNode.data) currentNode = currentNode.next; } } }","link":"/3274828756/"},{"title":"JavaSE---Object类","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Object类是所有类的父类，位于java.lang包中。这也是面试的一个小考点吧，这篇文章看看Object中有哪些方法。 Object类概述 Object类是JDK默认提供的一个类。java中除了Object类，所有类都存在继承，默认会继承Object父类 所有类的对象都可以使用 Object 接收。 Object 达到最高参数统一化。 什么时候使用Object类? 对于Object类的使用可以分为两个阶段：JDK 1.5以前，以及JDK 1.5之后。 Object之所以会被大量的进行参数的接收处理，很大的一部分原因在于：你的程序里面需要接受的类型很多，并不固定，可是现在的开发理念中强调的问题不再是这一点了，而是如何可以避免向下转型（如果避无可避，那么就用），因为从JDK1.5之后引入了泛型机制（在基础课程讲解泛型机制的时候重点分析了Object缺陷）。 现在的设计思想是用泛型来避免向下转型的操作（ClassCastException），如果你要认真读了API文档你会发现，可以接收Object类型的方法是越来越少了，开发中尽量回避Object接收的项目为主。 Object类有哪些方法？ 可以看到里面都是用native关键字修饰的方法。都是原生函数，得调用C++的函数。","link":"/Object/"}],"tags":[{"name":"https","slug":"https","link":"/tags/https/"},{"name":"MySql,DBUtils","slug":"MySql-DBUtils","link":"/tags/MySql-DBUtils/"},{"name":"HashMap","slug":"HashMap","link":"/tags/HashMap/"},{"name":"Http协议","slug":"Http协议","link":"/tags/Http%E5%8D%8F%E8%AE%AE/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"JDBC,MySql","slug":"JDBC-MySql","link":"/tags/JDBC-MySql/"},{"name":"JSP","slug":"JSP","link":"/tags/JSP/"},{"name":"EL","slug":"EL","link":"/tags/EL/"},{"name":"JSTL","slug":"JSTL","link":"/tags/JSTL/"},{"name":"OS","slug":"OS","link":"/tags/OS/"},{"name":"MySql","slug":"MySql","link":"/tags/MySql/"},{"name":"javaSE","slug":"javaSE","link":"/tags/javaSE/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"Tomcat","slug":"Tomcat","link":"/tags/Tomcat/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"XML","slug":"XML","link":"/tags/XML/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"Servlet","slug":"Servlet","link":"/tags/Servlet/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"区块链，比特币","slug":"区块链，比特币","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE%EF%BC%8C%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"Cookie","slug":"Cookie","link":"/tags/Cookie/"},{"name":"MVC","slug":"MVC","link":"/tags/MVC/"},{"name":"MySql,连接池","slug":"MySql-连接池","link":"/tags/MySql-%E8%BF%9E%E6%8E%A5%E6%B1%A0/"},{"name":"Session","slug":"Session","link":"/tags/Session/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"}],"categories":[{"name":"每天一道面试题","slug":"每天一道面试题","link":"/categories/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java Web","slug":"Java-Web","link":"/categories/Java-Web/"},{"name":"git+github","slug":"git-github","link":"/categories/git-github/"},{"name":"计算机操作系统","slug":"计算机操作系统","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"JavaSE基础知识","slug":"JavaSE基础知识","link":"/categories/JavaSE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"linux学习笔记","slug":"linux学习笔记","link":"/categories/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Hexo建站系列","slug":"Hexo建站系列","link":"/categories/Hexo%E5%BB%BA%E7%AB%99%E7%B3%BB%E5%88%97/"},{"name":"区块链+比特币","slug":"区块链-比特币","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"读后感","slug":"读后感","link":"/categories/%E8%AF%BB%E5%90%8E%E6%84%9F/"}]}